{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Battery Forecasting with DeepAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll prevent battery outages using Amazon Sagemaker and [DeepAR Forecasting](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The Amazon SageMaker DeepAR forecasting algorithm is a supervised learning algorithm for forecasting scalar (one-dimensional) time series using recurrent neural networks (RNN).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the required libraries and recovering stored data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the battery time series for a single device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8e4a851ed2317a249a0903f29d894361'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_loc = 1\n",
    "sample_device_id = data.iloc[device_loc][\"device_id\"]\n",
    "sample_device_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data[data[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery = sample_data[\"battery\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "battery.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [DeepAR input format](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html#deepar-inputoutput) requires data to be sampled at regular time intervals. Here is a sample input:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>{\"start\": \"2009-11-01 00:00:00\", \"target\": [4.3, \"NaN\", 5.1, ...], \"cat\": [0, 1], \"dynamic_feat\": [[1.1, 1.2, 0.5, ...]]}\n",
    "{\"start\": \"2012-01-30 00:00:00\", \"target\": [1.0, -5.0, ...], \"cat\": [2, 3], \"dynamic_feat\": [[1.1, 2.05, ...]]}\n",
    "{\"start\": \"1999-01-30 00:00:00\", \"target\": [2.0, 1.0], \"cat\": [1, 4], \"dynamic_feat\": [[1.3, 0.4]]}\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, we can see that the sample timestamps are no regularly spaced, but actualy reflects the observation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2020-02-25 20:50:37    75\n",
       "2020-02-25 21:07:07    75\n",
       "2020-02-25 21:23:15    75\n",
       "2020-02-25 21:38:36    75\n",
       "2020-02-25 22:03:11    75\n",
       "Name: battery, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "battery.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='timestamp'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "battery.tail(20).plot(style=\"k.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, note that observation are taken about every 5 minutes, but changing little.\n",
    "Pandas offers a convenient resampling function to create a uniform hourly dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = data[data[\"battery\"] > 0]\n",
    "hourly = (hourly.groupby(\"device_id\")\n",
    "          .battery\n",
    "          .resample(\"H\")\n",
    "          .min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id                         timestamp          \n",
       "0001495ce5f079703599a94c32dab2b0  2020-02-24 15:00:00    75.0\n",
       "                                  2020-02-24 16:00:00    75.0\n",
       "                                  2020-02-24 17:00:00    75.0\n",
       "                                  2020-02-24 18:00:00    75.0\n",
       "                                  2020-02-24 19:00:00    75.0\n",
       "                                                         ... \n",
       "fffaee1fbb9c96703850f64d3262e843  2020-02-25 17:00:00    64.0\n",
       "                                  2020-02-25 18:00:00    68.0\n",
       "                                  2020-02-25 19:00:00    75.0\n",
       "                                  2020-02-25 20:00:00    76.0\n",
       "                                  2020-02-25 21:00:00    76.0\n",
       "Name: battery, Length: 532029, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = hourly.reset_index().set_index(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-24 15:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 16:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 17:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 18:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 19:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 17:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 18:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532029 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  battery\n",
       "timestamp                                                     \n",
       "2020-02-24 15:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "2020-02-24 16:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "2020-02-24 17:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "2020-02-24 18:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "2020-02-24 19:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "...                                               ...      ...\n",
       "2020-02-25 17:00:00  fffaee1fbb9c96703850f64d3262e843     64.0\n",
       "2020-02-25 18:00:00  fffaee1fbb9c96703850f64d3262e843     68.0\n",
       "2020-02-25 19:00:00  fffaee1fbb9c96703850f64d3262e843     75.0\n",
       "2020-02-25 20:00:00  fffaee1fbb9c96703850f64d3262e843     76.0\n",
       "2020-02-25 21:00:00  fffaee1fbb9c96703850f64d3262e843     76.0\n",
       "\n",
       "[532029 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again visualize a sample tame series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsample = hourly[hourly[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='timestamp'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hsample.tail(12).plot(style=\"k.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='timestamp'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEeCAYAAACT504VAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA9b0lEQVR4nO29e3hcZ3Xv/1m6W7IuljTjuy3HtsZJnMQ4Drk4sUckISFtCfyghTRQAoUUeEqhvx5aWs6hAVoKJS3we4ByUmhCnwPhEqDQnlASiC8hd8dxbrZlO/H9KtuSbOs2t/X7Y+8ZS7ZkjaSZ2XvPrM/zzOOZd/blld89a6+93u+7lqgqhmEYRvAo87oDhmEYxuQwA24YhhFQzIAbhmEEFDPghmEYAcUMuGEYRkAxA24YhhFQKgp5stbWVm1rayvkKQ3DMALP888/f1xVQ+e2F9SAt7W1sWnTpkKe0jAMI/CIyN7R2i2EYhiGEVDMgBuGYQQUM+CGYRgBxQy4YRhGQBnXgItIRES2DHudEpFPuN99TES2i8irIvKPee+tYRiGkWFcFYqqdgIrAESkHDgI/ExEOoDbgStUdUhEwvnsqGEYhjGSiYZQbgReU9W9wEeAL6rqEICqHst15wzDMIyxmagBfzfwoPu+HbhBRJ4RkQ0iclVuu1a6HOkd5J5fvMpgPOl1V4xJMpRI8j//42WOnRr0uiuGD4gnU3zm569wsGcgp8fN2oCLSBXwVuDHblMF0AxcA3wS+JGIyCj73S0im0RkU1dXVw66XPw8ses4Dzy5h4077P8rqOw4cob/8/Q+frRpv9ddMXzA6119/PtTe3nwmX05Pe5EPPC3AJtV9aj7+QDwU3V4FkgBrefupKr3qeoqVV0VCp23EtQYhVgyBcB6M+CBZcB9elrfaWNoQF8sAcD6HbmNNE/EgN/B2fAJwH8AHQAi0g5UAcdz1rMSJu4a8A2dXVjJu2CSDn9t3tdNb3/c494YXtM/5FwPrxw8xbHTuQurZWXARaQOuBn46bDmfwMuEpFXgB8A71OzNjkhlnAM+MGeAXYdO+Nxb4zJkDbgKYXHd5kXXuqkPXCAjTty5+dmZcBVtU9VW1S1d1hbTFXfo6rLVXWlqj6Ws16VOEOuAQdY12niniAyOHwMt5sBL3X6XQNeUSY5/U3bSkwfkg6htM+cbjHUgJL2wFcuaGLDji5SKXs4LWXOuCGU65e28viOLhLJ1Dh7ZIcZcB8SS6SoLBc6ImGe23OSM0OJ8XcyfMWQa8Dfsnw2x88MsfXwKY97ZHhJv/sbvu2y2ZwaTLBlf09OjmsG3Ic4BryMtZEQ8aTyxC6bGw4ag3HHw3rzpTMBWLfdQmGlTF/MuaG/+ZKZlJdJzp6szYD7kHgyRVVFGasWNjO9usLCKAEkLSOc2zSNy+c1miS0xOkfSlBXVU5TbRVXLpiRszi4GXAfEks6HnhVRRmrl7SwofOYyQkDxmA8SUWZUFFeRrQ9xAv7uunpj3ndLcMj+mIJaqud1FNrIyFePZQbOaEZcB8ylEhRVe4MTTQS5lDvIDuOmpwwSAzGU9RUlgOwNhImpbBxp4XCSpW+oSR1Vc71EI04Cxo35ODJ2gy4D4knleqKtAF3Bnu9yQkDxWAiSU2lM4Yr5jfRVFtpY1jC9McS1FY5HvglsxsI11fnJKxmBtyHxBJJKl0PfHbjNJbNqrc4eMAYjCczHnh5mbBmaYiNJicsWfqGkkx3QygiQjQSyomc0Ay4D4klnEnMNGsjIZ7bc5LTg7YkOygMDQuhgPMkdfxMjFcO9V5gL6NY6Y8lqK0efj2EOTWY4IUpygnNgPuQeFJHGPBoe5hESnli1wkPe2VMhIH42RAKwJr2dCjMnqRKkTNDCeqqztbPWb2k1ZUTTi2sNm5FHqPwpBfypFnVNoPp1RX8fMtBWqZXediz8xHgkjkNmfie4TAYT1JTcdbjap1ezRXzGvnVq0e4dnFLwfpRXVHG8jmNlJWdl+nZKCD9sSS1VWevh8ZplVy5cAaPbj1KNDL5Ymb2q/MhQ8kUjVWVmc/pRT3/96XD/PKVIx72bHT+8OoFfOHtl3ndDV8xGE+ed1O78eKZ/POjO/j9bz1V0L58+49WcdMlMwt6TmMkfUMJ6qpHXg83XRzmCw9vn9L1YAbch8SHyQjTfOFtl3HHVQs86tHY/O+Nr/GbbUfRty1nlHoeJctgPEVz3cgxvHvNRaxqm0EqN2kwxiWeSvH++5+j8+hpM+Aeoqr0x5LUDYuBA9x13SIum9tEMouJ7Ru+NHq7GXAfEkumqKoYaQwbayu5ful59TI853DvAJ986CW2HT7NJXMavO6Ob3BkhCN/sDWV5Vy3uLBjGK6vZs/xvoKe0xhJLJkikdLznsiqKsqmHE6zSUwfEhvFA/cra12duqW9Hcm5KhSvaGutY88JM+Be0udmIqyryv31EAwrUWKkc6EEgXB9DZfOacjJqrJi4lwVilcsaqlj9/F+r7tR0vS5mQhrq3Mf8PD+CjPOI52NMChEIyGe39dN74Dp1NOcq0LxioWttRw/M2QpiT2k381EON0MeGlw7kIev9MRCZNMKb+1XB+AM2k1fCWmlyxqqQOwOLiHpMup1VoIpTSIBSiEAk6uj4aaCsv14RJPKinFFyGUtlbXgFsc3DPSIZRzZYS5wPsrzBiBqjoGPEAhlIryMm5oD7FhR5elvcVRoAC+8MAXttQCsPeExcG9Ij2JaR54CZBIKaoEyoADRNtDHDttpcPgbD1MPxjw2qoKZjZUs9tCKJ6RLmhcl4fVysGyEiVAuqBxkEIocFZOaLk+HAkh+MOAAyxsqWOvhVA8I11OzUIoJUAs4fz4g6RCAUdOuHxug8XBOVtOzQ8xcDApodf0Z2LgFkIpetIGPGgeODhZEzfv6yl5OWEmhOIDGSE4E5nHzwxZOmKP6BtKIJKf62FcKyEiERHZMux1SkQ+Mez7vxARFRH/rfMOILGAhlDA0YObnPBsRXq/hFDabCLTU/piSWory/OSEXJcK6Gqnaq6QlVXAFcC/cDPAERkPvBmYF/Oe1aiZDzwgIVQwJETNk6rLPll9YM+C6GYlNBb+ocVNM41E73CbgReU9W97uevAH8JmHYsRwTZA68oL+OGpa1sKPHSYX5SocBZKaEt5vGG4eXUcs1ErcS7gQcBROR24KCqvpjzXpUw8YRj+ILogYNTKqqrxOWEgwl/hVDSUsI9FkLxBKegcX6uhaythIhUAW8FfiwitcDfAJ/JYr+7RWSTiGzq6jKJ2XjEko73VhlADxxgbaZ0WOmGUQZj/gqhALS11JkH7hHnllPLJRO5wt4CbFbVo8BiYBHwoojsAeYBm0Vk1rk7qep9qrpKVVeFQqFc9LmoGQpwDBwgVF/NZXMbS1oP7qeVmGnaWurMA/eI/lhyREHjXDIRK3EHbvhEVV9W1bCqtqlqG3AAWKmq/qv3FTDiSTeEElAPHBw1yuZ93fT2l6ZszW8xcDApoZeMVk4tV2RlJUSkDrgZ+GleemFkCLIKJU00EiKl8Piu0vTCMzJCH92EF7WalNAr+mPJvBRzgCwNuKr2qWqLqvaO8X2bqpa2+DdHBHkhT5oV82fQVFvJuu2lasCTVJQJFT66CS9sMSmhV5wZSpxXTi1X+OcKM4Dg5kIZTnmZcMPSUMnKCQfjKab5KHwCTgwcTEpYaMYqaJwrgmslipSzuVCCXeE92h7i+JnSlBMOxJNU+8yAT6sqZ1ZDjeVEKTBDiRTJUQoa5woz4D5jqAg8cIA1JSwnHPJJPcxzWdhSa1kJC0w+y6mBGXDfEXc98Opyf3lwEyVUX83l8xpZV4JywsGEP8qpncsiq1BfcDIFjb1eyGMUhvRS+sqKYIdQwAmjvLCvm57+mNddKSiD8ZRPPfA6jp+JmZSwgKTrYXoqIzQKRzHICNOsjYQdOWGJZSf0S0X6czEpYeHJZzk1MAPuO+LJFGWCryRok2XF/CaaaitLblXmYDzJtDz9YKdCOiuhlVcrHP3mgZcWsUQqcNV4xqK8TFizNMSGHcdKSk44GE9R7UMPfGGzY8BtIrNwpD1wP+RCMQrAUCIVeAXKcKKREMfPxHj1UOnICQd9qkIxKWHhOeuBWwilJIgnU1QXkQEvRTmhY8D954EDtLXWmhKlgJxVoeTHA8/PUccgrYk0xqaYQigArdOruWJeI7985QjL5zaO+O6SOQ3MbKjxqGf5YzDhTxUKOCsyf73tqNfdKBnOVqTPzw29oAb8SO9gIU8XSGLJ4gqhANx8yUzufWQH73/guRHtV7XN4Mcfvs6jXuUPv6pQABaHpvOD5/bTdXqIUH21190pevrdgsb5Sq1QYA88wZmhRN5WJRUD8WRxeeAAf7J2MWvbwyT17ETmQ8/v5/vP7KO7L8aMuioPe5dbVNXXIZRrF7cAsHFHF++4cp7HvSl++mJJ6qoqEMnPuo6CWgoFnthVWprgiRJLpIpCAz6cyvIyLpvXyIr5TZnXO1bOI6WwcWdxSQzjSSWl+FJGCHDpnAZC9dUlX3i6UOSznBoU2ICXiZScJniiFJsKZSwun9fEjNpKNhTZ9TDgFnPw60S0iBBtD/H4zuMk3FW/Rv44M5TMmwYcCmzAp1dXsL7zGKqlowmeKPFk8Xngo1FeJqxpL76Us0M+rMZzLtFImN6BOC8e6PG6K0VP/1AReeD1NRUc7h1kx9EzhTxtoIiViAcOjkb8RF+MVw6NWickkGSq8fjYgF+/tJXyMinZghuFpC+Wv3Jq4IEBh9LSBE+UYlShjMWapSFEKCpDcragsX/HsHFaJSsXNLF+h/0O800+y6lBgQ14ZXkZy2bV2wTKBYgnNPDFHLKlZXo1l88rLkOSKWjsUxlhmmgkzCsHT3HstEl788mZoQS1xeKBg3PhbNrTbSktx8DxwP39488l0fYQW/b3cLKvOFLOBiGEAk74Cii6SWS/0T9URB44OBdOIqU8setEoU8dCIpRRnghopEQqvB4kcgJ0yqUaVX+HsNLZjcQrq9m/Y7i+H/3K0UVAwe4cuEM6qsr2FBEj825xPHASyOEAo6csLmuqmjkpYMZGaG/PXARYW17iMd3dJmcME9kChrnKQ8KeGDAK8vLuH5pK+u2d5mccBRKzQN3Us62Fo2ccDAAMsI0HcvCnBpM8ML+Hq+7UpRkChrnKQ8KeJSNMBoJceTUIJ1HT3txel9TSjLCNNFImJN9MV46GHw54VAmBu7/MVy9xJETmiosP6QzEXrqgYtIRES2DHudEpFPiMiXRWS7iLwkIj8TkaZsT7q2PQxQNI/NuaQYc6GMx5p2R05YDIbkrIzQ/x5447RKrlwww36HeSKdfdXThTyq2qmqK1R1BXAl0A/8DHgUWK6qlwM7gL/O9qSzGmu4eHYD67YH/webS1IpJZHSkvPAm+uquGJeU1EYkiCFUADWRkK8eugUx06ZnDDXpAsa5zN530QtxY3Aa6q6V1UfUdWE2/40MKHUZtFIiOf3mpxwOOmK9KVmwMG5Hl480MOJM0Ned2VKZGSEARnDjoj7NGxqlJyTKWjsIwP+buDBUdo/APxyIgeKtjtywt+WWMXyC5Ex4CUWQgEnDq4Kb//mk9z61Y2Z17v+91P0DgTnJj8QT1JZLoEpSn3x7HpmNlQXRfjKb2TKqflBBy4iVcBbgR+f0/5pIAF8b4z97haRTSKyqavr7F1+5cIZ1NdUFMVjc66IJUrXA798biN3XdfGsln1LGiuZUFzLeGGGp7ZfZLHtgengoyfizmMRkZOaNkJc06+y6nBxAo6vAXYrKqZX5OI3AX8LnCjjqEJVNX7gPsAVq1aldmmsryMG1z5mKrmLeF5kMgY8IB4b7mkrEy4562XjmhLpZSr/v7XrO/s4u1vCEbxgcF4iuqAxL/TRCNhfrTpAJv39fDGRc1ed6doyFSk94mM8A6GhU9E5FbgL4G3quqkylxH28McOTXI9iMmJwRHgQKUnAplLMrclLMbd3SRDIhGfMinFekvRDo7oYVRcsvZivQex8BFpA64GfjpsOavA/XAo6688FsTPfnaSLpiuYVRoLRDKGMRjYTo7o/zUkByVw8m/FtObSwaaiq5cqHJCXNNpqCx1ysxVbVPVVtUtXdY2xJVnZ+WGKrqhyd68pkNNVwyu8GyE7oMmQE/jzVLQ5QJrAuIcRmM+7ci/YWIRkJsPXyKoyYnzBl9bkHjfF4Pnl9paTnhKZMTZkIopRgDH4sZdVVcMb+JDQG5yQ/EknmrQJ5P0nJCy06YO/qG8lvQGHxhwMMkU8oTJie0EMoYdETCvHSwNxAa8SCGUACWzapnVkNNUeVm95r+WCKvE5jgAwO+ckGTyQldSnkhz4VIp5wNQgX7wXjK95kIR2O4nDBucsKc0JfnTITgAwNeUV7GmqUh1u+wYsemQhmd5XMaaZ1eFYjSa0FUoaTpWBbi9GCCzXu7ve5KUdA/lMhrJkLwgQEHR41y9NQQ2w6XtpywlHXgFyIjJ9zpfznhYDyYIRRwshNWlIktq88RZ4YSeV3EAz4x4NF2V05Y4vE3U6GMTTQSpqc/zos+lxMOJoKpQgGoNzlhTsl3QWPwiQEPu3LCUr9w4knHuzQP/HzWLG2lTGC9zzNYBlWFkiYaCbPt8CmO9JqccKrku5wa+MSAgxN/e35vd6ASF+UaU6GMTVNtFW9YMMPXj/eqGlgVSpqOZW6x4xJ/Gs4F/UMlMImZJiMn3FW6csKYWwzADPjoRNtDvHSgl+M+lRPGkilUg5MLfDQiM105YYk/DeeCvliJTGICvGF+Ew01FSWdjyEdQqkst8ReoxF1F5ts9KkXns4FXh3gG7CIEI2E+K3JCaeEqtI3lMi7B57fo0+AivIybmgPsa6zi1+8eGjEd8tm1dM+s96jnhUO04FfmEvnNNA6vZp1nV38Pyv9l51wKGDVeMYiGgnzg+f2c9/G15nfXJtpr6+pINoessyhWTCUSJHS/CayAh8ZcIBbLp3F/33pMH/24Asj2mc11PDUX7+p6C+cIZMRXpCyMmexyW+2HyWZUsrL/HU9ZKrxBNyAr17SQl1VOV/+Ved53/3oT661lLNZkClonOcQiq8M+O9dPpsV85oynijAY9uP8oWHt7P18CkundPoYe/yj1PQWIr+RjUVopEQP9l8gC37e7hy4QyvuzOCswWNg30Drq+pZONfdtDdf1ZQMJRIcvvXn+Cx7cfMgGfB2YLGJTKJCU78bUFLLUvC0zOvt71hLlAaKWdjiZR53+Nwgysn9GNyqwH3RxtkGWGalunVI36Hl85p5Kq25pKeo5oIZ4byX04NfGbARyNcX8PyuQ0lceHEEimLf49DU20VKxfM8GV62aBVpJ8o0UiI7UdOc7h3wOuu+J50MYd8FjSGABhwcCr3bN7XQ29/cWvEnRBKIIbEU6KREC8f7KXrtL/khIOJdAy8OMcwailnsyZdTm16qcgIL0Q0EiKZUh7fVdwXjnng2eFXOWHaAw9iNsJsaJ85ndmNNVaAJQsyHngpxcDHYsX8JhqnVRZ9HDyWNAOeDZfMduSEfluVWewhFEcjHuaJXScyq4aN0ckUNDYD7mrE3Qr2KZ9no5sKNomZHWVlzmKTjTu6SPhosclQvLhDKOA8DZ8ZSvC8pZy9IH2ZGLiFUADnsbnr9BBbD5/yuit5wzzw7IlGQvQO+Cs74UC8eFQoY7F6SSuV5VLymUPHwzzwc1ibTjlbxPE3m8TMnhuWOMWO/RRWK/YQCsD06gpWLWxmfQCKa3hJfyxBWZ4LGkOADHiovprL5jb66gebayyEkj2Ntf7LXV0sKzHHo2NZiM6jpznUY3LCsShEQWMIkAEH57F5877uopUTmgplYkQjYV4+2Mux0/7IXT2YSFJZLr5b4p9rMnJCn00i+4n+AmQihAAa8FRAittOhlhSLYQyAdJhtY07/JGCeDCepKZIJYTDWRqezpzGGtb5vLiGl5wpQCZCyMKAi0hERLYMe50SkU+ISLOIPCoiO91/856YYsX8GUUtJ4wlkoFORVpoLp3TQKi+2jfzIoPxFNVFHj4Bt4J9JMwTu46bnHAM+mPJvGcihCwMuKp2quoKVV0BXAn0Az8DPgX8RlWXAr9xP+eVcre4bbHKCU2FMjFEhGi7f+SEgwGuSD9ROiIh+mJJNu096XVXfEnfUILaPOdBgYmHUG4EXlPVvcDtwHfd9u8Cb8thv8Yk2h7i+JkhXj1UfHLCeEKtmMMEiUbCnBpMsGV/j9ddYTAe7HqYE+G6tJywSJ+Gp0qhPPCJnuHdwIPu+5mqeth9fwSYmbNeXYA1btzzffc/O+IOV1NZzr/+0SoWtdYVoht5wTzwiXP90lbKy4QP/fumET+Y6ooy/uU9Vxa0EIjjgZeGAZ9eXcFVbc1898k9PPzy4RHf/cnaxbz3moUe9cwf9A0lWNBSO/6GUyRrAy4iVcBbgb8+9ztVVREZNaYhIncDdwMsWLBgkt08S6i+mk/fdjHbjgzzwBV++sJB/vPFQ/zZjUunfA6vcGSEpWEAckXjtEr+1+9czEsHe882Kvz8xUP8fMtBPnnLsoL1ZTCeKpkQCsCf39zOD57dj3L2p//s7pP8+5N7St6AnxqM0zitMu/nmYgH/hZgs6oedT8fFZHZqnpYRGYDo84kqep9wH0Aq1atykng+kNrLjqvbVfXGdZ3Hgu2AU+mqKywEMpEuWv1ovPaDnQPsL6zq7AGPJFkegEem/3CVW3NXNU2srjDv258nb9/eBsHewaY2zTNo555i6rS0x+nqQAGfCLuwh2cDZ8A/AJ4n/v+fcDPc9WpyRBtD7Flfw89/TEvuzFpVJVYIkW1yQhzwtpIiFcPneLYqcJpxAfjqaLNRJgt0Ujxr5gej75YkkRKmVFblfdzZWUtRKQOuBn46bDmLwI3i8hO4Cb3s2dEl4Vdjbg/NMETJV2R3mLguSFjSAq42GSohFQoY7EkPJ25TdNKenKzu89xIhtrfeKBq2qfqraoau+wthOqeqOqLlXVm1TVUz3RFfOamFFbyfqALi6IuzI4W8iTGy6Z3UC4vrqgxQcGSkiFMhZOytkQT+w6zpBbI7TU6B1wVor7LYTia8rLhBuWBlcjnl4QYR54bkgbksd3Fk4jXkoqlAsRjYTpjyXZtKc0U872uKk+mvwSQgkKHctCnOiL8cqh3vE39hmxpBnwXJPWiL9QII14qalQxuK6xS1UlZeVbBy8252Hm+GXEEpQWLM0hPgsxWi2pD1wC6HkjrRGvBA5O1SVwYR54AB11RW8cVFzIH+HuaDHDaH4JgYeFFqmV3P53MZA1uxLe+CWCyV3NNQULuVsLJlCtfhTyWZLNBJi57EzHOju97orBafX9cCbplkIZcJEI2G27O/JzAQHhUwM3DzwnBKNhNh6+BRH8ywnTOcCtxuwQzrlbCl64d39ceqqygsSDi26qy0aCaEBTDlrKpT8EG13c1fn2ZCUQjWeibA4VMe8GaUpJ+zpjxdkAhOK0IBfnpYTBuzCMRVKfrh4dj0zG6rzXsNxsATqYU6EtAroyddKT07YOxAryDJ6KEIDXl4mrHVTjAZJTmgGPD84KWfDPL7zeOYpJx+USjm1idDhygmf211acsLu/jgz6syAT5poJMyJvhgvHwyOnDBmIZS8EY2EOD2YYPPe/BmSsyEUG78015aonLCnP1aQCUwoUgO+pj14csK0B26TYLln9dJWKsokr8vqLQZ+PrVVFVx9UXNB0xn4gd6BeEEkhDDxfOCBoLmuiivmNbGu8xgfvykY2QltIU/+SMsJf/nyYebPGJmjeVXbjJzkDB9MpEMoNn7DiUbCfP6/trL/ZD/zm/OfH9tr0pkIC7GIB4rUAwfnsfnFAz2cDIic0FQo+eW2y2az50Q/f/Ozl0e8Pv6DLTk5/kDM8cBLPRvhuXiRVMxLzgwlSKS0YCGUovTAwbnzf/XXO3l8Zxe3r5jrdXfGxSYx88sfXbuQ2y6bTUrPTmx/75l9/H+/2cmR3kFmNdZM6fhppcW0AtRBDBIXtdYxv3kaGzqPlUSRh3QelEKFUIrWWlw+t5HmuqrAxMFtIU9+ERFC9dXMbKjJvG67bBYAG3IgMbQY+OikVUBP7DpREnLCtAEvRC5wKGIDXubKCYOSnTCWzgduBrxgRGbWM6uhhnXbp36Tz8gI7QnqPDqWhRiIJ3l2d/FXsO8ZcJfRmwc+daKRECf7YiPrJfoUC6EUnuG5q6eqETcPfGyuvaiVqoqywDwNT4VMKllbyDN1bshkJ/S/DtUMuDdEI2FODyV4fooacVvIMzbTqsq5elFzIH6HUyVd0tGW0ueAtJwwCHf+eDJFmTgrSY3CsXpJCxVlMuUMloOJJJXlYuM3BtFImNe6+th/srizE2YmMc0Dzw0dkTAvHujhxJkhr7tyQWLJlHnfHlBfU8mqthlTTnY1EEtSYxLCMekokWLHPQOFy0QIJWDA09kJH/d5seNYImUTmB7REQmz/chpDvcOTPoYQ4kkNSYhHJNFrXUsaK4NxNPwVOjujxUsfAIlYMAvm9tIS12V7+/85oF7Rzp39VS8cCundmHOZic8kZnwLUZ6++MFU6BACRjw4XLCpI/lhOaBe0f7zOnMbqyZUhx8MG4hlPHoiISLXk7YM2AGPOesjYTo7o/z0oEer7syJrGEeeBe4XiHzmKTtBpoolhF+vG55qKWopcTWgglD6xZGqLM59kJ48mU5UHxkGgkxJkpyAkthDI+06rKueailrwX1/CS3v54wTTgkKUBF5EmEXlIRLaLyDYRuVZEVojI0yKyRUQ2icgb893ZyTKjroor5jf5OqGOeeDesnpJK5XlMmnjMmAeeFZE20O83tXHvhPFJydUVd+GUL4G/LeqLgOuALYB/wh8VlVXAJ9xP/uWjkiYl3wsJ7RJTG+ZXl3BVW3NrJ/ksnoLoWRHxzK32HEReuGnhxIkU1qwPCiQhQEXkUZgDfAdAFWNqWoPoECDu1kjcChPfcwJfi92HEtYCMVropEQnUdPc6hn4nLCoUTKDHgWLGqtY2FLccoJewu8iAeySye7COgC7heRK4DngY8DnwB+JSL34twIrstXJ3PB8jmNtE6v4lM/eZnP/ufWTHtFmfBPf7CCte0hD3vneODTq4s2u28giEbCfOHh7azv7OIPr14woX37hhKWyCpLou0h/v3pvaz43CMj2t96xRw+d/tyj3o1dTJ5UArogWdjMSqAlcDHVPUZEfka8Ckcr/vPVfUnIvIHOB76TefuLCJ3A3cDLFgwsR9FLikrE/7+7Zfx5K6RC3r+Y8shfvL8Ae8NeCJFZa0ZAC9ZGp7O3KZprO88NiEDfqC7n2Onh4jMmnpln1LggzdcRFmZjMgSuuVALz/atJ+/ue3iwD7JdLt5UApVjQeyM+AHgAOq+oz7+SEcA349jicO8GPg26PtrKr3AfcBrFq1ylMh9i2XzuKWS2eNaDs9lOCx7cdIptTTPBbxpOnAvUZEWBsJ8fMXDk5oUjkdDkjHd40LM7+5lr/9vUtHtK3rPMb773+OZ3af9NyZmiw9A2kP3EeTmKp6BNgvIhG36UZgK07Me63b9iZgZ156mGeikTA9/XFe9FgjbioUfxBtD9EXS7Jpb/aLTdZ3HmN+8zQuaq3LY8+Km2svaqG6ItgV7HtdD7yxQOXUIHsVyseA74nIS8AK4AvAh4B/EpEX3c9356WHeWbN0lZfaMRtEtMfXOfKCbNdVj+USPLkayeItocRsUyEk6Wm0tGITzWpmJd09/vQAwdQ1S2qukpVL1fVt6lqt6r+VlWvVNUrVPVqVX0+353NB021VbxhwQzP7/yxpJoH7gOmV1fwxkXNWS+rf253N/2xJB3LgvnY7yc6IiFeP97H3hN9XndlUvT0x5leXVFQR8wsBs5j80sHejnuoUY8lkhSbQbcF0Tbw+w4eiYrOeH6zmNUVZRx7UWtBehZcZNOKub10/Bk6RmIFVRCCGbAgbMXzkYPV2rGkikqy+0R3A9EM7mrx78e1nUe4+pFzVaNPge0tdbR1lLr+dPwZOkpcCZCMAMOwKVzGmidXu3pnT9uIRTfsGSYnPBC7D/Zz2tdfRkHwJg60UiYp14PZsrZnv5YQVdhghlw4GzK2Y07vUk5m0wpyZRSVW5enB8YXuz4QtkJ07l10tVmjKkTjYQYjKd4+vUTXndlwvQMxGk0D9wbopEQPf1xtuzvKfi500aissJCKH4hGgk7csI9Y8sJ128/xoLmWhaZfDBnXJOREwYvDt5T4EyEYAY8ww2unHCDB/G3WNKtSG8yQt9w3eIWqsrLxsxgORh35YORkMkHc0hNZTnXLm5hg48zh45GKqUWQvGSptoqVi6Y4UnK2bQHbioU/1BXXcFVi8aWlz635yQD8WRmwtPIHR2RMLuP97HneHDkhGdiCVJaWA04mAEfQTTiyAm7ThdWTpj2wG0hj7/oiDhywoOjyAnXbe8y+WCeiAawgn1PX+EzEYIZ8BF4JSeMux64qVD8xYUMyfodx7jmohaTD+aBhS11LGqt83UBlnPpGUgnsrIQimdcMtuVExb4wsnEwM2A+4rFobSccOT1sP9kP6939RENaNKlILC2PcRTAapg3+PBMnrILhthyVBW5sjHHnn1CPdtfG3Ed5fNbeLaxS15OW9GhWIhFF8hInQsC/HTzQdHXA+vHjoFWPbBfNKxLMwDT+7hHx7extwZ0zLt06sreddV8z3NHDoa6VSyZsA95ncun81PNh/gCw9vH9HeOK2S5//nTVTkwciaB+5fbrtsNt9/Zt9518PyuQ0mH8wjVy9qJlxfzXef2nved7Obaujw2eKp3oHCF3MAM+Dn0REJs+1zt45Y0PPI1iP8+Q9f5MUDPVy5sDnn58yoUMwD9x3XLW5l6znXAxDYogNBoaaynCc+9aYRC6liiRTXfvE3bOjs8p0B7/GgnBpYDHxUairLqauuyLzeFJlJeZmwbpIFb8fj7EIeGw4/cu71UFdd4btH+GKksrxsxP/5jLoqrlvcmnWmyELS3R8reCZCMAOeFY21laxc0JS3StpxW8hjGFkRjYTYe6Kf3T7TiPd6kMgKzIBnTTQS5pWDpzh2ejDnx46ZjNAwsiLank456y8vvGfADLivSdfp27jj+DhbThxbyGMY2bGgpZaLWut8lyuluz9GUwFLqaUxi5Ell85pIFxfnZf4my2lN4zsSaecHYj5RyNuIRSfI+KknH18RxeJ5NgpRieDyQgNI3uikRCxhL9SzloIJQBEI2FODSZynnLWFvIYRva8cVEz0yrLfRMHT2citBCKz7l+aasjJ8zxhRM3D9wwsiadcnZdZxeqhS/Aci6nh7zJRAhmwCdE47RKrlwwI+cTKBkVinnghpEVHZEQ+076Q07Y2+/NKkwwAz5h1kZCvHroFMdO5U5OeDaEYotDDCMb/FTBPpMHpcCrMMEM+ITJpBjNYcbCWFKpKi+zyi6GkSXzm2u5KFTni1WZPW4elBl1PjXgItIkIg+JyHYR2SYi17rtH3PbXhWRf8xvV/3BJbMdOeGGHN75Y4mUxb8NY4JE28M8s/uk53LCHtcDb/TxJObXgP9W1WXAFcA2EekAbgeuUNVLgXvz1Edfka5YvnFn7uSEsWTSwieGMUE6ljlywqdez/3iuolwNhOhDz1wEWkE1gDfAVDVmKr2AB8BvqiqQ267988yBSIaCXN6MMHmfT05OV48oeaBG8YEScsJ85VkLlu63XJqfo2BLwK6gPtF5AUR+baI1AHtwA0i8oyIbBCRq/LaUx+RlhPmSocaS1oIxTAmSnVFOdctbmH9jmOeygm7+2PUV1fkpVbAeGRzxgpgJfAvqvoGoA/4lNveDFwDfBL4kYwyCycid4vIJhHZ1NXl/YxxLmioqeTKhbmTE8YSKVvEYxiTILoszP6TA7zuoZzwQPcAc5qmjb9hHsjGahwADqjqM+7nh3AM+gHgp+rwLJACzivRrar3qeoqVV0VChVPDcFoJMTWw6c4mgM5YSyZMg24YUyCdF3Sddu9i+DuOdFHW2utJ+ce12qo6hFgv4hE3KYbga3AfwAdACLSDlQB3s4mFJB0WstcqFFiiZQlsjKMSTC/uZbFoTo2eFTBPplS9p3op63Fm/J62VqNjwHfE5GXgBXAF4B/Ay4SkVeAHwDvUz+say0QF8+uZ2ZDdU6KPFgIxTAmT0ckzDOvn6Q/lij4uQ/3DhBLpmjzqD5qVlZDVbe4YZDLVfVtqtrtqlHeo6rLVXWlqj6W7876CREh2h7m8Z3HM7lMJkvcJjENY9JEI2FiyRRPvVb47IR7jvcDsLDFpyEUY2yikZAjJ9zbPaXjmArFMCbPVYtmUFtV7smqzN0nnMnTRX72wI3RWb20lYoymfKyeguhGMbkceSEraz3IDvh3uN91FSWMbO+pqDnTWNWYwrkSk5oHrhhTI1oJMSB7gFe6yqsnHDPiT4WNtdRVubNSmqzGlMkGgmz7fApjvROXk4YS5iM0DCmQibJXIHDKHtO9HsmIQQz4FOmY5lz4WyYghrFDLhhTI15M2pZGp5e0PSyGQmhR/FvMAM+ZSIz65nVUDOlC8dUKIYxdaKREM/uPknfUGHkhId6XAmhRxpwMAM+ZdLZCX87BTmhTWIaxtQptJxw7wlHQmgGPOBEI2FODyV4fpJyQpvENIyps6ptBnUFlBN6LSEEM+A5YfWSFkdOOIkwiqoST1o6WcOYKtUV5Vy3pHBywj2uhDBcX533c42FWY0cUF9Tyaq2GZOaAY+lK9JbQQfDmDLRSIiDPQO81nUm7+fae6KPthbvJITgpIQ1ckBHJMw//HI7X/rv7VQOG9CFLXW848p5Y+6XqUhvHrhhTJl0seMv/nI7l8xuyLRXlpfxR9e10ZjDogu7j/exJDw9Z8ebDGbAc8Sty2fx9cd28a0Nr2Xa0k9x1y1pYXbj6PmCD/YMANBc591jmGEUC3ObpnHd4hZ+s/0YvxmWYlYVairL+dCai3JynmRK2X9ygJsumZmT400WM+A5YmFLHS9/9pYRbZ1HTnPLVzeyobOLd79xwaj7pePm1y85L5W6YRiT4Psfuua8tjd/ZQPrdxzLmQFPSwgXeahAAYuB55X2mdOZ03hhjfj6zmMsm1XPrEZvcikYRinQEQnz3O7unGnE97gKlIVmwIsXEWFtJMxvdx3PxLqHc3owzqY93XQsC3vQO8MoHdZGQsSSKZ7MkUZ8j6sB91JCCBZCyTvRSIgHn93H83u7uXZxy4jvnth1nERKM2WhSol4PM6BAwcYHJx6Sbpio6amhnnz5lFZWfgq58XKqoXNGY34zTmIW6clhDMbvJ27MgOeZ1YvaaWyXFi/49h5Bnx9Zxf11RWsXDjDo955x4EDB6ivr6etrY1RamGXLKrKiRMnOHDgAIsWLfK6O0VDVUUZq5e0ssHViE/1mttz3JEQen3tWgglz0yvruCqtmbWbx8ZB1dV1nd2cf3S1pJcRj84OEhLS4vnPwC/ISK0tLTYk0ke6FgW5mDPALuOTV0jvsfVgHtN6VkOD4hGQnQePc0hVzIIsP3IaY6cGqQjUrrxbzPeo2P/L/khnXJ2qkvt0xJCL7MQpjEDXgDSiwuGV85OK1PWRkov/u0X9uzZw/Lly7Pe/oEHHuDQoUOZz1/96lfp7+/PR9eMPDC7cRqRmfVTTjl7Nguhd3nA05gBLwBLw2k54dk7//rOY1w8u4GZDSYfDAq5MODJZDLX3TImQDQS4rk9JzkzBTlhWkJoHniJICJEl4X57U5HTnh6MM7ze7vpMO/bcxKJBHfeeScXX3wx73znO+nv7+dzn/scV111FcuXL+fuu+9GVXnooYfYtGkTd955JytWrOBrX/sahw4doqOjg46ODgAeeeQRrr32WlauXMnv//7vc+aME2tta2vjr/7qr1i5ciVf/OIXWblyZeb8O3fuHPHZyC/RSJh4Unly1/FJH2PPcdeA+yAGbiqUAhFtD/H9Z/axae9JTg3EHflgCce/h/PZ/3yVrYdO5fSYl8xp4G9/79Jxt+vs7OQ73/kOq1ev5gMf+ADf/OY3+dM//VM+85nPAPDe976X//qv/+Kd73wnX//617n33ntZtWoVAF/5yldYt24dra2tHD9+nL/7u7/j17/+NXV1dXzpS1/in//5nzPHaWlpYfPmzQD8+te/ZsuWLaxYsYL777+f97///Tn9242xWdU2g+nVFazr7OLNl86a1DH2nOhnWmW55xJCMA+8YFznygk3dHaxbnsX9TUVrFzQ5HW3Sp758+ezevVqAN7znvfw29/+lnXr1nH11Vdz2WWX8dhjj/Hqq6+Oe5ynn36arVu3snr1alasWMF3v/td9u7dm/n+Xe96V+b9Bz/4Qe6//36SySQ//OEP+cM//MPc/2HGqFSWl7F6SQsbOo9NOuXsnuN9LGyp9cVkc1YeuIg0Ad8GlgMKfEBVn3K/+wvgXiCkqpN/Lily0nLCx7Yf4/RgghuWtlJRgvLB0cjGU84X5/4IRYSPfvSjbNq0ifnz53PPPfdkJelTVW6++WYefPDBUb+vqzv7uP2Od7yDz372s7zpTW/iyiuvpKWlZdR9jPwQjYT51atH2XnsDO0z6ye8/+4TfbSHJ75fPsjWgnwN+G9VXQZcAWwDEJH5wJuBffnpXnHREQmz89gZjpwatPCJT9i3bx9PPfUUAN///ve5/vrrAWhtbeXMmTM89NBDmW3r6+s5ffr0qJ+vueYannjiCXbt2gVAX18fO3bsGPWcNTU13HLLLXzkIx+x8IkHZOSE2ycuJ3QkhN4WMh7OuAZcRBqBNcB3AFQ1pqo97tdfAf4Sxys3xiE6bNKyFJfP+5FIJMI3vvENLr74Yrq7u/nIRz7Chz70IZYvX84tt9zCVVddldn2rrvu4sMf/jArVqxgYGCAu+++m1tvvZWOjg5CoRAPPPAAd9xxB5dffjnXXnst27dvH/O8d955J2VlZbz5zW8uxJ9pDGN24zSWzapnXecxBuPJCb12H+8jnlQWtXovIQSQ8eJAIrICuA/YiuN9Pw98HLgJeJOqflxE9gCrxguhrFq1Sjdt2pSDbgcTVeX6L62jcVolD3/8Bq+74ynbtm3j4osv9robnnHvvffS29vL5z//+VG/L/X/n3zzxV9uH5G7f6L88O5ruPqiwoW+ROR5VV11bns2MfAKYCXwMVV9RkS+BtyD45WP6z6IyN3A3QALFoyeE7tUEBG+eedKq75T4rz97W/ntdde47HHHvO6KyXLB29YREtdFYnUxIMH02sqWNXWnIdeTZxsPPBZwNOq2uZ+vgHHgF8GpFcxzAMOAW9U1SNjHavUPXDjLOZhXhj7/zGGM5YHPq4r6Brk/SIScZtuBDaralhV21zDfgBYeSHjbRiGYeSWbBfyfAz4nohUAa8DNnVuTJlcpPUsRiarTzZKj6wMuKpuAc5z34d935aj/hglQk1NDSdOnLCUsueQzgdeU2M5cozxsaX0hifMmzePAwcO0NU1tcxwxUi6Io9hjIcZcMMTKisrreKMYUwR07MZhmEEFDPghmEYAcUMuGEYRkAZdyFPTk8mchroPKe5FSjmLIaNQK/XncgzNobBp9jHEII9jhFVPS8FYqEnMTvPXU0kIptGW2FULIjIfap6t9f9yCc2hsGn2McQgj2OIjLqEnYLoeSf//S6A8aUsTEsDopuHM2A5xlVLbqLptSwMSwOinEcC23A78uyzQgWNobBx8bQ34w6PgU14Kp6XidGa/MrIvJvInJMRF4Z1vZlEdkuIi+JyM/c8nOj7XuriHSKyC4R+dSw9kUi8ozb/kM330ygsDG0MSwkpTiGY42PhVAmxgPAree0PQosV9XLgR3AX5+7k4iUA98A3gJcAtwhIpe4X38J+IqqLgG6gT/OT9cNlwewMQw6D2BjCOTYgI92d8v2ziYif+1u0ykit1zomF6hqhuBk+e0PaKqCffj0zi50c/ljcAuVX1dVWPAD4Dbxcni9CYgXXjxu8Db8tH3bLExDP4YQnGPY6mMYTbkzIBf4O427p3N3e7dwKU4d9Zvikj5OHdMP/IB4JcAIjJHRB522+cC+4dtd8BtawF6hl146XZPsDEEAj6GYONIEYxhtuTSAx/17kZ2d7bbgR+o6pCq7gZ2uccb65i+Q0Q+DSSA7wGo6iFVvc3bXk0YG8PgjyGU8DgW0RhmRS4N+Fh3t1HvbCLyVhH53Dj7jtXuK0TkLuB3gTt19KWtB4H5wz7Pc9tOAE0iUnFOu1fYGAZ/DKFEx7HIxjArPJvEVNVfqOpnvDp/rhCRW4G/BN6qqv1jbPYcsNSNQVbhPKL+wr3I1gHvdLd7H/DzfPc5V9gYBn8MoTjGsVTHMJcGfKy7WzZ3trH2HavdE0TkQeApICIiB0Tkj4GvA/XAoyKyRUS+5W6bib25Xs+fAr8CtgE/UtVX3cP+FfD/isgunFjcdwr6R43ExjD4YwhFPo4lMobZoao5eeHkVXkdWARUAS/iTIT8GHi3u823gI+Osu+l7vbV7v6vA+VjHTNXfbaXjWExvmwcS+eV6wvnNhwN5mvAp922i4BncSZDfgxUu+1vBT43bN9Pu/t1Am+50DHtlccLwsawKF42jqXxKmg6WcMwDCN32EpMwzCMgGIG3DAMI6BMyYCLyHwRWSciW0XkVRH5uNv+eXGSymwRkUdEZM4Y+693l+ZucV/vHG07d9t7ROR/TKW/xuiMNY7Dvv8LEVERaR1jfxtHj7nAb/EeETk4bGxGXdQiIg+IyO5h2/3ZBc51l4h8PV9/i5E9U63IkwD+QlU3i0g98LyIPAp8WVX/F4B7IXwG+PAYx7hTVUetNmEUjFHHUVW3ish84M3AvnGOYePoLWP9FsFZPn9vFsf4pKo+NP5mhl+YkgeuqodVdbP7/jSOtnKuqp4atlkdkPVMqYiEROQnIvKc+1o97OsrROQpEdkpIh+aSt+Ns4w1ju7XX8FZIDGh2W4bx8IyzhhOChGpEyd167Mi8oKIDF86P9998topIn87lfMYUyBXchagDcdLa3A//z3O0ttXgNAY+6zHkSptcV8twPeB693vFwDb3Pf34GhPp+EUYN0PzPFaxlNsr+HjiJPr4mtu+x6g1cbR/69zxvAed+xeAv4NmDHGPg8Au4eN4WXAF4D3uN834UgI64C7gMPuOE9zf+OrvP67S/GVk0lMEZkO/AT4hLret6p+WlXn4ySV+dML7H6nqq5wXyeAm4Cvi8gW4BdAg3t8gJ+r6oCqHsdZ+vrGXPTfcBg+jjiP5H+DE/7KBhtHHzDKb/FfgMXAChyj+08X2P2Tw8bwZZzQ2afcMVwP1ODcjAEeVdUTqjoA/BS4Pg9/jjEOU65KLyKVOBfM91T1p6Ns8j3gYeBvReRXwExgk6p+cIxDlgHXqOrgOeeB8x/jTcSeI84dRxG5DGfV3Yvu//08YLOIvBEnk52No88Y7beoqkeHff+vwH+57+8H3gBcKFufAO9Q1c5zznM1Noa+YKoqFMHJGbBNVf95WPvSYZvdDmwHUNVb3Lv7WD96gEeAjw071orhxxKRGhFpAaI4yWmMKTLaOKrqy6oaVtU2VW3DyT63UlWP2Dj6jwv8FmcP2+ztOOEOVPX97hheKNXqr4CPucdGRN4w7LubRaRZRKbhpKV9Ijd/iTERpuqBrwbeC7zsPmaB89j9xyISAVLAXsZWoIzGnwHfEJGX3P5tHLb/SziP3K3A51X10BT7bziMOo6q+vDYu4yLjWNhGeu3eId781ScWPifTOCYnwe+CrwkImU4MfLfdb97Fsfbnwf8HzUFkifYUnrDMIyAYisxDcMwAooZcMMwjIBiBtwwDCOg5NyAXyAnQ7OIPOqu3HpURGa47XeKkzflZRF5UkSuGHasW90cG7tE5FO57qthGEaQyfkkpitbmq3DcjLgyIzuAk6q6hddYzxDVf9KRK7DkT51i8hbgHtU9WoRKcdZ+XUzjoTtOeAOVd2a0w4bhmEElJx74Dp2TobbcRaA4P77NnebJ1W1221/GkeWBM7qvF2q+rqqxoAfuMcwDMMwyHMMXETacFZ7PQPMVNXD7ldHcFbyncsfA79038/FyZOR5gBTTM5jGIZRTEx5Kf1YnJuTwV3MBYCqqojoOdt34Bhwy6lgGIaRBXnxwMfIj3I0vazX/ffYsO0vB74N3O4mQgI4CMwfdth5bpthGIZBflQoo+ZkwMlI9z73/fuAn7vbL8DJZvZeVd0xbPvngKUiskhEqoB3u8cwDMMwyI8K5XrgceBlnFwo4ORkeAb4EU46yr3AH6jqSRH5NvAOtw0goaqr3GPdhpOLoRz4N1X9+5x21jAMI8BYLhTDMIyAYisxDcMwAooZcMMwjIBiBtwwDCOgmAE3DMMIKGbADcMwAooZcMPXiEiTiHzUfT9HRB7K47lWuNJVwwgEZsANv9MEfBRAVQ+p6jvzeK4VgBlwIzCYDtzwNSKSzkLZCewELlbV5SJyF05GyzpgKXAvUIVT2HcIuM1dKLYY+AYQAvqBD6nqdhH5feBvgSTQC9wE7AKm4aRs+AecIr5fA2qAAeD9qto5gXOvB14E1uLkHfqAqj6bj/8no0RRVXvZy7cvoA14ZZT3d+EY3Hoc49wLfNj97is4SdQAfgMsdd9fDTzmvn8ZmOu+bxp2zK8PO3cDUOG+vwn4yQTPvR74V/f9mnTf7WWvXL3ylo3QMArAOnVyzp8WkV7gP932l4HL3YyY1wE/HpYNs9r99wngARH5EU4untFoBL4rIksBBSqzPfew7R4EUNWNItIgIk2q2jO5P9cwRmIG3AgyQ8Pep4Z9TuFc22VAj6quOHdHVf2wiFwN/A7wvIhcOcrxP49jqN/u5rZfP4FzZ0517qkv8PcYxoSwSUzD75zGCVVMGFU9Bex2492IwxXu+8Wq+oyqfgbowkldfO65GjmbwviuyXWfd7nnux7oVdXeSR7HMM7DDLjha9TJD/+EiLwCfHkSh7gT+GMReRF4lbNl+b7sFtJ+BXgSZ7JxHXCJiGwRkXcB/wj8g4i8wOSfVgfd/b+FU7DEMHKGqVAMI0+4KpT/oaqbvO6LUZyYB24YhhFQzAM3DMMIKOaBG4ZhBBQz4IZhGAHFDLhhGEZAMQNuGIYRUMyAG4ZhBBQz4IZhGAHl/weLDxxqzsPCFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hsample.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the last hours in the dataset for testing against predictions. This lets you evaluate how your model will perform on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-25 21:00:00')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_time = hourly.tail(1).index[0]\n",
    "last_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-25 18:00:00')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_time = last_time - pd.Timedelta('3 hour')\n",
    "cut_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 14:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 15:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 16:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 17:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 18:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  battery\n",
       "timestamp                                                     \n",
       "2020-02-25 14:00:00  fffaee1fbb9c96703850f64d3262e843     62.0\n",
       "2020-02-25 15:00:00  fffaee1fbb9c96703850f64d3262e843     62.0\n",
       "2020-02-25 16:00:00  fffaee1fbb9c96703850f64d3262e843     62.0\n",
       "2020-02-25 17:00:00  fffaee1fbb9c96703850f64d3262e843     64.0\n",
       "2020-02-25 18:00:00  fffaee1fbb9c96703850f64d3262e843     68.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = hourly.loc[hourly.index <= cut_time]\n",
    "train_set.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>00134c004e33e830e5dbce3355a485b9</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>00134c004e33e830e5dbce3355a485b9</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  battery\n",
       "timestamp                                                     \n",
       "2020-02-25 19:00:00  0001495ce5f079703599a94c32dab2b0     76.0\n",
       "2020-02-25 20:00:00  0001495ce5f079703599a94c32dab2b0     76.0\n",
       "2020-02-25 21:00:00  0001495ce5f079703599a94c32dab2b0     76.0\n",
       "2020-02-25 19:00:00  00134c004e33e830e5dbce3355a485b9     76.0\n",
       "2020-02-25 20:00:00  00134c004e33e830e5dbce3355a485b9     76.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = hourly.loc[hourly.index > cut_time]\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = train_set[train_set[\"device_id\"] == sample_device_id][\"battery\"]\n",
    "sample_test = test_set[test_set[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2020-02-25 14:00:00    64.0\n",
       "2020-02-25 15:00:00    64.0\n",
       "2020-02-25 16:00:00    64.0\n",
       "2020-02-25 17:00:00    66.0\n",
       "2020-02-25 18:00:00    70.0\n",
       "Name: battery, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 22:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  battery\n",
       "timestamp                                                     \n",
       "2020-02-25 19:00:00  8e4a851ed2317a249a0903f29d894361     76.0\n",
       "2020-02-25 20:00:00  8e4a851ed2317a249a0903f29d894361     75.0\n",
       "2020-02-25 21:00:00  8e4a851ed2317a249a0903f29d894361     75.0\n",
       "2020-02-25 22:00:00  8e4a851ed2317a249a0903f29d894361     75.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='timestamp'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sample_train.plot()\n",
    "sample_test.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Data Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data from pandas DataFrame to the expeted JSON Lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "def df_to_tss(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df[\"timeindex\"] = df.index\n",
    "    cats = {}\n",
    "    tss = {}\n",
    "    for index, row in df.iterrows():\n",
    "        target = row[\"battery\"]\n",
    "        if not(math.isnan(target)):\n",
    "            identity = row[\"device_id\"]\n",
    "            cat = cats.get(identity)\n",
    "            if not cat:\n",
    "                cat = len(cats)\n",
    "                start = str(row[\"timeindex\"])\n",
    "                ts = {\n",
    "                    \"start\": start,\n",
    "                    \"cat\": [cat],\n",
    "                    \"target\": [],\n",
    "                }\n",
    "                cats[identity] = cat\n",
    "                tss[cat] = ts\n",
    "            ts = tss.get(cat)\n",
    "            ts[\"target\"].append(target)\n",
    "    return tss\n",
    "\n",
    "def tss_to_jsonl(tss):  \n",
    "    result = \"\"\n",
    "    for key, value in tss.items():\n",
    "        jsonll = json.dumps(value)\n",
    "        result += jsonll\n",
    "        result += \"\\n\"\n",
    "    return result[:-1]\n",
    "\n",
    "def df_to_jsonl(dataframe):\n",
    "    return tss_to_jsonl(df_to_tss(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014468669891357422\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [0], \"target\": [75.0]}\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [1], \"target\": [76.0, 75.0, 75.0, 74.0, 74.0, 75.0, 75.0, 75.0, 73.0, 72.0, 71.0, 71.0, 70.0, 69.0, 69.0, 68.0, 68.0, 67.0, 66.0, 66.0, 65.0, 65.0, 64.0, 64.0, 63.0, 64.0, 65.0, 69.0]}\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [2], \"target\": [75.0, 75.0, 75.0, 74.0, 74.0, 75.0, 75.0, 75.0, 73.0, 72.0, 71.0, 71.0, 70.0, 69.0, 68.0, 68.0, 67.0, 67.0, 66.0, 66.0, 65.0, 64.0, 64.0, 63.0, 63.0, 63.0, 65.0, 68.0]}\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [3], \"target\": [76.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 73.0, 72.0, 72.0, 71.0, 70.0, 70.0, 69.0, 69.0]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "jsonl = df_to_jsonl(train_set.head(100))\n",
    "elapsed = time.time() - start\n",
    "print(elapsed)\n",
    "print(jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.3093159198761\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_tss = df_to_tss(train_set)\n",
    "train_jsonl = tss_to_jsonl(train_tss)\n",
    "\n",
    "test_tss = df_to_tss(test_set)\n",
    "test_jsonl = tss_to_jsonl(test_tss)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the json lines files locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./mt-battery-deepar/input/train.json', './mt-battery-deepar/input/test.json')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "prefix = \"mt-battery-deepar\"\n",
    "input_path = \"./{}/input\".format(prefix)\n",
    "\n",
    "train_path = \"{}/train.json\".format(input_path)\n",
    "test_path = \"{}/test.json\".format(input_path)\n",
    "(train_path,test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(input_path, ignore_errors=True)\n",
    "pathlib.Path(input_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, \"w\") as text_file:\n",
    "    print(train_jsonl, file=text_file)\n",
    "\n",
    "with open(test_path, \"w\") as text_file:\n",
    "    print(test_jsonl, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.0M\n",
      "9723287670420738316 drwxr-xr-x 2 root root 6.0K May 11 07:02 .\n",
      "7836241304386504013 drwxr-xr-x 3 root root 6.0K May 11 07:02 ..\n",
      "7646451925326945519 -rw-r--r-- 1 root root 1.3M May 11 07:02 test.json\n",
      "8257566047298566499 -rw-r--r-- 1 root root 3.8M May 11 07:02 train.json\n"
     ]
    }
   ],
   "source": [
    "! ls -liah \"{input_path}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload train and test sets to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: mt-battery-deepar/input/test.json to s3://mt-ml-workshop-gohvk4kt/mt-battery-deepar/test.json\n",
      "upload: mt-battery-deepar/input/train.json to s3://mt-ml-workshop-gohvk4kt/mt-battery-deepar/train.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync \"{input_path}/\" \"s3://{bucket}/{prefix}/\" --delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-11 07:02:44    1325499 test.json\n",
      "2021-05-11 07:02:44    3906490 train.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls \"s3://{bucket}/{prefix}/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 's3://mt-ml-workshop-gohvk4kt/mt-battery-deepar/train.json',\n",
       " 'test': 's3://mt-ml-workshop-gohvk4kt/mt-battery-deepar/test.json'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_input = {\n",
    "    \"train\": \"s3://{}/{}/train.json\".format(bucket,prefix),\n",
    "    \"test\": \"s3://{}/{}/test.json\".format(bucket,prefix)\n",
    "}\n",
    "dar_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different [ML instance types](https://aws.amazon.com/sagemaker/pricing/instance-types/) in training lets you control how efficiently models learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"You can train DeepAR on both GPU and CPU instances and in both single and multi-machine settings. We recommend starting with a single CPU instance (for example, ml.c4.2xlarge or ml.c4.4xlarge), and switching to GPU instances and multiple machines only when necessary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_instance_type='ml.c5.2xlarge' #Estimated Training Time: 10m\n",
    "train_instance_type='ml.m5.large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'522234722520.dkr.ecr.us-east-1.amazonaws.com/forecasting-deepar:1'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "dar_image_name = sagemaker.image_uris.retrieve('forecasting-deepar', boto3.Session().region_name)\n",
    "# dar_image_name = get_image_uri(boto3.Session().region_name, 'forecasting-deepar')\n",
    "dar_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "dar_estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_uri=dar_image_name,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=train_instance_type,\n",
    "    base_job_name=prefix,\n",
    "    output_path=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 'H'\n",
    "prediction_length = 4\n",
    "context_length = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dar_hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"num_cells\": \"40\",\n",
    "    \"num_layers\": \"3\",\n",
    "    \"likelihood\": \"gaussian\",\n",
    "    \"epochs\": \"20\",\n",
    "    \"mini_batch_size\": \"32\",\n",
    "    \"learning_rate\": \"0.001\",\n",
    "    \"dropout_rate\": \"0.05\",\n",
    "    \"early_stopping_patience\": \"10\",\n",
    "    \"cardinality\": \"auto\",\n",
    "    \"num_dynamic_feat\":\"ignore\"\n",
    "}\n",
    "dar_estimator.set_hyperparameters(**dar_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-11 07:10:08 Starting - Starting the training job...\n",
      "2021-05-11 07:10:10 Starting - Launching requested ML instancesProfilerReport-1620717008: InProgress\n",
      ".........\n",
      "2021-05-11 07:12:07 Starting - Preparing the instances for training......\n",
      "2021-05-11 07:13:07 Downloading - Downloading input data\n",
      "2021-05-11 07:13:07 Training - Downloading the training image.....\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] Reading default configuration from /opt/amazon/lib/python3.6/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'prediction_length': '4', 'dropout_rate': '0.05', 'time_freq': 'H', 'context_length': '12', 'cardinality': 'auto', 'early_stopping_patience': '10', 'num_dynamic_feat': 'ignore', 'num_cells': '40', 'likelihood': 'gaussian', 'num_layers': '3', 'epochs': '20', 'learning_rate': '0.001', 'mini_batch_size': '32'}\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.05', 'early_stopping_patience': '10', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'gaussian', 'mini_batch_size': '32', 'num_cells': '40', 'num_dynamic_feat': 'ignore', 'num_eval_samples': '100', 'num_layers': '3', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'prediction_length': '4', 'time_freq': 'H', 'context_length': '12', 'epochs': '20'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] [num_dynamic_feat=ignore] Not using any `dynamic_feat` feature that may be in the data.\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] random_seed is None\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] [cardinality=auto] Inferred value of cardinality=[16945] from dataset.\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] Training set statistics:\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] Integer time series\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] number of time series: 16945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] number of observations: 480294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] mean target length: 28.344290351136028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] min/mean/max target: 1.0/69.71937396677868/100.0\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] mean abs(target): 69.71937396677868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] contains missing values: no\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] Test set statistics:\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] Integer time series\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] number of time series: 16826\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] number of observations: 51669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] mean target length: 3.070783311541662\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] min/mean/max target: 13.0/75.99527763262304/100.0\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] mean abs(target): 75.99527763262304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] contains missing values: no\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] #memory_usage::<batchbuffer> = 0.2696990966796875 mb\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] nvidia-smi took: 0.025206327438354492 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717230.602632, \"EndTime\": 1620717230.6990495, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 92.74125099182129, \"count\": 1, \"min\": 92.74125099182129, \"max\": 92.74125099182129}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] #memory_usage::<model> = 5 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717230.7003257, \"EndTime\": 1620717230.8314598, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 228.66511344909668, \"count\": 1, \"min\": 228.66511344909668, \"max\": 228.66511344909668}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[0] avg_epoch_loss=4.792031\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=4.7920308113098145\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[5] avg_epoch_loss=4.253761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=4.253761331240336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch [5]#011Speed: 1201.89 samples/sec#011loss=4.253761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[10] avg_epoch_loss=4.123760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.9677584648132322\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch [10]#011Speed: 728.68 samples/sec#011loss=3.967758\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[15] avg_epoch_loss=3.973623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=15 train loss <loss>=3.643320178985596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch [15]#011Speed: 1320.82 samples/sec#011loss=3.643320\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[20] avg_epoch_loss=3.839406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=20 train loss <loss>=3.4099145412445067\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch [20]#011Speed: 815.25 samples/sec#011loss=3.409915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[25] avg_epoch_loss=3.690249\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=25 train loss <loss>=3.063789129257202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch [25]#011Speed: 1329.97 samples/sec#011loss=3.063789\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[30] avg_epoch_loss=3.546492\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=30 train loss <loss>=2.798953056335449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch [30]#011Speed: 841.68 samples/sec#011loss=2.798953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch[35] avg_epoch_loss=3.404605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=35 train loss <loss>=2.5249051570892336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch [35]#011Speed: 1331.16 samples/sec#011loss=2.524905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch[40] avg_epoch_loss=3.278701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=40 train loss <loss>=2.3721914768218992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch [40]#011Speed: 810.79 samples/sec#011loss=2.372191\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch[45] avg_epoch_loss=3.159435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=45 train loss <loss>=2.1814605712890627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch [45]#011Speed: 1247.77 samples/sec#011loss=2.181461\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch[50] avg_epoch_loss=3.077431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=50 train loss <loss>=2.3229851722717285\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch [50]#011Speed: 697.59 samples/sec#011loss=2.322985\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch[55] avg_epoch_loss=3.009260\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=55 train loss <loss>=2.31392297744751\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch [55]#011Speed: 901.37 samples/sec#011loss=2.313923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch[60] avg_epoch_loss=2.938695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=60 train loss <loss>=2.148361015319824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch [60]#011Speed: 527.44 samples/sec#011loss=2.148361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch[65] avg_epoch_loss=2.872689\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=65 train loss <loss>=2.0674139499664306\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch [65]#011Speed: 841.05 samples/sec#011loss=2.067414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch[70] avg_epoch_loss=2.812543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=70 train loss <loss>=2.0186251640319823\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch [70]#011Speed: 518.24 samples/sec#011loss=2.018625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch[75] avg_epoch_loss=2.761023\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=75 train loss <loss>=2.029439687728882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch [75]#011Speed: 817.20 samples/sec#011loss=2.029440\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch[80] avg_epoch_loss=2.719674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=80 train loss <loss>=2.0911667108535767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch [80]#011Speed: 516.36 samples/sec#011loss=2.091167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch[85] avg_epoch_loss=2.674815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=85 train loss <loss>=1.9481003046035767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch [85]#011Speed: 885.15 samples/sec#011loss=1.948100\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch[90] avg_epoch_loss=2.641667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=90 train loss <loss>=2.071513295173645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch [90]#011Speed: 515.84 samples/sec#011loss=2.071513\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch[95] avg_epoch_loss=2.600862\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=95 train loss <loss>=1.858212447166443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch [95]#011Speed: 813.25 samples/sec#011loss=1.858212\u001b[0m\n",
      "\n",
      "2021-05-11 07:14:07 Training - Training image download completed. Training in progress.\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch[100] avg_epoch_loss=2.562705\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=100 train loss <loss>=1.8300957918167113\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch [100]#011Speed: 511.65 samples/sec#011loss=1.830096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch[105] avg_epoch_loss=2.526629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=105 train loss <loss>=1.7978889703750611\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch [105]#011Speed: 1362.47 samples/sec#011loss=1.797889\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch[110] avg_epoch_loss=2.511212\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=110 train loss <loss>=2.184369373321533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch [110]#011Speed: 785.12 samples/sec#011loss=2.184369\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch[115] avg_epoch_loss=2.488637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=115 train loss <loss>=1.9874833822250366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch [115]#011Speed: 1343.38 samples/sec#011loss=1.987483\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch[120] avg_epoch_loss=2.466922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=120 train loss <loss>=1.9631194591522216\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch [120]#011Speed: 720.48 samples/sec#011loss=1.963119\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch[125] avg_epoch_loss=2.438233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=125 train loss <loss>=1.7439706325531006\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch [125]#011Speed: 862.72 samples/sec#011loss=1.743971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch[130] avg_epoch_loss=2.410829\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=130 train loss <loss>=1.7202335834503173\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch [130]#011Speed: 791.22 samples/sec#011loss=1.720234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch[135] avg_epoch_loss=2.432928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=135 train loss <loss>=3.0119275093078612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch [135]#011Speed: 1344.18 samples/sec#011loss=3.011928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch[140] avg_epoch_loss=2.414597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=140 train loss <loss>=1.9160011529922485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch [140]#011Speed: 769.37 samples/sec#011loss=1.916001\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch[145] avg_epoch_loss=2.396969\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=145 train loss <loss>=1.8998450994491578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch [145]#011Speed: 1272.23 samples/sec#011loss=1.899845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch[150] avg_epoch_loss=2.377983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=150 train loss <loss>=1.8236025333404542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch [150]#011Speed: 864.56 samples/sec#011loss=1.823603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch[155] avg_epoch_loss=2.362726\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=155 train loss <loss>=1.9019527196884156\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch [155]#011Speed: 1251.36 samples/sec#011loss=1.901953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch[160] avg_epoch_loss=2.344710\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=160 train loss <loss>=1.7826276302337647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch [160]#011Speed: 809.09 samples/sec#011loss=1.782628\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch[165] avg_epoch_loss=2.327062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=165 train loss <loss>=1.7587870836257935\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch [165]#011Speed: 1193.38 samples/sec#011loss=1.758787\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch[170] avg_epoch_loss=2.309988\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=170 train loss <loss>=1.7431488275527953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch [170]#011Speed: 820.59 samples/sec#011loss=1.743149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch[175] avg_epoch_loss=2.288556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=175 train loss <loss>=1.5555837869644165\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch [175]#011Speed: 1353.68 samples/sec#011loss=1.555584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch[180] avg_epoch_loss=2.306567\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=180 train loss <loss>=2.9405394315719606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch [180]#011Speed: 860.42 samples/sec#011loss=2.940539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch[185] avg_epoch_loss=2.295510\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=185 train loss <loss>=1.895247459411621\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch [185]#011Speed: 1336.40 samples/sec#011loss=1.895247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch[190] avg_epoch_loss=2.284570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=190 train loss <loss>=1.8776071548461915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch [190]#011Speed: 838.72 samples/sec#011loss=1.877607\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch[195] avg_epoch_loss=2.275550\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=195 train loss <loss>=1.930997657775879\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch [195]#011Speed: 1346.31 samples/sec#011loss=1.930998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch[200] avg_epoch_loss=2.265024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=200 train loss <loss>=1.8523955345153809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch [200]#011Speed: 843.40 samples/sec#011loss=1.852396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch[205] avg_epoch_loss=2.255457\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=205 train loss <loss>=1.8708555221557617\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch [205]#011Speed: 1256.21 samples/sec#011loss=1.870856\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch[210] avg_epoch_loss=2.246064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=210 train loss <loss>=1.8590858459472657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch [210]#011Speed: 859.79 samples/sec#011loss=1.859086\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch[215] avg_epoch_loss=2.233850\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=215 train loss <loss>=1.7184139966964722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch [215]#011Speed: 1344.48 samples/sec#011loss=1.718414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[220] avg_epoch_loss=2.220490\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=220 train loss <loss>=1.6433300256729126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [220]#011Speed: 867.59 samples/sec#011loss=1.643330\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[225] avg_epoch_loss=2.208736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=225 train loss <loss>=1.6892305850982665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [225]#011Speed: 1306.86 samples/sec#011loss=1.689231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[230] avg_epoch_loss=2.196277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=230 train loss <loss>=1.6331115007400512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [230]#011Speed: 788.98 samples/sec#011loss=1.633112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[235] avg_epoch_loss=2.204023\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=235 train loss <loss>=2.5619029998779297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [235]#011Speed: 1216.92 samples/sec#011loss=2.561903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[240] avg_epoch_loss=2.193974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=240 train loss <loss>=1.7196455717086792\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [240]#011Speed: 844.29 samples/sec#011loss=1.719646\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[245] avg_epoch_loss=2.183490\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=245 train loss <loss>=1.6781803846359253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [245]#011Speed: 1355.60 samples/sec#011loss=1.678180\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[250] avg_epoch_loss=2.173952\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=250 train loss <loss>=1.704652762413025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [250]#011Speed: 854.20 samples/sec#011loss=1.704653\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch[255] avg_epoch_loss=2.163006\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=255 train loss <loss>=1.6135135889053345\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch [255]#011Speed: 1275.18 samples/sec#011loss=1.613514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch[260] avg_epoch_loss=2.156838\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=260 train loss <loss>=1.8410661697387696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch [260]#011Speed: 816.35 samples/sec#011loss=1.841066\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch[265] avg_epoch_loss=2.146766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=265 train loss <loss>=1.6210114002227782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch [265]#011Speed: 1344.68 samples/sec#011loss=1.621011\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch[270] avg_epoch_loss=2.137026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=270 train loss <loss>=1.618810272216797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch [270]#011Speed: 806.13 samples/sec#011loss=1.618810\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch[275] avg_epoch_loss=2.127519\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=275 train loss <loss>=1.6122395038604735\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch [275]#011Speed: 1248.92 samples/sec#011loss=1.612240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch[280] avg_epoch_loss=2.117771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=280 train loss <loss>=1.5796887874603271\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch [280]#011Speed: 697.04 samples/sec#011loss=1.579689\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch[285] avg_epoch_loss=2.106786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=285 train loss <loss>=1.4894686698913575\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch [285]#011Speed: 780.22 samples/sec#011loss=1.489469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch[290] avg_epoch_loss=2.096892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=290 train loss <loss>=1.530920386314392\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch [290]#011Speed: 535.99 samples/sec#011loss=1.530920\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch[295] avg_epoch_loss=2.086427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=295 train loss <loss>=1.4773511648178101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch [295]#011Speed: 1032.97 samples/sec#011loss=1.477351\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch[300] avg_epoch_loss=2.080882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=300 train loss <loss>=1.7526219606399536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch [300]#011Speed: 808.39 samples/sec#011loss=1.752622\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch[305] avg_epoch_loss=2.073094\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=305 train loss <loss>=1.604297137260437\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch [305]#011Speed: 572.84 samples/sec#011loss=1.604297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch[310] avg_epoch_loss=2.066571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=310 train loss <loss>=1.6673192739486695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch [310]#011Speed: 530.16 samples/sec#011loss=1.667319\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch[315] avg_epoch_loss=2.061965\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=315 train loss <loss>=1.7755264520645142\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch [315]#011Speed: 798.05 samples/sec#011loss=1.775526\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch[320] avg_epoch_loss=2.136728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=320 train loss <loss>=6.861711764335633\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch [320]#011Speed: 833.18 samples/sec#011loss=6.861712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch[325] avg_epoch_loss=2.130938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=325 train loss <loss>=1.7592074871063232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch [325]#011Speed: 1224.07 samples/sec#011loss=1.759207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch[330] avg_epoch_loss=2.127709\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=330 train loss <loss>=1.9172049760818481\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch [330]#011Speed: 823.47 samples/sec#011loss=1.917205\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch[335] avg_epoch_loss=2.126024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=335 train loss <loss>=2.01447536945343\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch [335]#011Speed: 1367.52 samples/sec#011loss=2.014475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch[340] avg_epoch_loss=2.123646\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=340 train loss <loss>=1.9638386249542237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch [340]#011Speed: 818.07 samples/sec#011loss=1.963839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch[345] avg_epoch_loss=2.119917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=345 train loss <loss>=1.8656052827835083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch [345]#011Speed: 1253.32 samples/sec#011loss=1.865605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch[350] avg_epoch_loss=2.116175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=350 train loss <loss>=1.8572309970855714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch [350]#011Speed: 850.90 samples/sec#011loss=1.857231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch[355] avg_epoch_loss=2.112205\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=355 train loss <loss>=1.8334973573684692\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch [355]#011Speed: 1327.34 samples/sec#011loss=1.833497\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch[360] avg_epoch_loss=2.107910\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=360 train loss <loss>=1.802099919319153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch [360]#011Speed: 825.78 samples/sec#011loss=1.802100\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch[365] avg_epoch_loss=2.102364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=365 train loss <loss>=1.7019759893417359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch [365]#011Speed: 871.12 samples/sec#011loss=1.701976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch[370] avg_epoch_loss=2.095232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=370 train loss <loss>=1.5731580018997193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch [370]#011Speed: 487.62 samples/sec#011loss=1.573158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch[375] avg_epoch_loss=2.089086\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=375 train loss <loss>=1.6330088138580323\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch [375]#011Speed: 803.01 samples/sec#011loss=1.633009\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch[380] avg_epoch_loss=2.083411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=380 train loss <loss>=1.6566533327102662\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch [380]#011Speed: 550.58 samples/sec#011loss=1.656653\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch[385] avg_epoch_loss=2.075975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=385 train loss <loss>=1.5094160079956054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch [385]#011Speed: 1165.64 samples/sec#011loss=1.509416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch[390] avg_epoch_loss=2.068005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=390 train loss <loss>=1.4526726245880126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch [390]#011Speed: 857.11 samples/sec#011loss=1.452673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch[395] avg_epoch_loss=2.061293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=395 train loss <loss>=1.5364232540130616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch [395]#011Speed: 1363.51 samples/sec#011loss=1.536423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch[400] avg_epoch_loss=2.054233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=400 train loss <loss>=1.4951149463653564\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch [400]#011Speed: 510.48 samples/sec#011loss=1.495115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch[405] avg_epoch_loss=2.046635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=405 train loss <loss>=1.4372469186782837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch [405]#011Speed: 803.92 samples/sec#011loss=1.437247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch[410] avg_epoch_loss=2.043941\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=410 train loss <loss>=1.8252071619033814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch [410]#011Speed: 506.29 samples/sec#011loss=1.825207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch[415] avg_epoch_loss=2.042814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=415 train loss <loss>=1.9501867055892945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch [415]#011Speed: 581.33 samples/sec#011loss=1.950187\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch[420] avg_epoch_loss=2.038569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=420 train loss <loss>=1.685364055633545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch [420]#011Speed: 437.04 samples/sec#011loss=1.685364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] Epoch[0] Batch[425] avg_epoch_loss=2.035098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=425 train loss <loss>=1.7428502559661865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] Epoch[0] Batch [425]#011Speed: 639.74 samples/sec#011loss=1.742850\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] Epoch[0] Batch[430] avg_epoch_loss=2.030740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=430 train loss <loss>=1.6594168901443482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] Epoch[0] Batch [430]#011Speed: 416.75 samples/sec#011loss=1.659417\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] Epoch[0] Batch[435] avg_epoch_loss=2.026942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=435 train loss <loss>=1.6995966196060182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] Epoch[0] Batch [435]#011Speed: 714.23 samples/sec#011loss=1.699597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch[440] avg_epoch_loss=2.023175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=440 train loss <loss>=1.6946352481842042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch [440]#011Speed: 677.22 samples/sec#011loss=1.694635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch[445] avg_epoch_loss=2.018560\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=445 train loss <loss>=1.6115394592285157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch [445]#011Speed: 1224.38 samples/sec#011loss=1.611539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch[450] avg_epoch_loss=2.012465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=450 train loss <loss>=1.4687692642211914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch [450]#011Speed: 856.14 samples/sec#011loss=1.468769\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch[455] avg_epoch_loss=2.007270\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=455 train loss <loss>=1.5387062549591064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch [455]#011Speed: 1310.53 samples/sec#011loss=1.538706\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch[460] avg_epoch_loss=2.001341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=460 train loss <loss>=1.4606382608413697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch [460]#011Speed: 813.20 samples/sec#011loss=1.460638\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch[465] avg_epoch_loss=1.996224\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=465 train loss <loss>=1.5244105577468872\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch [465]#011Speed: 1293.00 samples/sec#011loss=1.524411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch[470] avg_epoch_loss=1.991548\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=470 train loss <loss>=1.5557206630706788\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch [470]#011Speed: 719.64 samples/sec#011loss=1.555721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch[475] avg_epoch_loss=1.985435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=475 train loss <loss>=1.4095767498016358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch [475]#011Speed: 1285.00 samples/sec#011loss=1.409577\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch[480] avg_epoch_loss=1.978741\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=480 train loss <loss>=1.3414634466171265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch [480]#011Speed: 814.65 samples/sec#011loss=1.341463\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch[485] avg_epoch_loss=1.972810\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=485 train loss <loss>=1.4023170709609984\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch [485]#011Speed: 1333.74 samples/sec#011loss=1.402317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch[490] avg_epoch_loss=1.969359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=490 train loss <loss>=1.633875799179077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch [490]#011Speed: 777.01 samples/sec#011loss=1.633876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch[495] avg_epoch_loss=1.965981\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=495 train loss <loss>=1.6342413425445557\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch [495]#011Speed: 1310.91 samples/sec#011loss=1.634241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch[500] avg_epoch_loss=1.959264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=500 train loss <loss>=1.2930211544036865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch [500]#011Speed: 789.81 samples/sec#011loss=1.293021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch[505] avg_epoch_loss=1.956631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=505 train loss <loss>=1.692733359336853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch [505]#011Speed: 1331.66 samples/sec#011loss=1.692733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch[510] avg_epoch_loss=1.950971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=510 train loss <loss>=1.3782354593276978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch [510]#011Speed: 817.68 samples/sec#011loss=1.378235\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch[515] avg_epoch_loss=1.945114\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=515 train loss <loss>=1.3465110301971435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch [515]#011Speed: 1342.75 samples/sec#011loss=1.346511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch[520] avg_epoch_loss=1.939237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=520 train loss <loss>=1.3327265739440919\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch [520]#011Speed: 773.21 samples/sec#011loss=1.332727\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch[525] avg_epoch_loss=1.935257\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=525 train loss <loss>=1.5205334186553956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch [525]#011Speed: 1352.41 samples/sec#011loss=1.520533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch[530] avg_epoch_loss=1.930956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=530 train loss <loss>=1.4785178661346436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch [530]#011Speed: 842.52 samples/sec#011loss=1.478518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch[535] avg_epoch_loss=1.927342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=535 train loss <loss>=1.5435444593429566\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch [535]#011Speed: 1305.92 samples/sec#011loss=1.543544\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch[540] avg_epoch_loss=1.923324\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=540 train loss <loss>=1.4925101041793822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch [540]#011Speed: 556.04 samples/sec#011loss=1.492510\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch[545] avg_epoch_loss=1.918348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=545 train loss <loss>=1.3799579620361329\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch [545]#011Speed: 865.52 samples/sec#011loss=1.379958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch[550] avg_epoch_loss=1.913447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=550 train loss <loss>=1.3782785177230834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch [550]#011Speed: 575.87 samples/sec#011loss=1.378279\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.6/lib/python3.6/contextlib.py:99: DeprecationWarning: generator 'local_timer' raised StopIteration\n",
      "  self.gen.throw(type, value, traceback)\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] processed a total of 17673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717230.8316145, \"EndTime\": 1620717251.928023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"update.time\": {\"sum\": 21096.277713775635, \"count\": 1, \"min\": 21096.277713775635, \"max\": 21096.277713775635}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=837.7220895257026 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, train loss <loss>=1.9114706076506465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_1425e237-4baf-4d26-94fa-48405fb2084c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717251.928198, \"EndTime\": 1620717251.9401839, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.311769485473633, \"count\": 1, \"min\": 11.311769485473633, \"max\": 11.311769485473633}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch[0] avg_epoch_loss=1.369514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=1.3695135116577148\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch[5] avg_epoch_loss=1.263467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=1.263467252254486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch [5]#011Speed: 1315.05 samples/sec#011loss=1.263467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch[10] avg_epoch_loss=1.302598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=1.3495543003082275\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch [10]#011Speed: 799.28 samples/sec#011loss=1.349554\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch[15] avg_epoch_loss=1.343551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=15 train loss <loss>=1.4336491346359252\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch [15]#011Speed: 1335.10 samples/sec#011loss=1.433649\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch[20] avg_epoch_loss=1.387540\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=20 train loss <loss>=1.5283031463623047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch [20]#011Speed: 841.38 samples/sec#011loss=1.528303\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch[25] avg_epoch_loss=1.399762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=25 train loss <loss>=1.4510964393615722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch [25]#011Speed: 1167.03 samples/sec#011loss=1.451096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[30] avg_epoch_loss=1.408250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=30 train loss <loss>=1.4523878812789917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [30]#011Speed: 841.17 samples/sec#011loss=1.452388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[35] avg_epoch_loss=1.463595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=35 train loss <loss>=1.8067344427108765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [35]#011Speed: 1358.36 samples/sec#011loss=1.806734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[40] avg_epoch_loss=1.493730\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=40 train loss <loss>=1.7107026338577271\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [40]#011Speed: 850.72 samples/sec#011loss=1.710703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[45] avg_epoch_loss=1.515551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=45 train loss <loss>=1.6944804906845092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [45]#011Speed: 1367.47 samples/sec#011loss=1.694480\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[50] avg_epoch_loss=1.521246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=50 train loss <loss>=1.5736440420150757\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [50]#011Speed: 849.82 samples/sec#011loss=1.573644\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[55] avg_epoch_loss=1.514277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=55 train loss <loss>=1.4431875467300415\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [55]#011Speed: 1271.46 samples/sec#011loss=1.443188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[60] avg_epoch_loss=1.518559\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=60 train loss <loss>=1.5665199041366578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [60]#011Speed: 840.61 samples/sec#011loss=1.566520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch[65] avg_epoch_loss=1.531600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=65 train loss <loss>=1.69069664478302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch [65]#011Speed: 1314.84 samples/sec#011loss=1.690697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch[70] avg_epoch_loss=1.530597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=70 train loss <loss>=1.5173661947250365\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch [70]#011Speed: 829.08 samples/sec#011loss=1.517366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch[75] avg_epoch_loss=1.532687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=75 train loss <loss>=1.5623605012893678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch [75]#011Speed: 1278.62 samples/sec#011loss=1.562361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch[80] avg_epoch_loss=1.533323\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=80 train loss <loss>=1.542988395690918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch [80]#011Speed: 844.37 samples/sec#011loss=1.542988\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch[85] avg_epoch_loss=1.528975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=85 train loss <loss>=1.458538866043091\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch [85]#011Speed: 1337.46 samples/sec#011loss=1.458539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch[90] avg_epoch_loss=1.577565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=90 train loss <loss>=2.4133167266845703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch [90]#011Speed: 796.70 samples/sec#011loss=2.413317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[95] avg_epoch_loss=1.570816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=95 train loss <loss>=1.447972559928894\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [95]#011Speed: 1349.40 samples/sec#011loss=1.447973\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[100] avg_epoch_loss=1.563253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=100 train loss <loss>=1.4180488348007203\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [100]#011Speed: 848.43 samples/sec#011loss=1.418049\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[105] avg_epoch_loss=1.555073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=105 train loss <loss>=1.3898352146148683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [105]#011Speed: 1275.37 samples/sec#011loss=1.389835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[110] avg_epoch_loss=1.561493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=110 train loss <loss>=1.6975998878479004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [110]#011Speed: 827.82 samples/sec#011loss=1.697600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[115] avg_epoch_loss=1.556779\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=115 train loss <loss>=1.452137565612793\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [115]#011Speed: 1366.56 samples/sec#011loss=1.452138\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[120] avg_epoch_loss=1.550063\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=120 train loss <loss>=1.3942543268203735\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [120]#011Speed: 773.64 samples/sec#011loss=1.394254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[125] avg_epoch_loss=1.546719\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=125 train loss <loss>=1.4657721281051637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [125]#011Speed: 1290.12 samples/sec#011loss=1.465772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch[130] avg_epoch_loss=1.539504\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=130 train loss <loss>=1.3576850891113281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch [130]#011Speed: 820.80 samples/sec#011loss=1.357685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch[135] avg_epoch_loss=1.532305\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=135 train loss <loss>=1.3436964511871339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch [135]#011Speed: 1371.94 samples/sec#011loss=1.343696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch[140] avg_epoch_loss=1.523429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=140 train loss <loss>=1.28200044631958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch [140]#011Speed: 819.91 samples/sec#011loss=1.282000\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch[145] avg_epoch_loss=1.524857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=145 train loss <loss>=1.5651230096817017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch [145]#011Speed: 1332.60 samples/sec#011loss=1.565123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch[150] avg_epoch_loss=1.521715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=150 train loss <loss>=1.4299713373184204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch [150]#011Speed: 727.42 samples/sec#011loss=1.429971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch[155] avg_epoch_loss=1.526253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=155 train loss <loss>=1.663305926322937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch [155]#011Speed: 1031.03 samples/sec#011loss=1.663306\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch[160] avg_epoch_loss=1.526920\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=160 train loss <loss>=1.5477361917495727\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch [160]#011Speed: 625.40 samples/sec#011loss=1.547736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch[165] avg_epoch_loss=1.528751\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=165 train loss <loss>=1.5877223014831543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch [165]#011Speed: 1343.30 samples/sec#011loss=1.587722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch[170] avg_epoch_loss=1.528774\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=170 train loss <loss>=1.5295167684555053\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch [170]#011Speed: 808.53 samples/sec#011loss=1.529517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch[175] avg_epoch_loss=1.526317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=175 train loss <loss>=1.442301082611084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch [175]#011Speed: 1354.42 samples/sec#011loss=1.442301\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch[180] avg_epoch_loss=1.522830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=180 train loss <loss>=1.4000888347625733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch [180]#011Speed: 786.15 samples/sec#011loss=1.400089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch[185] avg_epoch_loss=1.523610\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=185 train loss <loss>=1.5518368482589722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch [185]#011Speed: 1318.69 samples/sec#011loss=1.551837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch[190] avg_epoch_loss=1.525922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=190 train loss <loss>=1.611915612220764\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch [190]#011Speed: 832.56 samples/sec#011loss=1.611916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch[195] avg_epoch_loss=1.535303\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=195 train loss <loss>=1.8936836481094361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch [195]#011Speed: 1363.73 samples/sec#011loss=1.893684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch[200] avg_epoch_loss=1.653113\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=200 train loss <loss>=6.271257901191712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch [200]#011Speed: 851.69 samples/sec#011loss=6.271258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch[205] avg_epoch_loss=1.657066\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=205 train loss <loss>=1.8159664869308472\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch [205]#011Speed: 1306.37 samples/sec#011loss=1.815966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch[210] avg_epoch_loss=1.662772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=210 train loss <loss>=1.8978551626205444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch [210]#011Speed: 840.91 samples/sec#011loss=1.897855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch[215] avg_epoch_loss=1.667641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=215 train loss <loss>=1.8731024503707885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch [215]#011Speed: 1243.37 samples/sec#011loss=1.873102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch[220] avg_epoch_loss=1.671303\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=220 train loss <loss>=1.8295164585113526\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch [220]#011Speed: 850.01 samples/sec#011loss=1.829516\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch[225] avg_epoch_loss=1.676344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=225 train loss <loss>=1.8991571187973022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch [225]#011Speed: 1353.20 samples/sec#011loss=1.899157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch[230] avg_epoch_loss=1.678243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=230 train loss <loss>=1.7640895605087281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch [230]#011Speed: 678.33 samples/sec#011loss=1.764090\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch[235] avg_epoch_loss=1.678691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=235 train loss <loss>=1.6993945598602296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch [235]#011Speed: 1364.86 samples/sec#011loss=1.699395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch[240] avg_epoch_loss=1.677861\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=240 train loss <loss>=1.6386559724807739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch [240]#011Speed: 862.74 samples/sec#011loss=1.638656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch[245] avg_epoch_loss=1.675647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=245 train loss <loss>=1.568963885307312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch [245]#011Speed: 1257.68 samples/sec#011loss=1.568964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch[250] avg_epoch_loss=1.670945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=250 train loss <loss>=1.4396028995513916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch [250]#011Speed: 801.01 samples/sec#011loss=1.439603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch[255] avg_epoch_loss=1.667560\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=255 train loss <loss>=1.4976226329803466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch [255]#011Speed: 1319.00 samples/sec#011loss=1.497623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch[260] avg_epoch_loss=1.662022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=260 train loss <loss>=1.3784498214721679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch [260]#011Speed: 802.18 samples/sec#011loss=1.378450\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch[265] avg_epoch_loss=1.661418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=265 train loss <loss>=1.629911518096924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch [265]#011Speed: 1363.43 samples/sec#011loss=1.629912\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch[270] avg_epoch_loss=1.661936\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=270 train loss <loss>=1.6894856929779052\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch [270]#011Speed: 850.08 samples/sec#011loss=1.689486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch[275] avg_epoch_loss=1.683916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=275 train loss <loss>=2.875211787223816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch [275]#011Speed: 1235.59 samples/sec#011loss=2.875212\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[280] avg_epoch_loss=1.679892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=280 train loss <loss>=1.457804274559021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [280]#011Speed: 828.17 samples/sec#011loss=1.457804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[285] avg_epoch_loss=1.676648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=285 train loss <loss>=1.4943412780761718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [285]#011Speed: 1353.15 samples/sec#011loss=1.494341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[290] avg_epoch_loss=1.673689\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=290 train loss <loss>=1.504419469833374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [290]#011Speed: 844.21 samples/sec#011loss=1.504419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[295] avg_epoch_loss=1.673634\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=295 train loss <loss>=1.6704499483108521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [295]#011Speed: 1320.13 samples/sec#011loss=1.670450\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[300] avg_epoch_loss=1.672054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=300 train loss <loss>=1.5784913539886474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [300]#011Speed: 855.48 samples/sec#011loss=1.578491\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[305] avg_epoch_loss=1.671022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=305 train loss <loss>=1.6088905811309815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [305]#011Speed: 1334.45 samples/sec#011loss=1.608891\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[310] avg_epoch_loss=1.667113\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=310 train loss <loss>=1.427865481376648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [310]#011Speed: 800.91 samples/sec#011loss=1.427865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch[315] avg_epoch_loss=1.664361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=315 train loss <loss>=1.4931926727294922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch [315]#011Speed: 1141.69 samples/sec#011loss=1.493193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch[320] avg_epoch_loss=1.669447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=320 train loss <loss>=1.9908847093582154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch [320]#011Speed: 692.36 samples/sec#011loss=1.990885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch[325] avg_epoch_loss=1.665821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=325 train loss <loss>=1.4330280780792237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch [325]#011Speed: 1351.89 samples/sec#011loss=1.433028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch[330] avg_epoch_loss=1.663912\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=330 train loss <loss>=1.5394382715225219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch [330]#011Speed: 847.25 samples/sec#011loss=1.539438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch[335] avg_epoch_loss=1.660347\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=335 train loss <loss>=1.4243502616882324\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch [335]#011Speed: 1328.47 samples/sec#011loss=1.424350\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch[340] avg_epoch_loss=1.655902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=340 train loss <loss>=1.3572373390197754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch [340]#011Speed: 783.35 samples/sec#011loss=1.357237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch[345] avg_epoch_loss=1.650312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=345 train loss <loss>=1.269053292274475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch [345]#011Speed: 1302.82 samples/sec#011loss=1.269053\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch[350] avg_epoch_loss=1.646858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=350 train loss <loss>=1.4078591823577882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch [350]#011Speed: 775.89 samples/sec#011loss=1.407859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch[355] avg_epoch_loss=1.642359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=355 train loss <loss>=1.3265487909317017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch [355]#011Speed: 1361.88 samples/sec#011loss=1.326549\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch[360] avg_epoch_loss=1.641760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=360 train loss <loss>=1.5990564584732057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch [360]#011Speed: 847.95 samples/sec#011loss=1.599056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch[365] avg_epoch_loss=1.637926\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=365 train loss <loss>=1.361120581626892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch [365]#011Speed: 1325.73 samples/sec#011loss=1.361121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch[370] avg_epoch_loss=1.633746\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=370 train loss <loss>=1.3278100728988647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch [370]#011Speed: 801.87 samples/sec#011loss=1.327810\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch[375] avg_epoch_loss=1.628802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=375 train loss <loss>=1.2619062662124634\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch [375]#011Speed: 1317.38 samples/sec#011loss=1.261906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch[380] avg_epoch_loss=1.626597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=380 train loss <loss>=1.4608033418655395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch [380]#011Speed: 833.20 samples/sec#011loss=1.460803\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch[385] avg_epoch_loss=1.625836\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=385 train loss <loss>=1.5678786754608154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch [385]#011Speed: 1331.31 samples/sec#011loss=1.567879\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch[390] avg_epoch_loss=1.622939\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=390 train loss <loss>=1.3992878675460816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch [390]#011Speed: 825.01 samples/sec#011loss=1.399288\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch[395] avg_epoch_loss=1.622595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=395 train loss <loss>=1.5956680297851562\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch [395]#011Speed: 1353.73 samples/sec#011loss=1.595668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch[400] avg_epoch_loss=1.624224\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=400 train loss <loss>=1.7532394409179688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch [400]#011Speed: 849.83 samples/sec#011loss=1.753239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[405] avg_epoch_loss=1.623553\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=405 train loss <loss>=1.5697765350341797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [405]#011Speed: 1187.18 samples/sec#011loss=1.569777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[410] avg_epoch_loss=1.623635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=410 train loss <loss>=1.6302501678466796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [410]#011Speed: 843.81 samples/sec#011loss=1.630250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[415] avg_epoch_loss=1.622176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=415 train loss <loss>=1.5022634983062744\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [415]#011Speed: 1284.78 samples/sec#011loss=1.502263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[420] avg_epoch_loss=1.619728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=420 train loss <loss>=1.4160707473754883\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [420]#011Speed: 844.32 samples/sec#011loss=1.416071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[425] avg_epoch_loss=1.620753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=425 train loss <loss>=1.707046341896057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [425]#011Speed: 1361.08 samples/sec#011loss=1.707046\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[430] avg_epoch_loss=1.619268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=430 train loss <loss>=1.4927309513092042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [430]#011Speed: 838.08 samples/sec#011loss=1.492731\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[435] avg_epoch_loss=1.617256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=435 train loss <loss>=1.4438570976257323\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [435]#011Speed: 1222.10 samples/sec#011loss=1.443857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch[440] avg_epoch_loss=1.617207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=440 train loss <loss>=1.6128944873809814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch [440]#011Speed: 842.23 samples/sec#011loss=1.612894\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch[445] avg_epoch_loss=1.614905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=445 train loss <loss>=1.4118463039398192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch [445]#011Speed: 1335.02 samples/sec#011loss=1.411846\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch[450] avg_epoch_loss=1.612143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=450 train loss <loss>=1.3658392906188965\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch [450]#011Speed: 851.12 samples/sec#011loss=1.365839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch[455] avg_epoch_loss=1.611004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=455 train loss <loss>=1.5082474946975708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch [455]#011Speed: 1345.65 samples/sec#011loss=1.508247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch[460] avg_epoch_loss=1.612243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=460 train loss <loss>=1.7251936435699462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch [460]#011Speed: 850.68 samples/sec#011loss=1.725194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch[465] avg_epoch_loss=1.610813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=465 train loss <loss>=1.4789905786514281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch [465]#011Speed: 1358.36 samples/sec#011loss=1.478991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch[470] avg_epoch_loss=1.617401\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=470 train loss <loss>=2.2313797950744627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch [470]#011Speed: 813.40 samples/sec#011loss=2.231380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch[475] avg_epoch_loss=1.616021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=475 train loss <loss>=1.4860722541809082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch [475]#011Speed: 1352.90 samples/sec#011loss=1.486072\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch[480] avg_epoch_loss=1.616529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=480 train loss <loss>=1.6648213386535644\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch [480]#011Speed: 674.00 samples/sec#011loss=1.664821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch[485] avg_epoch_loss=1.615570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=485 train loss <loss>=1.5233737230300903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch [485]#011Speed: 1343.00 samples/sec#011loss=1.523374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch[490] avg_epoch_loss=1.613008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=490 train loss <loss>=1.363983392715454\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch [490]#011Speed: 841.79 samples/sec#011loss=1.363983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch[495] avg_epoch_loss=1.610116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=495 train loss <loss>=1.3261117458343505\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch [495]#011Speed: 1348.73 samples/sec#011loss=1.326112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch[500] avg_epoch_loss=1.608609\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=500 train loss <loss>=1.4591218471527099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch [500]#011Speed: 749.16 samples/sec#011loss=1.459122\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch[505] avg_epoch_loss=1.605476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=505 train loss <loss>=1.2915805578231812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch [505]#011Speed: 1311.71 samples/sec#011loss=1.291581\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch[510] avg_epoch_loss=1.604800\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=510 train loss <loss>=1.5363088607788087\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch [510]#011Speed: 834.31 samples/sec#011loss=1.536309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch[515] avg_epoch_loss=1.602785\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=515 train loss <loss>=1.3968477964401245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch [515]#011Speed: 1347.23 samples/sec#011loss=1.396848\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch[520] avg_epoch_loss=1.600252\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=520 train loss <loss>=1.3389395475387573\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch [520]#011Speed: 832.82 samples/sec#011loss=1.338940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch[525] avg_epoch_loss=1.596674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=525 train loss <loss>=1.223785924911499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch [525]#011Speed: 1348.80 samples/sec#011loss=1.223786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch[530] avg_epoch_loss=1.592983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=530 train loss <loss>=1.2047465801239015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch [530]#011Speed: 798.44 samples/sec#011loss=1.204747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch[535] avg_epoch_loss=1.590833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=535 train loss <loss>=1.3624425888061524\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch [535]#011Speed: 1369.39 samples/sec#011loss=1.362443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch[540] avg_epoch_loss=1.588823\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=540 train loss <loss>=1.3733328819274901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch [540]#011Speed: 843.90 samples/sec#011loss=1.373333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch[545] avg_epoch_loss=1.587583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=545 train loss <loss>=1.4534337043762207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch [545]#011Speed: 1318.96 samples/sec#011loss=1.453434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch[550] avg_epoch_loss=1.583761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=550 train loss <loss>=1.1663749933242797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch [550]#011Speed: 1272.95 samples/sec#011loss=1.166375\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] processed a total of 17624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717251.9402602, \"EndTime\": 1620717269.5696063, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17629.251718521118, \"count\": 1, \"min\": 17629.251718521118, \"max\": 17629.251718521118}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=999.6948553477905 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, train loss <loss>=1.5837606747656683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_b61a6d21-ea94-4364-a26b-38e70bf85bc4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717269.5696685, \"EndTime\": 1620717269.5796854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.355306625366211, \"count\": 1, \"min\": 9.355306625366211, \"max\": 9.355306625366211}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[2] Batch[0] avg_epoch_loss=1.138234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=1.1382344961166382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[2] Batch[5] avg_epoch_loss=1.260678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=1.2606775959332783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[2] Batch [5]#011Speed: 1353.52 samples/sec#011loss=1.260678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[2] Batch[10] avg_epoch_loss=1.266130\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=1.2726739645004272\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[2] Batch [10]#011Speed: 861.31 samples/sec#011loss=1.272674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch[15] avg_epoch_loss=1.270963\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=15 train loss <loss>=1.2815942764282227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch [15]#011Speed: 1200.97 samples/sec#011loss=1.281594\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch[20] avg_epoch_loss=1.266155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=20 train loss <loss>=1.250770592689514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch [20]#011Speed: 825.97 samples/sec#011loss=1.250771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch[25] avg_epoch_loss=1.284785\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=25 train loss <loss>=1.3630294799804688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch [25]#011Speed: 1104.94 samples/sec#011loss=1.363029\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch[30] avg_epoch_loss=1.295014\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=30 train loss <loss>=1.3482066869735718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch [30]#011Speed: 834.26 samples/sec#011loss=1.348207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch[35] avg_epoch_loss=1.309439\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=35 train loss <loss>=1.3988702058792115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch [35]#011Speed: 1338.17 samples/sec#011loss=1.398870\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch[40] avg_epoch_loss=1.313752\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=40 train loss <loss>=1.3448086738586427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch [40]#011Speed: 821.50 samples/sec#011loss=1.344809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch[45] avg_epoch_loss=1.317590\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=45 train loss <loss>=1.3490566253662108\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch [45]#011Speed: 1216.02 samples/sec#011loss=1.349057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch[50] avg_epoch_loss=1.324175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=50 train loss <loss>=1.3847608804702758\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch [50]#011Speed: 837.50 samples/sec#011loss=1.384761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch[55] avg_epoch_loss=1.328741\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=55 train loss <loss>=1.375312042236328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch [55]#011Speed: 1336.87 samples/sec#011loss=1.375312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch[60] avg_epoch_loss=1.322438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=60 train loss <loss>=1.2518461704254151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch [60]#011Speed: 840.55 samples/sec#011loss=1.251846\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch[65] avg_epoch_loss=1.323277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=65 train loss <loss>=1.3335097551345825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch [65]#011Speed: 1302.08 samples/sec#011loss=1.333510\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch[70] avg_epoch_loss=1.328642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=70 train loss <loss>=1.3994640111923218\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch [70]#011Speed: 813.30 samples/sec#011loss=1.399464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch[75] avg_epoch_loss=1.319889\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=75 train loss <loss>=1.1955992460250855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch [75]#011Speed: 1336.27 samples/sec#011loss=1.195599\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch[80] avg_epoch_loss=1.332848\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=80 train loss <loss>=1.5298214197158813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch [80]#011Speed: 786.06 samples/sec#011loss=1.529821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch[85] avg_epoch_loss=1.411082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=85 train loss <loss>=2.6784728288650514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch [85]#011Speed: 1358.38 samples/sec#011loss=2.678473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch[90] avg_epoch_loss=1.452391\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=90 train loss <loss>=2.1628992557525635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch [90]#011Speed: 658.63 samples/sec#011loss=2.162899\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch[95] avg_epoch_loss=1.460977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=95 train loss <loss>=1.6172483444213868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch [95]#011Speed: 1238.75 samples/sec#011loss=1.617248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch[100] avg_epoch_loss=1.484386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=100 train loss <loss>=1.9338458061218262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch [100]#011Speed: 839.66 samples/sec#011loss=1.933846\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[105] avg_epoch_loss=1.495211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=105 train loss <loss>=1.7138755798339844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [105]#011Speed: 1346.70 samples/sec#011loss=1.713876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[110] avg_epoch_loss=1.509535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=110 train loss <loss>=1.8131894588470459\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [110]#011Speed: 785.59 samples/sec#011loss=1.813189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[115] avg_epoch_loss=1.516926\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=115 train loss <loss>=1.6810055017471313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [115]#011Speed: 1333.36 samples/sec#011loss=1.681006\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[120] avg_epoch_loss=1.520541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=120 train loss <loss>=1.6044179916381835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [120]#011Speed: 848.86 samples/sec#011loss=1.604418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[125] avg_epoch_loss=1.520589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=125 train loss <loss>=1.5217445135116576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [125]#011Speed: 1375.44 samples/sec#011loss=1.521745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[130] avg_epoch_loss=1.525867\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=130 train loss <loss>=1.6588895797729493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [130]#011Speed: 859.57 samples/sec#011loss=1.658890\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[135] avg_epoch_loss=1.520211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=135 train loss <loss>=1.3720224857330323\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [135]#011Speed: 1309.83 samples/sec#011loss=1.372022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch[140] avg_epoch_loss=1.565724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=140 train loss <loss>=2.8036691427230833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch [140]#011Speed: 786.31 samples/sec#011loss=2.803669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch[145] avg_epoch_loss=1.604069\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=145 train loss <loss>=2.685393738746643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch [145]#011Speed: 1320.21 samples/sec#011loss=2.685394\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch[150] avg_epoch_loss=1.607658\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=150 train loss <loss>=1.7124679803848266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch [150]#011Speed: 799.56 samples/sec#011loss=1.712468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch[155] avg_epoch_loss=1.610776\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=155 train loss <loss>=1.704916501045227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch [155]#011Speed: 1365.07 samples/sec#011loss=1.704917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch[160] avg_epoch_loss=1.611923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=160 train loss <loss>=1.6477223634719849\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch [160]#011Speed: 858.15 samples/sec#011loss=1.647722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch[165] avg_epoch_loss=1.613485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=165 train loss <loss>=1.6637871026992799\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch [165]#011Speed: 1331.21 samples/sec#011loss=1.663787\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch[170] avg_epoch_loss=1.614954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=170 train loss <loss>=1.6637309312820434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch [170]#011Speed: 747.35 samples/sec#011loss=1.663731\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch[175] avg_epoch_loss=1.614056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=175 train loss <loss>=1.58334379196167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch [175]#011Speed: 1349.77 samples/sec#011loss=1.583344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch[180] avg_epoch_loss=1.610185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=180 train loss <loss>=1.4739161729812622\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch [180]#011Speed: 793.38 samples/sec#011loss=1.473916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch[185] avg_epoch_loss=1.606306\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=185 train loss <loss>=1.4658845901489257\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch [185]#011Speed: 1369.34 samples/sec#011loss=1.465885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch[190] avg_epoch_loss=1.602217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=190 train loss <loss>=1.4501205444335938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch [190]#011Speed: 847.77 samples/sec#011loss=1.450121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch[195] avg_epoch_loss=1.627498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=195 train loss <loss>=2.5932279586791993\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch [195]#011Speed: 1369.40 samples/sec#011loss=2.593228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch[200] avg_epoch_loss=1.627756\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=200 train loss <loss>=1.6378451824188232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch [200]#011Speed: 826.76 samples/sec#011loss=1.637845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch[205] avg_epoch_loss=1.625394\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=205 train loss <loss>=1.5304742336273194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch [205]#011Speed: 1204.75 samples/sec#011loss=1.530474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch[210] avg_epoch_loss=1.622722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=210 train loss <loss>=1.5126061201095582\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch [210]#011Speed: 832.74 samples/sec#011loss=1.512606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch[215] avg_epoch_loss=1.617128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=215 train loss <loss>=1.3810546398162842\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch [215]#011Speed: 1326.29 samples/sec#011loss=1.381055\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch[220] avg_epoch_loss=1.611857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=220 train loss <loss>=1.384175181388855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch [220]#011Speed: 816.13 samples/sec#011loss=1.384175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch[225] avg_epoch_loss=1.609363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=225 train loss <loss>=1.4991249561309814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch [225]#011Speed: 1357.58 samples/sec#011loss=1.499125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch[230] avg_epoch_loss=1.602616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=230 train loss <loss>=1.297652268409729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch [230]#011Speed: 856.90 samples/sec#011loss=1.297652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch[235] avg_epoch_loss=1.594669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=235 train loss <loss>=1.2275192975997924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch [235]#011Speed: 1349.43 samples/sec#011loss=1.227519\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch[240] avg_epoch_loss=1.589211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=240 train loss <loss>=1.3315688371658325\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch [240]#011Speed: 780.71 samples/sec#011loss=1.331569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch[245] avg_epoch_loss=1.581908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=245 train loss <loss>=1.229916524887085\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch [245]#011Speed: 1349.13 samples/sec#011loss=1.229917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch[250] avg_epoch_loss=1.576474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=250 train loss <loss>=1.3091049194335938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch [250]#011Speed: 630.60 samples/sec#011loss=1.309105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch[255] avg_epoch_loss=1.570753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=255 train loss <loss>=1.2835645437240601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch [255]#011Speed: 1366.34 samples/sec#011loss=1.283565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[260] avg_epoch_loss=1.595149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=260 train loss <loss>=2.844254994392395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [260]#011Speed: 831.76 samples/sec#011loss=2.844255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[265] avg_epoch_loss=1.604765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=265 train loss <loss>=2.1067097663879393\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [265]#011Speed: 1354.15 samples/sec#011loss=2.106710\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[270] avg_epoch_loss=1.603882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=270 train loss <loss>=1.5569177627563477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [270]#011Speed: 770.66 samples/sec#011loss=1.556918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[275] avg_epoch_loss=1.604486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=275 train loss <loss>=1.6371942043304444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [275]#011Speed: 1297.27 samples/sec#011loss=1.637194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[280] avg_epoch_loss=1.603492\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=280 train loss <loss>=1.548640751838684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [280]#011Speed: 867.28 samples/sec#011loss=1.548641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[285] avg_epoch_loss=1.602930\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=285 train loss <loss>=1.5713683843612671\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [285]#011Speed: 1331.47 samples/sec#011loss=1.571368\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[290] avg_epoch_loss=1.601855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=290 train loss <loss>=1.5403417825698853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [290]#011Speed: 803.22 samples/sec#011loss=1.540342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch[295] avg_epoch_loss=1.605443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=295 train loss <loss>=1.8142453670501708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch [295]#011Speed: 1349.09 samples/sec#011loss=1.814245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch[300] avg_epoch_loss=1.604054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=300 train loss <loss>=1.5218369245529175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch [300]#011Speed: 774.52 samples/sec#011loss=1.521837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch[305] avg_epoch_loss=1.605904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=305 train loss <loss>=1.7173028230667113\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch [305]#011Speed: 1295.98 samples/sec#011loss=1.717303\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch[310] avg_epoch_loss=1.603755\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=310 train loss <loss>=1.4722387313842773\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch [310]#011Speed: 793.37 samples/sec#011loss=1.472239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch[315] avg_epoch_loss=1.600152\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=315 train loss <loss>=1.376037049293518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch [315]#011Speed: 1351.68 samples/sec#011loss=1.376037\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch[320] avg_epoch_loss=1.596461\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=320 train loss <loss>=1.3631415128707887\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch [320]#011Speed: 831.42 samples/sec#011loss=1.363142\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch[325] avg_epoch_loss=1.591478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=325 train loss <loss>=1.2716187477111816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch [325]#011Speed: 1286.35 samples/sec#011loss=1.271619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch[330] avg_epoch_loss=1.586882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=330 train loss <loss>=1.2871933460235596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch [330]#011Speed: 793.21 samples/sec#011loss=1.287193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch[335] avg_epoch_loss=1.581532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=335 train loss <loss>=1.2273800373077393\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch [335]#011Speed: 1356.94 samples/sec#011loss=1.227380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch[340] avg_epoch_loss=1.575381\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=340 train loss <loss>=1.1620283603668213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch [340]#011Speed: 824.61 samples/sec#011loss=1.162028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch[345] avg_epoch_loss=1.569782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=345 train loss <loss>=1.1879348278045654\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch [345]#011Speed: 1362.82 samples/sec#011loss=1.187935\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch[350] avg_epoch_loss=1.565509\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=350 train loss <loss>=1.269839334487915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch [350]#011Speed: 859.00 samples/sec#011loss=1.269839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[355] avg_epoch_loss=1.563498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=355 train loss <loss>=1.4222895145416259\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [355]#011Speed: 1313.14 samples/sec#011loss=1.422290\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[360] avg_epoch_loss=1.559264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=360 train loss <loss>=1.257828450202942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [360]#011Speed: 857.00 samples/sec#011loss=1.257828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[365] avg_epoch_loss=1.554875\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=365 train loss <loss>=1.2379504442214966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [365]#011Speed: 1271.09 samples/sec#011loss=1.237950\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[370] avg_epoch_loss=1.550876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=370 train loss <loss>=1.258167290687561\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [370]#011Speed: 843.04 samples/sec#011loss=1.258167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[375] avg_epoch_loss=1.547294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=375 train loss <loss>=1.2814867973327637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [375]#011Speed: 1346.08 samples/sec#011loss=1.281487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[380] avg_epoch_loss=1.544575\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=380 train loss <loss>=1.3401232004165649\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [380]#011Speed: 858.35 samples/sec#011loss=1.340123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[385] avg_epoch_loss=1.541025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=385 train loss <loss>=1.2705149173736572\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [385]#011Speed: 1169.40 samples/sec#011loss=1.270515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch[390] avg_epoch_loss=1.539009\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=390 train loss <loss>=1.3833505868911744\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch [390]#011Speed: 512.57 samples/sec#011loss=1.383351\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch[395] avg_epoch_loss=1.536529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=395 train loss <loss>=1.3426605463027954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch [395]#011Speed: 838.15 samples/sec#011loss=1.342661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch[400] avg_epoch_loss=1.535774\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=400 train loss <loss>=1.4759130001068115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch [400]#011Speed: 607.90 samples/sec#011loss=1.475913\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch[405] avg_epoch_loss=1.532938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=405 train loss <loss>=1.3054978370666503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch [405]#011Speed: 1026.86 samples/sec#011loss=1.305498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[410] avg_epoch_loss=1.533819\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=410 train loss <loss>=1.6053376913070678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch [410]#011Speed: 847.43 samples/sec#011loss=1.605338\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[415] avg_epoch_loss=1.530127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=415 train loss <loss>=1.2266712427139281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch [415]#011Speed: 1347.46 samples/sec#011loss=1.226671\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[420] avg_epoch_loss=1.527686\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=420 train loss <loss>=1.32463800907135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch [420]#011Speed: 779.31 samples/sec#011loss=1.324638\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[425] avg_epoch_loss=1.525772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=425 train loss <loss>=1.3646044254302978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch [425]#011Speed: 1359.28 samples/sec#011loss=1.364604\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[430] avg_epoch_loss=1.523520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=430 train loss <loss>=1.331591749191284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch [430]#011Speed: 870.04 samples/sec#011loss=1.331592\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[435] avg_epoch_loss=1.523813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=435 train loss <loss>=1.5490822792053223\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch [435]#011Speed: 1331.74 samples/sec#011loss=1.549082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[440] avg_epoch_loss=1.520161\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=440 train loss <loss>=1.201698398590088\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [440]#011Speed: 838.22 samples/sec#011loss=1.201698\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch[445] avg_epoch_loss=1.516341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=445 train loss <loss>=1.1794648885726928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [445]#011Speed: 1334.63 samples/sec#011loss=1.179465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch[450] avg_epoch_loss=1.515253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=450 train loss <loss>=1.418145513534546\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [450]#011Speed: 823.26 samples/sec#011loss=1.418146\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch[455] avg_epoch_loss=1.513436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=455 train loss <loss>=1.3495707750320434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [455]#011Speed: 1355.27 samples/sec#011loss=1.349571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch[460] avg_epoch_loss=1.512128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=460 train loss <loss>=1.3928860902786255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [460]#011Speed: 702.03 samples/sec#011loss=1.392886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch[465] avg_epoch_loss=1.517532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=465 train loss <loss>=2.015733790397644\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [465]#011Speed: 1334.60 samples/sec#011loss=2.015734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch[470] avg_epoch_loss=1.514740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=470 train loss <loss>=1.2545839309692384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [470]#011Speed: 843.01 samples/sec#011loss=1.254584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch[475] avg_epoch_loss=1.512300\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=475 train loss <loss>=1.282410168647766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch [475]#011Speed: 1303.33 samples/sec#011loss=1.282410\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch[480] avg_epoch_loss=1.510003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=480 train loss <loss>=1.2912798881530763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch [480]#011Speed: 737.54 samples/sec#011loss=1.291280\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch[485] avg_epoch_loss=1.507459\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=485 train loss <loss>=1.2628020524978638\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch [485]#011Speed: 1304.22 samples/sec#011loss=1.262802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch[490] avg_epoch_loss=1.503791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=490 train loss <loss>=1.1472304344177247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch [490]#011Speed: 820.93 samples/sec#011loss=1.147230\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch[495] avg_epoch_loss=1.501488\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=495 train loss <loss>=1.2753582715988159\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch [495]#011Speed: 1319.59 samples/sec#011loss=1.275358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch[500] avg_epoch_loss=1.498469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=500 train loss <loss>=1.1989265441894532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch [500]#011Speed: 862.83 samples/sec#011loss=1.198927\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch[505] avg_epoch_loss=1.499060\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=505 train loss <loss>=1.558327865600586\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch [505]#011Speed: 1279.27 samples/sec#011loss=1.558328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch[510] avg_epoch_loss=1.497684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=510 train loss <loss>=1.358445644378662\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch [510]#011Speed: 792.90 samples/sec#011loss=1.358446\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch[515] avg_epoch_loss=1.494996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=515 train loss <loss>=1.2202059984207154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch [515]#011Speed: 1121.64 samples/sec#011loss=1.220206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch[520] avg_epoch_loss=1.492254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=520 train loss <loss>=1.2093385219573975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch [520]#011Speed: 837.29 samples/sec#011loss=1.209339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch[525] avg_epoch_loss=1.488608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=525 train loss <loss>=1.108695125579834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch [525]#011Speed: 1320.40 samples/sec#011loss=1.108695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch[530] avg_epoch_loss=1.488003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=530 train loss <loss>=1.4243282556533814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch [530]#011Speed: 819.34 samples/sec#011loss=1.424328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[2] Batch[535] avg_epoch_loss=1.486387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=535 train loss <loss>=1.3147730112075806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[2] Batch [535]#011Speed: 1351.90 samples/sec#011loss=1.314773\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[2] Batch[540] avg_epoch_loss=1.485291\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=540 train loss <loss>=1.3678291082382201\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[2] Batch [540]#011Speed: 941.44 samples/sec#011loss=1.367829\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[2] Batch[545] avg_epoch_loss=1.483052\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=545 train loss <loss>=1.2407281875610352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[2] Batch [545]#011Speed: 1297.14 samples/sec#011loss=1.240728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] processed a total of 17496 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717269.5797493, \"EndTime\": 1620717287.36247, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17782.611846923828, \"count\": 1, \"min\": 17782.611846923828, \"max\": 17782.611846923828}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=983.8718209640307 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, train loss <loss>=1.4823990312747153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_23fdd8a1-3754-49e6-81ab-0bc5fefc5b66-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717287.3625517, \"EndTime\": 1620717287.3730128, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.72747802734375, \"count\": 1, \"min\": 9.72747802734375, \"max\": 9.72747802734375}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch[0] avg_epoch_loss=1.275267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=1.2752673625946045\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch[5] avg_epoch_loss=1.204551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=1.204550564289093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch [5]#011Speed: 1342.83 samples/sec#011loss=1.204551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch[10] avg_epoch_loss=1.175234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=1.1400543451309204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch [10]#011Speed: 833.43 samples/sec#011loss=1.140054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch[15] avg_epoch_loss=1.158225\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=15 train loss <loss>=1.1208057880401612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch [15]#011Speed: 991.21 samples/sec#011loss=1.120806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch[20] avg_epoch_loss=1.140857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=20 train loss <loss>=1.0852767944335937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch [20]#011Speed: 842.41 samples/sec#011loss=1.085277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch[25] avg_epoch_loss=1.232954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=25 train loss <loss>=1.6197627544403077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch [25]#011Speed: 1310.67 samples/sec#011loss=1.619763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch[30] avg_epoch_loss=1.277770\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=30 train loss <loss>=1.5108116626739503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch [30]#011Speed: 738.97 samples/sec#011loss=1.510812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch[35] avg_epoch_loss=1.286101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=35 train loss <loss>=1.3377578258514404\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch [35]#011Speed: 1331.30 samples/sec#011loss=1.337758\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch[40] avg_epoch_loss=1.300279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=40 train loss <loss>=1.4023576736450196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch [40]#011Speed: 852.80 samples/sec#011loss=1.402358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch[45] avg_epoch_loss=1.287127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=45 train loss <loss>=1.179284405708313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch [45]#011Speed: 1320.87 samples/sec#011loss=1.179284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch[50] avg_epoch_loss=1.298853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=50 train loss <loss>=1.4067265033721923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch [50]#011Speed: 842.66 samples/sec#011loss=1.406727\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch[55] avg_epoch_loss=1.291573\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=55 train loss <loss>=1.217314863204956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch [55]#011Speed: 1323.15 samples/sec#011loss=1.217315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch[60] avg_epoch_loss=1.291735\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=60 train loss <loss>=1.2935492992401123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch [60]#011Speed: 791.96 samples/sec#011loss=1.293549\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch[65] avg_epoch_loss=1.296957\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=65 train loss <loss>=1.36067533493042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch [65]#011Speed: 1295.42 samples/sec#011loss=1.360675\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch[70] avg_epoch_loss=1.289821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=70 train loss <loss>=1.1956242561340331\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch [70]#011Speed: 809.18 samples/sec#011loss=1.195624\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch[75] avg_epoch_loss=1.302060\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=75 train loss <loss>=1.4758437871932983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch [75]#011Speed: 1345.07 samples/sec#011loss=1.475844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[80] avg_epoch_loss=1.298612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=80 train loss <loss>=1.24620840549469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [80]#011Speed: 840.57 samples/sec#011loss=1.246208\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[85] avg_epoch_loss=1.298541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=85 train loss <loss>=1.2973976135253906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [85]#011Speed: 1315.21 samples/sec#011loss=1.297398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[90] avg_epoch_loss=1.298078\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=90 train loss <loss>=1.2901065587997436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [90]#011Speed: 841.28 samples/sec#011loss=1.290107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[95] avg_epoch_loss=1.294339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=95 train loss <loss>=1.2262929439544679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [95]#011Speed: 1123.91 samples/sec#011loss=1.226293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[100] avg_epoch_loss=1.292692\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=100 train loss <loss>=1.2610651016235352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [100]#011Speed: 841.05 samples/sec#011loss=1.261065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[105] avg_epoch_loss=1.283112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=105 train loss <loss>=1.089599895477295\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [105]#011Speed: 1340.76 samples/sec#011loss=1.089600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[110] avg_epoch_loss=1.275815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=110 train loss <loss>=1.1211170434951783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [110]#011Speed: 843.00 samples/sec#011loss=1.121117\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch[115] avg_epoch_loss=1.276049\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=115 train loss <loss>=1.2812532186508179\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch [115]#011Speed: 1278.41 samples/sec#011loss=1.281253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch[120] avg_epoch_loss=1.313714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=120 train loss <loss>=2.1875388860702514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch [120]#011Speed: 847.04 samples/sec#011loss=2.187539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch[125] avg_epoch_loss=1.315204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=125 train loss <loss>=1.351255679130554\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch [125]#011Speed: 1201.71 samples/sec#011loss=1.351256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch[130] avg_epoch_loss=1.313575\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=130 train loss <loss>=1.2725213766098022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch [130]#011Speed: 847.23 samples/sec#011loss=1.272521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch[135] avg_epoch_loss=1.309758\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=135 train loss <loss>=1.2097529888153076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch [135]#011Speed: 1303.12 samples/sec#011loss=1.209753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch[140] avg_epoch_loss=1.305815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=140 train loss <loss>=1.1985737323760985\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch [140]#011Speed: 833.20 samples/sec#011loss=1.198574\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch[145] avg_epoch_loss=1.308533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=145 train loss <loss>=1.3851855754852296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch [145]#011Speed: 1319.74 samples/sec#011loss=1.385186\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch[150] avg_epoch_loss=1.336219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=150 train loss <loss>=2.144645643234253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch [150]#011Speed: 847.43 samples/sec#011loss=2.144646\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch[155] avg_epoch_loss=1.335035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=155 train loss <loss>=1.2992839574813844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch [155]#011Speed: 1359.32 samples/sec#011loss=1.299284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch[160] avg_epoch_loss=1.333971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=160 train loss <loss>=1.3007646322250366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch [160]#011Speed: 797.72 samples/sec#011loss=1.300765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch[165] avg_epoch_loss=1.333292\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=165 train loss <loss>=1.311422848701477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch [165]#011Speed: 1315.41 samples/sec#011loss=1.311423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch[170] avg_epoch_loss=1.336272\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=170 train loss <loss>=1.4352198839187622\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch [170]#011Speed: 818.03 samples/sec#011loss=1.435220\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch[175] avg_epoch_loss=1.333539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=175 train loss <loss>=1.2400554180145265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch [175]#011Speed: 943.77 samples/sec#011loss=1.240055\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch[180] avg_epoch_loss=1.328608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=180 train loss <loss>=1.1550403118133545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch [180]#011Speed: 766.30 samples/sec#011loss=1.155040\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch[185] avg_epoch_loss=1.331436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=185 train loss <loss>=1.4338241815567017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch [185]#011Speed: 1275.43 samples/sec#011loss=1.433824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch[190] avg_epoch_loss=1.345155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=190 train loss <loss>=1.8554766654968262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch [190]#011Speed: 761.10 samples/sec#011loss=1.855477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch[195] avg_epoch_loss=1.358331\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=195 train loss <loss>=1.86167254447937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch [195]#011Speed: 1280.75 samples/sec#011loss=1.861673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch[200] avg_epoch_loss=1.362471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=200 train loss <loss>=1.5247608184814454\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch [200]#011Speed: 847.35 samples/sec#011loss=1.524761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch[205] avg_epoch_loss=1.368250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=205 train loss <loss>=1.600553321838379\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch [205]#011Speed: 1333.05 samples/sec#011loss=1.600553\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch[210] avg_epoch_loss=1.372575\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=210 train loss <loss>=1.5507522344589233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch [210]#011Speed: 808.96 samples/sec#011loss=1.550752\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch[215] avg_epoch_loss=1.374514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=215 train loss <loss>=1.4563389539718627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch [215]#011Speed: 1314.71 samples/sec#011loss=1.456339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch[220] avg_epoch_loss=1.373733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=220 train loss <loss>=1.3400254249572754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch [220]#011Speed: 751.15 samples/sec#011loss=1.340025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch[225] avg_epoch_loss=1.371974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=225 train loss <loss>=1.2942049741744994\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch [225]#011Speed: 1299.02 samples/sec#011loss=1.294205\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch[230] avg_epoch_loss=1.367840\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=230 train loss <loss>=1.1810125589370728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch [230]#011Speed: 821.19 samples/sec#011loss=1.181013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[235] avg_epoch_loss=1.365039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=235 train loss <loss>=1.2356156826019287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [235]#011Speed: 1330.20 samples/sec#011loss=1.235616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[240] avg_epoch_loss=1.395523\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=240 train loss <loss>=2.834377384185791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [240]#011Speed: 832.63 samples/sec#011loss=2.834377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[245] avg_epoch_loss=1.391571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=245 train loss <loss>=1.20106840133667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [245]#011Speed: 1366.38 samples/sec#011loss=1.201068\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[250] avg_epoch_loss=1.389520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=250 train loss <loss>=1.2886189222335815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [250]#011Speed: 785.14 samples/sec#011loss=1.288619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[255] avg_epoch_loss=1.388455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=255 train loss <loss>=1.3350092411041259\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [255]#011Speed: 1329.48 samples/sec#011loss=1.335009\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[260] avg_epoch_loss=1.387695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=260 train loss <loss>=1.3487560749053955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [260]#011Speed: 851.08 samples/sec#011loss=1.348756\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[265] avg_epoch_loss=1.389315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=265 train loss <loss>=1.4738706350326538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [265]#011Speed: 1359.49 samples/sec#011loss=1.473871\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch[270] avg_epoch_loss=1.392758\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=270 train loss <loss>=1.5759284973144532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch [270]#011Speed: 847.09 samples/sec#011loss=1.575928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch[275] avg_epoch_loss=1.389857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=275 train loss <loss>=1.2326127767562867\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch [275]#011Speed: 1358.52 samples/sec#011loss=1.232613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch[280] avg_epoch_loss=1.387419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=280 train loss <loss>=1.2528837203979493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch [280]#011Speed: 849.34 samples/sec#011loss=1.252884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch[285] avg_epoch_loss=1.384622\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=285 train loss <loss>=1.2273965358734131\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch [285]#011Speed: 1161.83 samples/sec#011loss=1.227397\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch[290] avg_epoch_loss=1.379741\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=290 train loss <loss>=1.100575566291809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch [290]#011Speed: 844.67 samples/sec#011loss=1.100576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch[295] avg_epoch_loss=1.379592\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=295 train loss <loss>=1.3708930492401123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch [295]#011Speed: 1339.72 samples/sec#011loss=1.370893\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch[300] avg_epoch_loss=1.377237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=300 train loss <loss>=1.2378345727920532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch [300]#011Speed: 856.35 samples/sec#011loss=1.237835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch[305] avg_epoch_loss=1.375769\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=305 train loss <loss>=1.2874160051345824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch [305]#011Speed: 1367.79 samples/sec#011loss=1.287416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch[310] avg_epoch_loss=1.373620\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=310 train loss <loss>=1.242080807685852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch [310]#011Speed: 847.14 samples/sec#011loss=1.242081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch[315] avg_epoch_loss=1.370313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=315 train loss <loss>=1.164588212966919\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch [315]#011Speed: 1353.21 samples/sec#011loss=1.164588\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch[320] avg_epoch_loss=1.383752\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=320 train loss <loss>=2.2331547260284426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch [320]#011Speed: 801.99 samples/sec#011loss=2.233155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch[325] avg_epoch_loss=1.385424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=325 train loss <loss>=1.4927331447601317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch [325]#011Speed: 1312.06 samples/sec#011loss=1.492733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[330] avg_epoch_loss=1.384349\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=330 train loss <loss>=1.3142274618148804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [330]#011Speed: 854.23 samples/sec#011loss=1.314227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[335] avg_epoch_loss=1.385024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=335 train loss <loss>=1.4297393560409546\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [335]#011Speed: 1198.78 samples/sec#011loss=1.429739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[340] avg_epoch_loss=1.382022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=340 train loss <loss>=1.1803080320358277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [340]#011Speed: 730.40 samples/sec#011loss=1.180308\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[345] avg_epoch_loss=1.379609\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=345 train loss <loss>=1.2150445938110352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [345]#011Speed: 1341.30 samples/sec#011loss=1.215045\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[350] avg_epoch_loss=1.379876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=350 train loss <loss>=1.3983357429504395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [350]#011Speed: 822.34 samples/sec#011loss=1.398336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[355] avg_epoch_loss=1.376407\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=355 train loss <loss>=1.1328683376312256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [355]#011Speed: 1358.44 samples/sec#011loss=1.132868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[360] avg_epoch_loss=1.372502\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=360 train loss <loss>=1.0944893956184387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [360]#011Speed: 858.11 samples/sec#011loss=1.094489\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch[365] avg_epoch_loss=1.369531\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=365 train loss <loss>=1.1550247311592101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch [365]#011Speed: 1320.52 samples/sec#011loss=1.155025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch[370] avg_epoch_loss=1.367355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=370 train loss <loss>=1.2080315589904784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch [370]#011Speed: 854.16 samples/sec#011loss=1.208032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch[375] avg_epoch_loss=1.364114\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=375 train loss <loss>=1.123622965812683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch [375]#011Speed: 1350.47 samples/sec#011loss=1.123623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch[380] avg_epoch_loss=1.363014\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=380 train loss <loss>=1.280337119102478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch [380]#011Speed: 759.77 samples/sec#011loss=1.280337\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch[385] avg_epoch_loss=1.362619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=385 train loss <loss>=1.3325037002563476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch [385]#011Speed: 1347.94 samples/sec#011loss=1.332504\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch[390] avg_epoch_loss=1.369812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=390 train loss <loss>=1.925124502182007\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch [390]#011Speed: 850.67 samples/sec#011loss=1.925125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch[395] avg_epoch_loss=1.374585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=395 train loss <loss>=1.7478572607040406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch [395]#011Speed: 1279.51 samples/sec#011loss=1.747857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch[400] avg_epoch_loss=1.376570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=400 train loss <loss>=1.5337567806243897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch [400]#011Speed: 793.65 samples/sec#011loss=1.533757\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch[405] avg_epoch_loss=1.376783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=405 train loss <loss>=1.3939044237136842\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch [405]#011Speed: 1381.04 samples/sec#011loss=1.393904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch[410] avg_epoch_loss=1.378430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=410 train loss <loss>=1.5121066093444824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch [410]#011Speed: 729.94 samples/sec#011loss=1.512107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch[415] avg_epoch_loss=1.381252\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=415 train loss <loss>=1.6132477521896362\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch [415]#011Speed: 1350.79 samples/sec#011loss=1.613248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch[420] avg_epoch_loss=1.382932\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=420 train loss <loss>=1.5226881980895997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch [420]#011Speed: 807.07 samples/sec#011loss=1.522688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch[425] avg_epoch_loss=1.383332\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=425 train loss <loss>=1.4170480966567993\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch [425]#011Speed: 1356.26 samples/sec#011loss=1.417048\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch[430] avg_epoch_loss=1.382091\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=430 train loss <loss>=1.276338815689087\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch [430]#011Speed: 823.52 samples/sec#011loss=1.276339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch[435] avg_epoch_loss=1.381897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=435 train loss <loss>=1.365193247795105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch [435]#011Speed: 1357.16 samples/sec#011loss=1.365193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch[440] avg_epoch_loss=1.380937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=440 train loss <loss>=1.2971624374389648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch [440]#011Speed: 835.90 samples/sec#011loss=1.297162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch[445] avg_epoch_loss=1.379245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=445 train loss <loss>=1.230006456375122\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch [445]#011Speed: 1188.96 samples/sec#011loss=1.230006\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch[450] avg_epoch_loss=1.377016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=450 train loss <loss>=1.1781985759735107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch [450]#011Speed: 847.56 samples/sec#011loss=1.178199\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch[455] avg_epoch_loss=1.375640\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=455 train loss <loss>=1.2515417337417603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch [455]#011Speed: 911.35 samples/sec#011loss=1.251542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch[460] avg_epoch_loss=1.374868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=460 train loss <loss>=1.304506540298462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch [460]#011Speed: 399.66 samples/sec#011loss=1.304507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch[465] avg_epoch_loss=1.372489\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=465 train loss <loss>=1.1531190872192383\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch [465]#011Speed: 768.10 samples/sec#011loss=1.153119\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch[470] avg_epoch_loss=1.370276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=470 train loss <loss>=1.16400089263916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch [470]#011Speed: 831.98 samples/sec#011loss=1.164001\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch[475] avg_epoch_loss=1.369855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=475 train loss <loss>=1.3301915287971497\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch [475]#011Speed: 1291.87 samples/sec#011loss=1.330192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch[480] avg_epoch_loss=1.368010\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=480 train loss <loss>=1.192430329322815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch [480]#011Speed: 849.64 samples/sec#011loss=1.192430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch[485] avg_epoch_loss=1.366065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=485 train loss <loss>=1.178966236114502\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch [485]#011Speed: 1279.51 samples/sec#011loss=1.178966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch[490] avg_epoch_loss=1.366013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=490 train loss <loss>=1.3609161376953125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch [490]#011Speed: 645.63 samples/sec#011loss=1.360916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch[495] avg_epoch_loss=1.363382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=495 train loss <loss>=1.1049922227859497\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch [495]#011Speed: 1239.01 samples/sec#011loss=1.104992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch[500] avg_epoch_loss=1.362125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=500 train loss <loss>=1.2374598026275634\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch [500]#011Speed: 843.44 samples/sec#011loss=1.237460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch[505] avg_epoch_loss=1.359402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=505 train loss <loss>=1.086556077003479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch [505]#011Speed: 1362.95 samples/sec#011loss=1.086556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch[510] avg_epoch_loss=1.359057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=510 train loss <loss>=1.3241506814956665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch [510]#011Speed: 841.02 samples/sec#011loss=1.324151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch[515] avg_epoch_loss=1.358533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=515 train loss <loss>=1.304983389377594\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch [515]#011Speed: 887.97 samples/sec#011loss=1.304983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch[520] avg_epoch_loss=1.359968\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=520 train loss <loss>=1.5080660104751586\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch [520]#011Speed: 449.20 samples/sec#011loss=1.508066\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch[525] avg_epoch_loss=1.359716\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=525 train loss <loss>=1.3334328413009644\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch [525]#011Speed: 863.64 samples/sec#011loss=1.333433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch[530] avg_epoch_loss=1.358512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=530 train loss <loss>=1.2318774938583374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch [530]#011Speed: 523.64 samples/sec#011loss=1.231877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch[535] avg_epoch_loss=1.357914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=535 train loss <loss>=1.2943687677383422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch [535]#011Speed: 1288.48 samples/sec#011loss=1.294369\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch[540] avg_epoch_loss=1.357493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=540 train loss <loss>=1.3123962879180908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch [540]#011Speed: 846.43 samples/sec#011loss=1.312396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch[545] avg_epoch_loss=1.356734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=545 train loss <loss>=1.2746009349822998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch [545]#011Speed: 1302.52 samples/sec#011loss=1.274601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch[550] avg_epoch_loss=1.356105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=550 train loss <loss>=1.2874167680740356\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch [550]#011Speed: 536.30 samples/sec#011loss=1.287417\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[3] Batch[555] avg_epoch_loss=1.354951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=555 train loss <loss>=1.227741575241089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[3] Batch [555]#011Speed: 835.09 samples/sec#011loss=1.227742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] processed a total of 17805 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717287.3730938, \"EndTime\": 1620717306.1465006, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 18773.342609405518, \"count\": 1, \"min\": 18773.342609405518, \"max\": 18773.342609405518}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=948.4136267276848 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, train loss <loss>=1.3547960230863287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_c8b0e41b-7769-4564-a22b-faba45ed9be7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717306.1465774, \"EndTime\": 1620717306.1603403, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 13.219356536865234, \"count\": 1, \"min\": 13.219356536865234, \"max\": 13.219356536865234}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[4] Batch[0] avg_epoch_loss=1.110884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=1.1108835935592651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[4] Batch[5] avg_epoch_loss=1.069283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=1.0692826708157857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[4] Batch [5]#011Speed: 769.96 samples/sec#011loss=1.069283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[4] Batch[10] avg_epoch_loss=1.137943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=1.2203347206115722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[4] Batch [10]#011Speed: 447.00 samples/sec#011loss=1.220335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch[15] avg_epoch_loss=1.173831\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=15 train loss <loss>=1.252785897254944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch [15]#011Speed: 768.40 samples/sec#011loss=1.252786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch[20] avg_epoch_loss=1.155495\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=20 train loss <loss>=1.0968208074569703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch [20]#011Speed: 491.02 samples/sec#011loss=1.096821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch[25] avg_epoch_loss=1.190692\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=25 train loss <loss>=1.3385156393051147\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch [25]#011Speed: 831.23 samples/sec#011loss=1.338516\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch[30] avg_epoch_loss=1.257587\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=30 train loss <loss>=1.6054431676864624\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch [30]#011Speed: 498.23 samples/sec#011loss=1.605443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch[35] avg_epoch_loss=1.253675\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=35 train loss <loss>=1.2294181346893311\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch [35]#011Speed: 1229.44 samples/sec#011loss=1.229418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch[40] avg_epoch_loss=1.245955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=40 train loss <loss>=1.1903698682785033\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch [40]#011Speed: 833.15 samples/sec#011loss=1.190370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch[45] avg_epoch_loss=1.236507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=45 train loss <loss>=1.1590386867523192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch [45]#011Speed: 1145.93 samples/sec#011loss=1.159039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch[50] avg_epoch_loss=1.230613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=50 train loss <loss>=1.176387333869934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch [50]#011Speed: 617.20 samples/sec#011loss=1.176387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch[55] avg_epoch_loss=1.228258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=55 train loss <loss>=1.2042400121688843\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch [55]#011Speed: 1243.41 samples/sec#011loss=1.204240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch[60] avg_epoch_loss=1.229000\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=60 train loss <loss>=1.237301802635193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch [60]#011Speed: 843.58 samples/sec#011loss=1.237302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch[65] avg_epoch_loss=1.293600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=65 train loss <loss>=2.0817206382751463\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch [65]#011Speed: 1341.85 samples/sec#011loss=2.081721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch[70] avg_epoch_loss=1.291661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=70 train loss <loss>=1.2660664081573487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch [70]#011Speed: 854.54 samples/sec#011loss=1.266066\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch[75] avg_epoch_loss=1.285220\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=75 train loss <loss>=1.1937644243240357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch [75]#011Speed: 1363.92 samples/sec#011loss=1.193764\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch[80] avg_epoch_loss=1.284209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=80 train loss <loss>=1.2688390254974364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch [80]#011Speed: 831.17 samples/sec#011loss=1.268839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch[85] avg_epoch_loss=1.277200\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=85 train loss <loss>=1.1636584043502807\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch [85]#011Speed: 1073.67 samples/sec#011loss=1.163658\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch[90] avg_epoch_loss=1.278511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=90 train loss <loss>=1.3010511159896851\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch [90]#011Speed: 827.27 samples/sec#011loss=1.301051\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch[95] avg_epoch_loss=1.269357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=95 train loss <loss>=1.1027660846710206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch [95]#011Speed: 1312.29 samples/sec#011loss=1.102766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch[100] avg_epoch_loss=1.265321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=100 train loss <loss>=1.1878133773803712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch [100]#011Speed: 826.82 samples/sec#011loss=1.187813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch[105] avg_epoch_loss=1.323432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=105 train loss <loss>=2.49727885723114\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch [105]#011Speed: 1352.14 samples/sec#011loss=2.497279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch[110] avg_epoch_loss=1.321313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=110 train loss <loss>=1.276384997367859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch [110]#011Speed: 831.94 samples/sec#011loss=1.276385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch[115] avg_epoch_loss=1.320669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=115 train loss <loss>=1.3063873767852783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch [115]#011Speed: 1318.05 samples/sec#011loss=1.306387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch[120] avg_epoch_loss=1.320545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=120 train loss <loss>=1.317668581008911\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch [120]#011Speed: 777.77 samples/sec#011loss=1.317669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[125] avg_epoch_loss=1.316886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=125 train loss <loss>=1.2283326625823974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [125]#011Speed: 1343.34 samples/sec#011loss=1.228333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[130] avg_epoch_loss=1.315408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=130 train loss <loss>=1.2781748056411744\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [130]#011Speed: 835.49 samples/sec#011loss=1.278175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[135] avg_epoch_loss=1.311602\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=135 train loss <loss>=1.2118679761886597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [135]#011Speed: 1333.18 samples/sec#011loss=1.211868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[140] avg_epoch_loss=1.311916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=140 train loss <loss>=1.3204712629318238\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [140]#011Speed: 838.99 samples/sec#011loss=1.320471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[145] avg_epoch_loss=1.309432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=145 train loss <loss>=1.2393754720687866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [145]#011Speed: 1329.30 samples/sec#011loss=1.239375\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[150] avg_epoch_loss=1.304632\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=150 train loss <loss>=1.1644804239273072\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [150]#011Speed: 728.82 samples/sec#011loss=1.164480\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[155] avg_epoch_loss=1.297146\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=155 train loss <loss>=1.0710575342178346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [155]#011Speed: 1337.08 samples/sec#011loss=1.071058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch[160] avg_epoch_loss=1.292151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=160 train loss <loss>=1.1363183975219726\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch [160]#011Speed: 857.57 samples/sec#011loss=1.136318\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch[165] avg_epoch_loss=1.289694\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=165 train loss <loss>=1.210567021369934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch [165]#011Speed: 1364.15 samples/sec#011loss=1.210567\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch[170] avg_epoch_loss=1.287442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=170 train loss <loss>=1.2126842141151428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch [170]#011Speed: 852.39 samples/sec#011loss=1.212684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch[175] avg_epoch_loss=1.282116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=175 train loss <loss>=1.0999637603759767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch [175]#011Speed: 1365.12 samples/sec#011loss=1.099964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch[180] avg_epoch_loss=1.281927\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=180 train loss <loss>=1.2752636194229126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch [180]#011Speed: 582.17 samples/sec#011loss=1.275264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch[185] avg_epoch_loss=1.280376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=185 train loss <loss>=1.2242436170578004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch [185]#011Speed: 842.11 samples/sec#011loss=1.224244\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch[190] avg_epoch_loss=1.279200\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=190 train loss <loss>=1.2354314804077149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch [190]#011Speed: 551.21 samples/sec#011loss=1.235431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch[195] avg_epoch_loss=1.296413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=195 train loss <loss>=1.9539644956588744\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch [195]#011Speed: 1353.43 samples/sec#011loss=1.953964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch[200] avg_epoch_loss=1.295563\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=200 train loss <loss>=1.2622586131095885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch [200]#011Speed: 592.29 samples/sec#011loss=1.262259\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch[205] avg_epoch_loss=1.306986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=205 train loss <loss>=1.7661929607391358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch [205]#011Speed: 1225.16 samples/sec#011loss=1.766193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch[210] avg_epoch_loss=1.306852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=210 train loss <loss>=1.3013062477111816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch [210]#011Speed: 845.87 samples/sec#011loss=1.301306\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch[215] avg_epoch_loss=1.309248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=215 train loss <loss>=1.410385823249817\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch [215]#011Speed: 1342.64 samples/sec#011loss=1.410386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch[220] avg_epoch_loss=1.308419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=220 train loss <loss>=1.2726061582565307\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch [220]#011Speed: 853.85 samples/sec#011loss=1.272606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch[225] avg_epoch_loss=1.306793\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=225 train loss <loss>=1.2349009037017822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch [225]#011Speed: 1334.73 samples/sec#011loss=1.234901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch[230] avg_epoch_loss=1.303602\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=230 train loss <loss>=1.1593819856643677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch [230]#011Speed: 784.35 samples/sec#011loss=1.159382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch[235] avg_epoch_loss=1.300869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=235 train loss <loss>=1.1745711326599122\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch [235]#011Speed: 1279.87 samples/sec#011loss=1.174571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[240] avg_epoch_loss=1.297296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=240 train loss <loss>=1.1286497831344604\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [240]#011Speed: 769.31 samples/sec#011loss=1.128650\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[245] avg_epoch_loss=1.296396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=245 train loss <loss>=1.2530407190322876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [245]#011Speed: 1296.43 samples/sec#011loss=1.253041\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[250] avg_epoch_loss=1.301296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=250 train loss <loss>=1.5423672676086426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [250]#011Speed: 836.59 samples/sec#011loss=1.542367\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[255] avg_epoch_loss=1.322008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=255 train loss <loss>=2.3617627382278443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [255]#011Speed: 1346.92 samples/sec#011loss=2.361763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[260] avg_epoch_loss=1.323696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=260 train loss <loss>=1.410132384300232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [260]#011Speed: 825.52 samples/sec#011loss=1.410132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[265] avg_epoch_loss=1.322661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=265 train loss <loss>=1.2686219453811645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [265]#011Speed: 1326.26 samples/sec#011loss=1.268622\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[270] avg_epoch_loss=1.322447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=270 train loss <loss>=1.3110353708267213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [270]#011Speed: 798.96 samples/sec#011loss=1.311035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch[275] avg_epoch_loss=1.322723\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=275 train loss <loss>=1.3376965284347535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch [275]#011Speed: 1327.63 samples/sec#011loss=1.337697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch[280] avg_epoch_loss=1.320267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=280 train loss <loss>=1.1847007751464844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch [280]#011Speed: 850.31 samples/sec#011loss=1.184701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch[285] avg_epoch_loss=1.316363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=285 train loss <loss>=1.09693284034729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch [285]#011Speed: 1338.76 samples/sec#011loss=1.096933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch[290] avg_epoch_loss=1.315759\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=290 train loss <loss>=1.2812633752822875\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch [290]#011Speed: 856.73 samples/sec#011loss=1.281263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch[295] avg_epoch_loss=1.315718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=295 train loss <loss>=1.3133319854736327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch [295]#011Speed: 1297.11 samples/sec#011loss=1.313332\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch[300] avg_epoch_loss=1.316185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=300 train loss <loss>=1.3438318014144897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch [300]#011Speed: 783.37 samples/sec#011loss=1.343832\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[305] avg_epoch_loss=1.314652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=305 train loss <loss>=1.2223575353622436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [305]#011Speed: 1301.64 samples/sec#011loss=1.222358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[310] avg_epoch_loss=1.312026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=310 train loss <loss>=1.1512678861618042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [310]#011Speed: 845.72 samples/sec#011loss=1.151268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[315] avg_epoch_loss=1.311777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=315 train loss <loss>=1.2962991714477539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [315]#011Speed: 1313.55 samples/sec#011loss=1.296299\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[320] avg_epoch_loss=1.308611\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=320 train loss <loss>=1.1085336923599243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [320]#011Speed: 825.77 samples/sec#011loss=1.108534\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[325] avg_epoch_loss=1.305422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=325 train loss <loss>=1.1007039546966553\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [325]#011Speed: 1362.20 samples/sec#011loss=1.100704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[330] avg_epoch_loss=1.308054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=330 train loss <loss>=1.479644513130188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [330]#011Speed: 823.80 samples/sec#011loss=1.479645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[335] avg_epoch_loss=1.304430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=335 train loss <loss>=1.0644938468933105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [335]#011Speed: 1219.35 samples/sec#011loss=1.064494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch[340] avg_epoch_loss=1.300603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=340 train loss <loss>=1.0434354186058044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch [340]#011Speed: 836.78 samples/sec#011loss=1.043435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch[345] avg_epoch_loss=1.298383\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=345 train loss <loss>=1.1470215320587158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch [345]#011Speed: 1295.05 samples/sec#011loss=1.147022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch[350] avg_epoch_loss=1.296126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=350 train loss <loss>=1.1399107336997987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch [350]#011Speed: 812.33 samples/sec#011loss=1.139911\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch[355] avg_epoch_loss=1.294358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=355 train loss <loss>=1.1702375411987305\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch [355]#011Speed: 1328.29 samples/sec#011loss=1.170238\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch[360] avg_epoch_loss=1.293106\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=360 train loss <loss>=1.204015564918518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch [360]#011Speed: 642.61 samples/sec#011loss=1.204016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch[365] avg_epoch_loss=1.289976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=365 train loss <loss>=1.0639646768569946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch [365]#011Speed: 1237.60 samples/sec#011loss=1.063965\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch[370] avg_epoch_loss=1.288751\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=370 train loss <loss>=1.1990738749504088\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch [370]#011Speed: 836.96 samples/sec#011loss=1.199074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch[375] avg_epoch_loss=1.287384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=375 train loss <loss>=1.1859597444534302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch [375]#011Speed: 1299.95 samples/sec#011loss=1.185960\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch[380] avg_epoch_loss=1.296355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=380 train loss <loss>=1.9709426522254945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch [380]#011Speed: 824.65 samples/sec#011loss=1.970943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch[385] avg_epoch_loss=1.297521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=385 train loss <loss>=1.3863911390304566\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch [385]#011Speed: 1255.00 samples/sec#011loss=1.386391\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch[390] avg_epoch_loss=1.297804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=390 train loss <loss>=1.3196645736694337\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch [390]#011Speed: 717.94 samples/sec#011loss=1.319665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch[395] avg_epoch_loss=1.296901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=395 train loss <loss>=1.2262833833694458\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch [395]#011Speed: 1175.33 samples/sec#011loss=1.226283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch[400] avg_epoch_loss=1.295432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=400 train loss <loss>=1.1790844678878785\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch [400]#011Speed: 820.47 samples/sec#011loss=1.179084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch[405] avg_epoch_loss=1.295124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=405 train loss <loss>=1.2704567432403564\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch [405]#011Speed: 1312.48 samples/sec#011loss=1.270457\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch[410] avg_epoch_loss=1.294397\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=410 train loss <loss>=1.2352961301803589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch [410]#011Speed: 827.78 samples/sec#011loss=1.235296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch[415] avg_epoch_loss=1.292958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=415 train loss <loss>=1.174687647819519\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch [415]#011Speed: 1284.96 samples/sec#011loss=1.174688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch[420] avg_epoch_loss=1.293647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=420 train loss <loss>=1.3509535551071168\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch [420]#011Speed: 845.93 samples/sec#011loss=1.350954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch[425] avg_epoch_loss=1.294844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=425 train loss <loss>=1.395706868171692\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch [425]#011Speed: 1300.74 samples/sec#011loss=1.395707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch[430] avg_epoch_loss=1.295439\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=430 train loss <loss>=1.3461154222488403\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch [430]#011Speed: 772.41 samples/sec#011loss=1.346115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch[435] avg_epoch_loss=1.293447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=435 train loss <loss>=1.1216846704483032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch [435]#011Speed: 1350.51 samples/sec#011loss=1.121685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch[440] avg_epoch_loss=1.293415\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=440 train loss <loss>=1.2906865239143372\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch [440]#011Speed: 842.28 samples/sec#011loss=1.290687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch[445] avg_epoch_loss=1.292321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=445 train loss <loss>=1.1957633733749389\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch [445]#011Speed: 1338.69 samples/sec#011loss=1.195763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch[450] avg_epoch_loss=1.292094\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=450 train loss <loss>=1.271849775314331\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch [450]#011Speed: 841.51 samples/sec#011loss=1.271850\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch[455] avg_epoch_loss=1.292866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=455 train loss <loss>=1.3624943971633912\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch [455]#011Speed: 1334.03 samples/sec#011loss=1.362494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch[460] avg_epoch_loss=1.302073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=460 train loss <loss>=2.1417988538742065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch [460]#011Speed: 804.88 samples/sec#011loss=2.141799\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch[465] avg_epoch_loss=1.307835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=465 train loss <loss>=1.8391164541244507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch [465]#011Speed: 1361.21 samples/sec#011loss=1.839116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch[470] avg_epoch_loss=1.309943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=470 train loss <loss>=1.5064109086990356\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch [470]#011Speed: 867.48 samples/sec#011loss=1.506411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch[475] avg_epoch_loss=1.312495\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=475 train loss <loss>=1.5528582811355591\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch [475]#011Speed: 1327.46 samples/sec#011loss=1.552858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch[480] avg_epoch_loss=1.313028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=480 train loss <loss>=1.3637592792510986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch [480]#011Speed: 849.84 samples/sec#011loss=1.363759\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch[485] avg_epoch_loss=1.312517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=485 train loss <loss>=1.2633854627609253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch [485]#011Speed: 1320.80 samples/sec#011loss=1.263385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch[490] avg_epoch_loss=1.312414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=490 train loss <loss>=1.3024261236190795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch [490]#011Speed: 793.95 samples/sec#011loss=1.302426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch[495] avg_epoch_loss=1.311852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=495 train loss <loss>=1.2565770387649535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch [495]#011Speed: 1335.75 samples/sec#011loss=1.256577\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch[500] avg_epoch_loss=1.310643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=500 train loss <loss>=1.1907914876937866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch [500]#011Speed: 874.46 samples/sec#011loss=1.190791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch[505] avg_epoch_loss=1.309253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=505 train loss <loss>=1.1699443101882934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch [505]#011Speed: 1326.05 samples/sec#011loss=1.169944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch[510] avg_epoch_loss=1.306954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=510 train loss <loss>=1.0743158340454102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch [510]#011Speed: 715.25 samples/sec#011loss=1.074316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch[515] avg_epoch_loss=1.304304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=515 train loss <loss>=1.0334643363952636\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch [515]#011Speed: 1356.90 samples/sec#011loss=1.033464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch[520] avg_epoch_loss=1.302459\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=520 train loss <loss>=1.112037682533264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch [520]#011Speed: 574.30 samples/sec#011loss=1.112038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch[525] avg_epoch_loss=1.299516\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=525 train loss <loss>=0.9928559064865112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch [525]#011Speed: 1362.91 samples/sec#011loss=0.992856\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch[530] avg_epoch_loss=1.297167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=530 train loss <loss>=1.050092887878418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch [530]#011Speed: 855.64 samples/sec#011loss=1.050093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch[535] avg_epoch_loss=1.303051\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=535 train loss <loss>=1.9279313564300538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch [535]#011Speed: 1352.51 samples/sec#011loss=1.927931\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch[540] avg_epoch_loss=1.304135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=540 train loss <loss>=1.4203054666519166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch [540]#011Speed: 900.00 samples/sec#011loss=1.420305\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch[545] avg_epoch_loss=1.302107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=545 train loss <loss>=1.0826474666595458\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch [545]#011Speed: 1304.39 samples/sec#011loss=1.082647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] processed a total of 17570 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717306.1604047, \"EndTime\": 1620717324.890717, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 18730.2463054657, \"count\": 1, \"min\": 18730.2463054657, \"max\": 18730.2463054657}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=938.0491687778757 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, train loss <loss>=1.3008225758509202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_a17fba37-3144-4a15-b572-43888481273b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717324.8907967, \"EndTime\": 1620717324.9012141, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.664058685302734, \"count\": 1, \"min\": 9.664058685302734, \"max\": 9.664058685302734}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[5] Batch[0] avg_epoch_loss=1.114033\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=1.1140326261520386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch[5] avg_epoch_loss=1.118777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=1.1187767386436462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch [5]#011Speed: 1206.17 samples/sec#011loss=1.118777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch[10] avg_epoch_loss=1.163884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=1.2180119037628174\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch [10]#011Speed: 860.99 samples/sec#011loss=1.218012\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch[15] avg_epoch_loss=1.151614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=15 train loss <loss>=1.1246196031570435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch [15]#011Speed: 1304.32 samples/sec#011loss=1.124620\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch[20] avg_epoch_loss=1.135665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=20 train loss <loss>=1.084629273414612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch [20]#011Speed: 856.25 samples/sec#011loss=1.084629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch[25] avg_epoch_loss=1.163795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=25 train loss <loss>=1.2819432973861695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch [25]#011Speed: 1231.72 samples/sec#011loss=1.281943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch[30] avg_epoch_loss=1.154551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=30 train loss <loss>=1.106479024887085\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch [30]#011Speed: 823.71 samples/sec#011loss=1.106479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch[35] avg_epoch_loss=1.172783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=35 train loss <loss>=1.2858253359794616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch [35]#011Speed: 1249.33 samples/sec#011loss=1.285825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch[40] avg_epoch_loss=1.185020\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=40 train loss <loss>=1.2731242418289184\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch [40]#011Speed: 852.67 samples/sec#011loss=1.273124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch[45] avg_epoch_loss=1.186528\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=45 train loss <loss>=1.198888397216797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch [45]#011Speed: 1338.37 samples/sec#011loss=1.198888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch[50] avg_epoch_loss=1.194986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=50 train loss <loss>=1.272801923751831\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch [50]#011Speed: 834.08 samples/sec#011loss=1.272802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch[55] avg_epoch_loss=1.187325\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=55 train loss <loss>=1.1091891288757325\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch [55]#011Speed: 1365.68 samples/sec#011loss=1.109189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch[60] avg_epoch_loss=1.192412\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=60 train loss <loss>=1.2493770480155946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch [60]#011Speed: 844.85 samples/sec#011loss=1.249377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[65] avg_epoch_loss=1.203158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=65 train loss <loss>=1.3342580556869508\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [65]#011Speed: 1334.12 samples/sec#011loss=1.334258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[70] avg_epoch_loss=1.208913\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=70 train loss <loss>=1.2848875045776367\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [70]#011Speed: 795.94 samples/sec#011loss=1.284888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[75] avg_epoch_loss=1.210911\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=75 train loss <loss>=1.239276075363159\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [75]#011Speed: 1373.55 samples/sec#011loss=1.239276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[80] avg_epoch_loss=1.201060\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=80 train loss <loss>=1.051333522796631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [80]#011Speed: 860.08 samples/sec#011loss=1.051334\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[85] avg_epoch_loss=1.192804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=85 train loss <loss>=1.0590500116348267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [85]#011Speed: 1329.40 samples/sec#011loss=1.059050\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[90] avg_epoch_loss=1.191618\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=90 train loss <loss>=1.1712254762649537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [90]#011Speed: 848.54 samples/sec#011loss=1.171225\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[95] avg_epoch_loss=1.314968\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=95 train loss <loss>=3.5599280834197997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [95]#011Speed: 1359.53 samples/sec#011loss=3.559928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch[100] avg_epoch_loss=1.307693\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=100 train loss <loss>=1.1680170059204102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch [100]#011Speed: 794.81 samples/sec#011loss=1.168017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch[105] avg_epoch_loss=1.322869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=105 train loss <loss>=1.6294226408004762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch [105]#011Speed: 1361.06 samples/sec#011loss=1.629423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch[110] avg_epoch_loss=1.325704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=110 train loss <loss>=1.3858046531677246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch [110]#011Speed: 840.70 samples/sec#011loss=1.385805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch[115] avg_epoch_loss=1.339185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=115 train loss <loss>=1.6384785175323486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch [115]#011Speed: 1302.98 samples/sec#011loss=1.638479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch[120] avg_epoch_loss=1.342501\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=120 train loss <loss>=1.4194201946258544\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch [120]#011Speed: 869.30 samples/sec#011loss=1.419420\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch[125] avg_epoch_loss=1.346195\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=125 train loss <loss>=1.435596776008606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch [125]#011Speed: 1353.40 samples/sec#011loss=1.435597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch[130] avg_epoch_loss=1.345821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=130 train loss <loss>=1.336397409439087\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch [130]#011Speed: 681.04 samples/sec#011loss=1.336397\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch[135] avg_epoch_loss=1.344684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=135 train loss <loss>=1.3148881912231445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch [135]#011Speed: 1230.87 samples/sec#011loss=1.314888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch[140] avg_epoch_loss=1.368915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=140 train loss <loss>=2.0279873609542847\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch [140]#011Speed: 837.34 samples/sec#011loss=2.027987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch[145] avg_epoch_loss=1.364522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=145 train loss <loss>=1.2406358003616333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch [145]#011Speed: 1360.83 samples/sec#011loss=1.240636\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch[150] avg_epoch_loss=1.359912\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=150 train loss <loss>=1.2253163576126098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch [150]#011Speed: 841.22 samples/sec#011loss=1.225316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch[155] avg_epoch_loss=1.356607\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=155 train loss <loss>=1.2567824363708495\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch [155]#011Speed: 1278.72 samples/sec#011loss=1.256782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[160] avg_epoch_loss=1.351903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=160 train loss <loss>=1.2051606893539428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [160]#011Speed: 850.04 samples/sec#011loss=1.205161\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[165] avg_epoch_loss=1.346679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=165 train loss <loss>=1.178462266921997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [165]#011Speed: 1206.22 samples/sec#011loss=1.178462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[170] avg_epoch_loss=1.339702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=170 train loss <loss>=1.1080570459365844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [170]#011Speed: 859.41 samples/sec#011loss=1.108057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[175] avg_epoch_loss=1.335854\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=175 train loss <loss>=1.2042388200759888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [175]#011Speed: 1334.08 samples/sec#011loss=1.204239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[180] avg_epoch_loss=1.330640\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=180 train loss <loss>=1.1471360564231872\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [180]#011Speed: 837.32 samples/sec#011loss=1.147136\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[185] avg_epoch_loss=1.324523\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=185 train loss <loss>=1.1030730128288269\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [185]#011Speed: 1335.02 samples/sec#011loss=1.103073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[190] avg_epoch_loss=1.326145\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=190 train loss <loss>=1.386484479904175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [190]#011Speed: 842.93 samples/sec#011loss=1.386484\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch[195] avg_epoch_loss=1.337630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=195 train loss <loss>=1.776344108581543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch [195]#011Speed: 1298.09 samples/sec#011loss=1.776344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch[200] avg_epoch_loss=1.346901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=200 train loss <loss>=1.7103343248367309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch [200]#011Speed: 821.10 samples/sec#011loss=1.710334\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch[205] avg_epoch_loss=1.346079\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=205 train loss <loss>=1.313044810295105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch [205]#011Speed: 1335.48 samples/sec#011loss=1.313045\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch[210] avg_epoch_loss=1.356200\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=210 train loss <loss>=1.7731921672821045\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch [210]#011Speed: 857.44 samples/sec#011loss=1.773192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch[215] avg_epoch_loss=1.354742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=215 train loss <loss>=1.2931842803955078\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch [215]#011Speed: 1360.26 samples/sec#011loss=1.293184\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch[220] avg_epoch_loss=1.356083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=220 train loss <loss>=1.4140177965164185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch [220]#011Speed: 835.72 samples/sec#011loss=1.414018\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[225] avg_epoch_loss=1.356013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=225 train loss <loss>=1.352942132949829\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [225]#011Speed: 1340.41 samples/sec#011loss=1.352942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[230] avg_epoch_loss=1.353112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=230 train loss <loss>=1.2219601631164552\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [230]#011Speed: 804.32 samples/sec#011loss=1.221960\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[235] avg_epoch_loss=1.349729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=235 train loss <loss>=1.1934433460235596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [235]#011Speed: 1362.00 samples/sec#011loss=1.193443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[240] avg_epoch_loss=1.345412\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=240 train loss <loss>=1.1416734457015991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [240]#011Speed: 854.82 samples/sec#011loss=1.141673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[245] avg_epoch_loss=1.339490\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=245 train loss <loss>=1.0540381908416747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [245]#011Speed: 1347.66 samples/sec#011loss=1.054038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[250] avg_epoch_loss=1.333716\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=250 train loss <loss>=1.0496256589889525\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [250]#011Speed: 855.56 samples/sec#011loss=1.049626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[255] avg_epoch_loss=1.339512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=255 train loss <loss>=1.6304791688919067\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [255]#011Speed: 1321.34 samples/sec#011loss=1.630479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch[260] avg_epoch_loss=1.337863\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=260 train loss <loss>=1.2534091472625732\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch [260]#011Speed: 855.79 samples/sec#011loss=1.253409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch[265] avg_epoch_loss=1.334113\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=265 train loss <loss>=1.138370966911316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch [265]#011Speed: 1238.57 samples/sec#011loss=1.138371\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch[270] avg_epoch_loss=1.331135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=270 train loss <loss>=1.1727189540863037\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch [270]#011Speed: 844.56 samples/sec#011loss=1.172719\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch[275] avg_epoch_loss=1.328291\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=275 train loss <loss>=1.174133849143982\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch [275]#011Speed: 1309.17 samples/sec#011loss=1.174134\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch[280] avg_epoch_loss=1.325070\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=280 train loss <loss>=1.147283673286438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch [280]#011Speed: 852.22 samples/sec#011loss=1.147284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch[285] avg_epoch_loss=1.327238\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=285 train loss <loss>=1.449065136909485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch [285]#011Speed: 1317.16 samples/sec#011loss=1.449065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch[290] avg_epoch_loss=1.324632\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=290 train loss <loss>=1.1756065964698792\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch [290]#011Speed: 800.19 samples/sec#011loss=1.175607\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch[295] avg_epoch_loss=1.325420\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=295 train loss <loss>=1.3712471723556519\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch [295]#011Speed: 821.21 samples/sec#011loss=1.371247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch[300] avg_epoch_loss=1.329290\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=300 train loss <loss>=1.558429765701294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch [300]#011Speed: 835.78 samples/sec#011loss=1.558430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch[305] avg_epoch_loss=1.325640\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=305 train loss <loss>=1.1058832168579102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch [305]#011Speed: 1362.98 samples/sec#011loss=1.105883\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch[310] avg_epoch_loss=1.322164\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=310 train loss <loss>=1.1094334363937377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch [310]#011Speed: 696.27 samples/sec#011loss=1.109433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch[315] avg_epoch_loss=1.319224\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=315 train loss <loss>=1.136364722251892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch [315]#011Speed: 1197.24 samples/sec#011loss=1.136365\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch[320] avg_epoch_loss=1.326060\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=320 train loss <loss>=1.7581013202667237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch [320]#011Speed: 802.44 samples/sec#011loss=1.758101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch[325] avg_epoch_loss=1.324500\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=325 train loss <loss>=1.2243331670761108\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch [325]#011Speed: 1188.09 samples/sec#011loss=1.224333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch[330] avg_epoch_loss=1.322337\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=330 train loss <loss>=1.1813038825988769\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch [330]#011Speed: 843.80 samples/sec#011loss=1.181304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch[335] avg_epoch_loss=1.318755\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=335 train loss <loss>=1.0816039562225341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch [335]#011Speed: 1349.39 samples/sec#011loss=1.081604\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch[340] avg_epoch_loss=1.314737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=340 train loss <loss>=1.0447791814804077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch [340]#011Speed: 816.04 samples/sec#011loss=1.044779\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch[345] avg_epoch_loss=1.310678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=345 train loss <loss>=1.0338446021080017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch [345]#011Speed: 1363.29 samples/sec#011loss=1.033845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch[350] avg_epoch_loss=1.307598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=350 train loss <loss>=1.0944652795791625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch [350]#011Speed: 823.69 samples/sec#011loss=1.094465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch[355] avg_epoch_loss=1.307099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=355 train loss <loss>=1.272042202949524\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch [355]#011Speed: 1345.33 samples/sec#011loss=1.272042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch[360] avg_epoch_loss=1.307357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=360 train loss <loss>=1.325771701335907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch [360]#011Speed: 757.63 samples/sec#011loss=1.325772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch[365] avg_epoch_loss=1.306616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=365 train loss <loss>=1.2530804753303528\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch [365]#011Speed: 1313.78 samples/sec#011loss=1.253080\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch[370] avg_epoch_loss=1.307865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=370 train loss <loss>=1.3992856740951538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch [370]#011Speed: 829.96 samples/sec#011loss=1.399286\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch[375] avg_epoch_loss=1.307761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=375 train loss <loss>=1.3000755548477172\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch [375]#011Speed: 1316.63 samples/sec#011loss=1.300076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch[380] avg_epoch_loss=1.306260\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=380 train loss <loss>=1.1933395624160767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch [380]#011Speed: 852.10 samples/sec#011loss=1.193340\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch[385] avg_epoch_loss=1.304348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=385 train loss <loss>=1.1586845636367797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch [385]#011Speed: 1362.92 samples/sec#011loss=1.158685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch[390] avg_epoch_loss=1.302864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=390 train loss <loss>=1.188312029838562\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch [390]#011Speed: 821.97 samples/sec#011loss=1.188312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch[395] avg_epoch_loss=1.300292\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=395 train loss <loss>=1.0991544365882873\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch [395]#011Speed: 1365.06 samples/sec#011loss=1.099154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch[400] avg_epoch_loss=1.296672\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=400 train loss <loss>=1.0099689483642578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch [400]#011Speed: 837.31 samples/sec#011loss=1.009969\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch[405] avg_epoch_loss=1.295147\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=405 train loss <loss>=1.1728020548820495\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch [405]#011Speed: 1358.49 samples/sec#011loss=1.172802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[410] avg_epoch_loss=1.292214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=410 train loss <loss>=1.0540921807289123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [410]#011Speed: 855.36 samples/sec#011loss=1.054092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[415] avg_epoch_loss=1.293025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=415 train loss <loss>=1.3596691846847535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [415]#011Speed: 1337.85 samples/sec#011loss=1.359669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[420] avg_epoch_loss=1.291044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=420 train loss <loss>=1.1262288093566895\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [420]#011Speed: 792.46 samples/sec#011loss=1.126229\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[425] avg_epoch_loss=1.292329\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=425 train loss <loss>=1.400535225868225\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [425]#011Speed: 1329.98 samples/sec#011loss=1.400535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[430] avg_epoch_loss=1.293605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=430 train loss <loss>=1.402346634864807\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [430]#011Speed: 836.46 samples/sec#011loss=1.402347\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[435] avg_epoch_loss=1.294141\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=435 train loss <loss>=1.3402997732162476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [435]#011Speed: 1333.86 samples/sec#011loss=1.340300\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[440] avg_epoch_loss=1.292330\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=440 train loss <loss>=1.134454083442688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [440]#011Speed: 817.92 samples/sec#011loss=1.134454\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch[445] avg_epoch_loss=1.290943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=445 train loss <loss>=1.1685545206069947\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch [445]#011Speed: 1293.87 samples/sec#011loss=1.168555\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch[450] avg_epoch_loss=1.288761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=450 train loss <loss>=1.0941850781440734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch [450]#011Speed: 853.99 samples/sec#011loss=1.094185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch[455] avg_epoch_loss=1.289981\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=455 train loss <loss>=1.3999862670898438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch [455]#011Speed: 666.78 samples/sec#011loss=1.399986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch[460] avg_epoch_loss=1.288828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=460 train loss <loss>=1.1837114334106444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch [460]#011Speed: 723.50 samples/sec#011loss=1.183711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch[465] avg_epoch_loss=1.286724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=465 train loss <loss>=1.0926649212837218\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch [465]#011Speed: 1297.17 samples/sec#011loss=1.092665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[470] avg_epoch_loss=1.284892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=470 train loss <loss>=1.1141623258590698\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [470]#011Speed: 833.48 samples/sec#011loss=1.114162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[475] avg_epoch_loss=1.283898\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=475 train loss <loss>=1.1903043508529663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [475]#011Speed: 1333.50 samples/sec#011loss=1.190304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[480] avg_epoch_loss=1.283969\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=480 train loss <loss>=1.2906914710998536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [480]#011Speed: 794.28 samples/sec#011loss=1.290691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[485] avg_epoch_loss=1.282910\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=485 train loss <loss>=1.1810594558715821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [485]#011Speed: 1318.73 samples/sec#011loss=1.181059\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[490] avg_epoch_loss=1.279906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=490 train loss <loss>=0.9879572272300721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [490]#011Speed: 870.74 samples/sec#011loss=0.987957\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[495] avg_epoch_loss=1.276812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=495 train loss <loss>=0.9729038715362549\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [495]#011Speed: 1273.91 samples/sec#011loss=0.972904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[500] avg_epoch_loss=1.274178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=500 train loss <loss>=1.0129318118095398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [500]#011Speed: 854.30 samples/sec#011loss=1.012932\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch[505] avg_epoch_loss=1.271442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=505 train loss <loss>=0.9972755432128906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch [505]#011Speed: 1318.78 samples/sec#011loss=0.997276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch[510] avg_epoch_loss=1.268317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=510 train loss <loss>=0.9520822525024414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch [510]#011Speed: 841.93 samples/sec#011loss=0.952082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch[515] avg_epoch_loss=1.264884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=515 train loss <loss>=0.9139766454696655\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch [515]#011Speed: 1176.13 samples/sec#011loss=0.913977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch[520] avg_epoch_loss=1.265533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=520 train loss <loss>=1.3325002670288086\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch [520]#011Speed: 852.80 samples/sec#011loss=1.332500\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch[525] avg_epoch_loss=1.265203\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=525 train loss <loss>=1.2309121131896972\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch [525]#011Speed: 1374.53 samples/sec#011loss=1.230912\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch[530] avg_epoch_loss=1.263924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=530 train loss <loss>=1.12933851480484\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch [530]#011Speed: 832.64 samples/sec#011loss=1.129339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch[535] avg_epoch_loss=1.263414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=535 train loss <loss>=1.209227168560028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch [535]#011Speed: 1356.44 samples/sec#011loss=1.209227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch[540] avg_epoch_loss=1.262670\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=540 train loss <loss>=1.1828863382339478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch [540]#011Speed: 850.86 samples/sec#011loss=1.182886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch[545] avg_epoch_loss=1.260822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=545 train loss <loss>=1.0609622716903686\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch [545]#011Speed: 1365.70 samples/sec#011loss=1.060962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch[550] avg_epoch_loss=1.259798\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=550 train loss <loss>=1.1479232549667358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch [550]#011Speed: 1122.21 samples/sec#011loss=1.147923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] processed a total of 17658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717324.90128, \"EndTime\": 1620717342.524269, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17622.914791107178, \"count\": 1, \"min\": 17622.914791107178, \"max\": 17622.914791107178}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=1001.9798378111614 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, train loss <loss>=1.2600485670609751\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_6f71a84d-24a2-4dbf-9567-8b5c633193d7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717342.524426, \"EndTime\": 1620717342.5346668, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.489774703979492, \"count\": 1, \"min\": 9.489774703979492, \"max\": 9.489774703979492}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[6] Batch[0] avg_epoch_loss=1.102250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=1.1022497415542603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[6] Batch[5] avg_epoch_loss=1.285740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=1.2857404748598735\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[6] Batch [5]#011Speed: 1341.05 samples/sec#011loss=1.285740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[6] Batch[10] avg_epoch_loss=1.210768\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=1.1208012104034424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[6] Batch [10]#011Speed: 854.50 samples/sec#011loss=1.120801\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch[15] avg_epoch_loss=1.154471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=15 train loss <loss>=1.03061603307724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch [15]#011Speed: 1359.09 samples/sec#011loss=1.030616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch[20] avg_epoch_loss=1.122149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=20 train loss <loss>=1.0187183022499084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch [20]#011Speed: 872.43 samples/sec#011loss=1.018718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch[25] avg_epoch_loss=1.102561\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=25 train loss <loss>=1.0202925562858582\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch [25]#011Speed: 1197.22 samples/sec#011loss=1.020293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch[30] avg_epoch_loss=1.141125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=30 train loss <loss>=1.3416593313217162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch [30]#011Speed: 504.42 samples/sec#011loss=1.341659\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch[35] avg_epoch_loss=1.166529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=35 train loss <loss>=1.324034285545349\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch [35]#011Speed: 847.82 samples/sec#011loss=1.324034\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch[40] avg_epoch_loss=1.208673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=40 train loss <loss>=1.5121105432510376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch [40]#011Speed: 633.67 samples/sec#011loss=1.512111\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch[45] avg_epoch_loss=1.218190\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=45 train loss <loss>=1.2962233066558837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch [45]#011Speed: 1354.48 samples/sec#011loss=1.296223\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch[50] avg_epoch_loss=1.222676\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=50 train loss <loss>=1.2639504194259643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch [50]#011Speed: 875.42 samples/sec#011loss=1.263950\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch[55] avg_epoch_loss=1.213466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=55 train loss <loss>=1.1195289850234986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch [55]#011Speed: 1259.63 samples/sec#011loss=1.119529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch[60] avg_epoch_loss=1.206938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=60 train loss <loss>=1.1338140726089478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch [60]#011Speed: 617.13 samples/sec#011loss=1.133814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch[65] avg_epoch_loss=1.212473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=65 train loss <loss>=1.2800008296966552\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch [65]#011Speed: 1099.24 samples/sec#011loss=1.280001\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch[70] avg_epoch_loss=1.212157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=70 train loss <loss>=1.2079939365386962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch [70]#011Speed: 855.25 samples/sec#011loss=1.207994\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch[75] avg_epoch_loss=1.205535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=75 train loss <loss>=1.1114991784095765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch [75]#011Speed: 1356.19 samples/sec#011loss=1.111499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch[80] avg_epoch_loss=1.206291\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=80 train loss <loss>=1.217785406112671\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch [80]#011Speed: 808.96 samples/sec#011loss=1.217785\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch[85] avg_epoch_loss=1.208470\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=85 train loss <loss>=1.2437751293182373\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch [85]#011Speed: 1264.62 samples/sec#011loss=1.243775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch[90] avg_epoch_loss=1.268742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=90 train loss <loss>=2.305406963825226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch [90]#011Speed: 811.42 samples/sec#011loss=2.305407\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch[95] avg_epoch_loss=1.267089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=95 train loss <loss>=1.237001657485962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch [95]#011Speed: 1352.43 samples/sec#011loss=1.237002\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch[100] avg_epoch_loss=1.264325\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=100 train loss <loss>=1.2112600803375244\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch [100]#011Speed: 767.22 samples/sec#011loss=1.211260\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch[105] avg_epoch_loss=1.266202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=105 train loss <loss>=1.3041212797164916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch [105]#011Speed: 1315.17 samples/sec#011loss=1.304121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch[110] avg_epoch_loss=1.273715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=110 train loss <loss>=1.432996964454651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch [110]#011Speed: 880.16 samples/sec#011loss=1.432997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch[115] avg_epoch_loss=1.267852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=115 train loss <loss>=1.1376930475234985\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch [115]#011Speed: 1215.87 samples/sec#011loss=1.137693\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch[120] avg_epoch_loss=1.263256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=120 train loss <loss>=1.1566114544868469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch [120]#011Speed: 831.09 samples/sec#011loss=1.156611\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch[125] avg_epoch_loss=1.262673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=125 train loss <loss>=1.248574423789978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch [125]#011Speed: 1371.04 samples/sec#011loss=1.248574\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[130] avg_epoch_loss=1.254026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=130 train loss <loss>=1.0361281752586364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [130]#011Speed: 844.05 samples/sec#011loss=1.036128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[135] avg_epoch_loss=1.249857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=135 train loss <loss>=1.1406158685684205\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [135]#011Speed: 1358.99 samples/sec#011loss=1.140616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[140] avg_epoch_loss=1.246910\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=140 train loss <loss>=1.16674702167511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [140]#011Speed: 860.15 samples/sec#011loss=1.166747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[145] avg_epoch_loss=1.250531\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=145 train loss <loss>=1.3526482820510863\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [145]#011Speed: 1358.65 samples/sec#011loss=1.352648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[150] avg_epoch_loss=1.242800\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=150 train loss <loss>=1.0170606136322022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [150]#011Speed: 788.90 samples/sec#011loss=1.017061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[155] avg_epoch_loss=1.235052\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=155 train loss <loss>=1.0010712146759033\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [155]#011Speed: 1324.18 samples/sec#011loss=1.001071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[160] avg_epoch_loss=1.232997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=160 train loss <loss>=1.1688789129257202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [160]#011Speed: 854.86 samples/sec#011loss=1.168879\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch[165] avg_epoch_loss=1.229415\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=165 train loss <loss>=1.1140759706497192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch [165]#011Speed: 1289.92 samples/sec#011loss=1.114076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch[170] avg_epoch_loss=1.226431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=170 train loss <loss>=1.1273509740829468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch [170]#011Speed: 835.74 samples/sec#011loss=1.127351\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch[175] avg_epoch_loss=1.227321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=175 train loss <loss>=1.2577655553817748\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch [175]#011Speed: 1362.31 samples/sec#011loss=1.257766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch[180] avg_epoch_loss=1.223382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=180 train loss <loss>=1.0847232222557068\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch [180]#011Speed: 766.56 samples/sec#011loss=1.084723\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch[185] avg_epoch_loss=1.223820\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=185 train loss <loss>=1.2396875619888306\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch [185]#011Speed: 1327.84 samples/sec#011loss=1.239688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch[190] avg_epoch_loss=1.227052\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=190 train loss <loss>=1.347277283668518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch [190]#011Speed: 795.34 samples/sec#011loss=1.347277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch[195] avg_epoch_loss=1.228495\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=195 train loss <loss>=1.2836182594299317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch [195]#011Speed: 1326.23 samples/sec#011loss=1.283618\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch[200] avg_epoch_loss=1.235060\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=200 train loss <loss>=1.4924192428588867\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch [200]#011Speed: 840.90 samples/sec#011loss=1.492419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch[205] avg_epoch_loss=1.253526\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=205 train loss <loss>=1.995837426185608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch [205]#011Speed: 1334.40 samples/sec#011loss=1.995837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch[210] avg_epoch_loss=1.263908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=210 train loss <loss>=1.691664457321167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch [210]#011Speed: 813.25 samples/sec#011loss=1.691664\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch[215] avg_epoch_loss=1.268737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=215 train loss <loss>=1.4725284099578857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch [215]#011Speed: 1299.53 samples/sec#011loss=1.472528\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch[220] avg_epoch_loss=1.270370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=220 train loss <loss>=1.3408852577209474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch [220]#011Speed: 545.55 samples/sec#011loss=1.340885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch[225] avg_epoch_loss=1.271705\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=225 train loss <loss>=1.330724334716797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch [225]#011Speed: 1314.02 samples/sec#011loss=1.330724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch[230] avg_epoch_loss=1.270977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=230 train loss <loss>=1.2380711317062378\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch [230]#011Speed: 848.05 samples/sec#011loss=1.238071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch[235] avg_epoch_loss=1.286380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=235 train loss <loss>=1.9980099678039551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch [235]#011Speed: 1322.41 samples/sec#011loss=1.998010\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch[240] avg_epoch_loss=1.284182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=240 train loss <loss>=1.1804015159606933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch [240]#011Speed: 793.85 samples/sec#011loss=1.180402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch[245] avg_epoch_loss=1.281413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=245 train loss <loss>=1.1479856252670289\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch [245]#011Speed: 1316.25 samples/sec#011loss=1.147986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch[250] avg_epoch_loss=1.278681\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=250 train loss <loss>=1.1442556619644164\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch [250]#011Speed: 836.73 samples/sec#011loss=1.144256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch[255] avg_epoch_loss=1.276411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=255 train loss <loss>=1.162478518486023\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch [255]#011Speed: 1317.01 samples/sec#011loss=1.162479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch[260] avg_epoch_loss=1.275503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=260 train loss <loss>=1.2290128231048585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch [260]#011Speed: 820.45 samples/sec#011loss=1.229013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch[265] avg_epoch_loss=1.283748\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=265 train loss <loss>=1.7141282558441162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch [265]#011Speed: 1371.26 samples/sec#011loss=1.714128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch[270] avg_epoch_loss=1.294548\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=270 train loss <loss>=1.8691116571426392\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch [270]#011Speed: 858.23 samples/sec#011loss=1.869112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch[275] avg_epoch_loss=1.291254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=275 train loss <loss>=1.1127177953720093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch [275]#011Speed: 1257.04 samples/sec#011loss=1.112718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch[280] avg_epoch_loss=1.288310\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=280 train loss <loss>=1.1257898092269898\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch [280]#011Speed: 848.39 samples/sec#011loss=1.125790\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[285] avg_epoch_loss=1.285314\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=285 train loss <loss>=1.1169332027435304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [285]#011Speed: 1314.41 samples/sec#011loss=1.116933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[290] avg_epoch_loss=1.282175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=290 train loss <loss>=1.1026313304901123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [290]#011Speed: 837.83 samples/sec#011loss=1.102631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[295] avg_epoch_loss=1.278798\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=295 train loss <loss>=1.0822400093078612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [295]#011Speed: 1356.14 samples/sec#011loss=1.082240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[300] avg_epoch_loss=1.274426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=300 train loss <loss>=1.0156419396400451\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [300]#011Speed: 872.78 samples/sec#011loss=1.015642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[305] avg_epoch_loss=1.274023\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=305 train loss <loss>=1.2497605562210083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [305]#011Speed: 1246.03 samples/sec#011loss=1.249761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[310] avg_epoch_loss=1.271611\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=310 train loss <loss>=1.1239505767822267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [310]#011Speed: 854.57 samples/sec#011loss=1.123951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[315] avg_epoch_loss=1.279636\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=315 train loss <loss>=1.778791880607605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [315]#011Speed: 1363.63 samples/sec#011loss=1.778792\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch[320] avg_epoch_loss=1.277358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=320 train loss <loss>=1.1334031820297241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch [320]#011Speed: 856.54 samples/sec#011loss=1.133403\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch[325] avg_epoch_loss=1.276293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=325 train loss <loss>=1.2079347133636475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch [325]#011Speed: 1301.25 samples/sec#011loss=1.207935\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch[330] avg_epoch_loss=1.275240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=330 train loss <loss>=1.2065797328948975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch [330]#011Speed: 866.31 samples/sec#011loss=1.206580\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch[335] avg_epoch_loss=1.273246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=335 train loss <loss>=1.1412063837051392\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch [335]#011Speed: 1370.73 samples/sec#011loss=1.141206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch[340] avg_epoch_loss=1.270413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=340 train loss <loss>=1.0800971269607544\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch [340]#011Speed: 826.90 samples/sec#011loss=1.080097\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch[345] avg_epoch_loss=1.267943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=345 train loss <loss>=1.0994686365127564\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch [345]#011Speed: 1364.49 samples/sec#011loss=1.099469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[350] avg_epoch_loss=1.266132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=350 train loss <loss>=1.1408063888549804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [350]#011Speed: 852.26 samples/sec#011loss=1.140806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[355] avg_epoch_loss=1.262468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=355 train loss <loss>=1.005265200138092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [355]#011Speed: 1313.49 samples/sec#011loss=1.005265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[360] avg_epoch_loss=1.259970\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=360 train loss <loss>=1.0820652365684509\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [360]#011Speed: 862.47 samples/sec#011loss=1.082065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[365] avg_epoch_loss=1.259456\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=365 train loss <loss>=1.2224032282829285\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [365]#011Speed: 1378.71 samples/sec#011loss=1.222403\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[370] avg_epoch_loss=1.255671\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=370 train loss <loss>=0.978585171699524\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [370]#011Speed: 814.78 samples/sec#011loss=0.978585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[375] avg_epoch_loss=1.253774\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=375 train loss <loss>=1.1130251169204712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [375]#011Speed: 1371.84 samples/sec#011loss=1.113025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[380] avg_epoch_loss=1.256279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=380 train loss <loss>=1.444653058052063\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [380]#011Speed: 752.42 samples/sec#011loss=1.444653\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch[385] avg_epoch_loss=1.252441\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=385 train loss <loss>=0.9599414825439453\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch [385]#011Speed: 826.87 samples/sec#011loss=0.959941\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch[390] avg_epoch_loss=1.249884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=390 train loss <loss>=1.0524823188781738\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch [390]#011Speed: 824.95 samples/sec#011loss=1.052482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch[395] avg_epoch_loss=1.246579\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=395 train loss <loss>=0.9881485819816589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch [395]#011Speed: 1345.75 samples/sec#011loss=0.988149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch[400] avg_epoch_loss=1.242664\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=400 train loss <loss>=0.9326163172721863\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch [400]#011Speed: 768.18 samples/sec#011loss=0.932616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch[405] avg_epoch_loss=1.240759\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=405 train loss <loss>=1.08799649477005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch [405]#011Speed: 1269.89 samples/sec#011loss=1.087996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[410] avg_epoch_loss=1.237221\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=410 train loss <loss>=0.9499072670936585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [410]#011Speed: 808.86 samples/sec#011loss=0.949907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[415] avg_epoch_loss=1.235596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=415 train loss <loss>=1.1020413517951966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [415]#011Speed: 1352.16 samples/sec#011loss=1.102041\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[420] avg_epoch_loss=1.235659\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=420 train loss <loss>=1.240854549407959\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [420]#011Speed: 847.45 samples/sec#011loss=1.240855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[425] avg_epoch_loss=1.232247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=425 train loss <loss>=0.9449854254722595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [425]#011Speed: 1340.61 samples/sec#011loss=0.944985\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[430] avg_epoch_loss=1.231999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=430 train loss <loss>=1.2109062433242799\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [430]#011Speed: 862.65 samples/sec#011loss=1.210906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[435] avg_epoch_loss=1.231377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=435 train loss <loss>=1.177693510055542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [435]#011Speed: 1216.92 samples/sec#011loss=1.177694\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[440] avg_epoch_loss=1.230956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=440 train loss <loss>=1.1942971110343934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [440]#011Speed: 831.29 samples/sec#011loss=1.194297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch[445] avg_epoch_loss=1.229728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=445 train loss <loss>=1.1213773250579835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch [445]#011Speed: 1316.14 samples/sec#011loss=1.121377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch[450] avg_epoch_loss=1.226854\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=450 train loss <loss>=0.9705368161201477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch [450]#011Speed: 855.39 samples/sec#011loss=0.970537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch[455] avg_epoch_loss=1.225488\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=455 train loss <loss>=1.1022768020629883\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch [455]#011Speed: 1347.74 samples/sec#011loss=1.102277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch[460] avg_epoch_loss=1.224376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=460 train loss <loss>=1.1229016184806824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch [460]#011Speed: 876.79 samples/sec#011loss=1.122902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch[465] avg_epoch_loss=1.221784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=465 train loss <loss>=0.9828758478164673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch [465]#011Speed: 1171.10 samples/sec#011loss=0.982876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch[470] avg_epoch_loss=1.221768\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=470 train loss <loss>=1.2202656745910645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch [470]#011Speed: 860.65 samples/sec#011loss=1.220266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[475] avg_epoch_loss=1.233801\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=475 train loss <loss>=2.3672322630882263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [475]#011Speed: 1368.11 samples/sec#011loss=2.367232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[480] avg_epoch_loss=1.233954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=480 train loss <loss>=1.2485323429107666\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [480]#011Speed: 816.51 samples/sec#011loss=1.248532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[485] avg_epoch_loss=1.233530\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=485 train loss <loss>=1.1927481651306153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [485]#011Speed: 1373.62 samples/sec#011loss=1.192748\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[490] avg_epoch_loss=1.234192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=490 train loss <loss>=1.2985690355300903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [490]#011Speed: 865.55 samples/sec#011loss=1.298569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[495] avg_epoch_loss=1.233274\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=495 train loss <loss>=1.1430814027786256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [495]#011Speed: 1363.83 samples/sec#011loss=1.143081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[500] avg_epoch_loss=1.231818\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=500 train loss <loss>=1.0874413013458253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [500]#011Speed: 803.50 samples/sec#011loss=1.087441\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[505] avg_epoch_loss=1.231312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=505 train loss <loss>=1.180580723285675\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [505]#011Speed: 1338.83 samples/sec#011loss=1.180581\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch[510] avg_epoch_loss=1.229057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=510 train loss <loss>=1.0008270263671875\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch [510]#011Speed: 860.15 samples/sec#011loss=1.000827\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch[515] avg_epoch_loss=1.226877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=515 train loss <loss>=1.0041272282600402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch [515]#011Speed: 1311.94 samples/sec#011loss=1.004127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch[520] avg_epoch_loss=1.225533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=520 train loss <loss>=1.0868736863136292\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch [520]#011Speed: 850.31 samples/sec#011loss=1.086874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch[525] avg_epoch_loss=1.223255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=525 train loss <loss>=0.9858634829521179\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch [525]#011Speed: 1382.27 samples/sec#011loss=0.985863\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch[530] avg_epoch_loss=1.221725\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=530 train loss <loss>=1.0607390403747559\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch [530]#011Speed: 783.88 samples/sec#011loss=1.060739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch[535] avg_epoch_loss=1.220651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=535 train loss <loss>=1.1066262483596803\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch [535]#011Speed: 1370.25 samples/sec#011loss=1.106626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[6] Batch[540] avg_epoch_loss=1.219340\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=540 train loss <loss>=1.0788007140159608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[6] Batch [540]#011Speed: 610.54 samples/sec#011loss=1.078801\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[6] Batch[545] avg_epoch_loss=1.219634\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=545 train loss <loss>=1.2514257788658143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[6] Batch [545]#011Speed: 775.97 samples/sec#011loss=1.251426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[6] Batch[550] avg_epoch_loss=1.220864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=550 train loss <loss>=1.3551444292068482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[6] Batch [550]#011Speed: 805.14 samples/sec#011loss=1.355144\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] processed a total of 17669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717342.5347297, \"EndTime\": 1620717360.5969174, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 18062.083959579468, \"count\": 1, \"min\": 18062.083959579468, \"max\": 18062.083959579468}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=978.2314221695659 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, train loss <loss>=1.2209775296947625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_fdaa35cc-cfad-42fc-b79d-5bf824b9c7a4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717360.5969875, \"EndTime\": 1620717360.6069279, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.435415267944336, \"count\": 1, \"min\": 9.435415267944336, \"max\": 9.435415267944336}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[7] Batch[0] avg_epoch_loss=1.102039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=1.1020385026931763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[7] Batch[5] avg_epoch_loss=1.052074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=1.05207355817159\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[7] Batch [5]#011Speed: 1105.82 samples/sec#011loss=1.052074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[10] avg_epoch_loss=1.118799\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=1.1988701343536377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [10]#011Speed: 827.27 samples/sec#011loss=1.198870\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[15] avg_epoch_loss=1.103774\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=15 train loss <loss>=1.0707199335098267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [15]#011Speed: 1290.36 samples/sec#011loss=1.070720\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[20] avg_epoch_loss=1.080394\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=20 train loss <loss>=1.0055774569511413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [20]#011Speed: 839.51 samples/sec#011loss=1.005577\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[25] avg_epoch_loss=1.089356\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=25 train loss <loss>=1.1269929885864258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [25]#011Speed: 1335.84 samples/sec#011loss=1.126993\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[30] avg_epoch_loss=1.096863\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=30 train loss <loss>=1.1359016299247742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [30]#011Speed: 846.94 samples/sec#011loss=1.135902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[35] avg_epoch_loss=1.105255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=35 train loss <loss>=1.157288408279419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [35]#011Speed: 1243.59 samples/sec#011loss=1.157288\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[40] avg_epoch_loss=1.096693\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=40 train loss <loss>=1.035046935081482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [40]#011Speed: 833.19 samples/sec#011loss=1.035047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch[45] avg_epoch_loss=1.091015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=45 train loss <loss>=1.0444485187530517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch [45]#011Speed: 505.07 samples/sec#011loss=1.044449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch[50] avg_epoch_loss=1.109043\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=50 train loss <loss>=1.274900460243225\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch [50]#011Speed: 548.52 samples/sec#011loss=1.274900\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch[55] avg_epoch_loss=1.104923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=55 train loss <loss>=1.0629021883010865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch [55]#011Speed: 1203.30 samples/sec#011loss=1.062902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch[60] avg_epoch_loss=1.104824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=60 train loss <loss>=1.103713321685791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch [60]#011Speed: 806.78 samples/sec#011loss=1.103713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[65] avg_epoch_loss=1.105091\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=65 train loss <loss>=1.1083482265472413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [65]#011Speed: 1345.95 samples/sec#011loss=1.108348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[70] avg_epoch_loss=1.104089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=70 train loss <loss>=1.0908694505691527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [70]#011Speed: 839.54 samples/sec#011loss=1.090869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[75] avg_epoch_loss=1.101820\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=75 train loss <loss>=1.069601547718048\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [75]#011Speed: 1329.63 samples/sec#011loss=1.069602\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[80] avg_epoch_loss=1.103316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=80 train loss <loss>=1.1260426998138429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [80]#011Speed: 842.50 samples/sec#011loss=1.126043\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[85] avg_epoch_loss=1.093499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=85 train loss <loss>=0.9344653964042664\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [85]#011Speed: 1361.36 samples/sec#011loss=0.934465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[90] avg_epoch_loss=1.208093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=90 train loss <loss>=3.179115915298462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [90]#011Speed: 782.44 samples/sec#011loss=3.179116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[95] avg_epoch_loss=1.232363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=95 train loss <loss>=1.6740705490112304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [95]#011Speed: 1310.69 samples/sec#011loss=1.674071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch[100] avg_epoch_loss=1.243816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=100 train loss <loss>=1.4637139081954955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch [100]#011Speed: 849.09 samples/sec#011loss=1.463714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch[105] avg_epoch_loss=1.255677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=105 train loss <loss>=1.4952784538269044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch [105]#011Speed: 1095.58 samples/sec#011loss=1.495278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch[110] avg_epoch_loss=1.264797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=110 train loss <loss>=1.458134126663208\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch [110]#011Speed: 490.58 samples/sec#011loss=1.458134\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch[115] avg_epoch_loss=1.273417\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=115 train loss <loss>=1.464790439605713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch [115]#011Speed: 737.93 samples/sec#011loss=1.464790\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch[120] avg_epoch_loss=1.278269\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=120 train loss <loss>=1.3908278942108154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch [120]#011Speed: 513.00 samples/sec#011loss=1.390828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch[125] avg_epoch_loss=1.279078\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=125 train loss <loss>=1.298645305633545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch [125]#011Speed: 1361.65 samples/sec#011loss=1.298645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch[130] avg_epoch_loss=1.276370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=130 train loss <loss>=1.2081377267837525\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch [130]#011Speed: 829.88 samples/sec#011loss=1.208138\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch[135] avg_epoch_loss=1.272575\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=135 train loss <loss>=1.1731439352035522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch [135]#011Speed: 785.43 samples/sec#011loss=1.173144\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch[140] avg_epoch_loss=1.265988\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=140 train loss <loss>=1.0868150234222411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch [140]#011Speed: 422.18 samples/sec#011loss=1.086815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch[145] avg_epoch_loss=1.270797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=145 train loss <loss>=1.4064194440841675\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch [145]#011Speed: 760.66 samples/sec#011loss=1.406419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch[150] avg_epoch_loss=1.264147\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=150 train loss <loss>=1.0699841260910035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch [150]#011Speed: 494.85 samples/sec#011loss=1.069984\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch[155] avg_epoch_loss=1.259594\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=155 train loss <loss>=1.1220916986465455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch [155]#011Speed: 756.08 samples/sec#011loss=1.122092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch[160] avg_epoch_loss=1.263504\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=160 train loss <loss>=1.385477614402771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch [160]#011Speed: 494.42 samples/sec#011loss=1.385478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch[165] avg_epoch_loss=1.255401\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=165 train loss <loss>=0.9944855690002441\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch [165]#011Speed: 857.47 samples/sec#011loss=0.994486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch[170] avg_epoch_loss=1.250163\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=170 train loss <loss>=1.0762680053710938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch [170]#011Speed: 497.20 samples/sec#011loss=1.076268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch[175] avg_epoch_loss=1.241661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=175 train loss <loss>=0.9509009957313538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch [175]#011Speed: 772.15 samples/sec#011loss=0.950901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch[180] avg_epoch_loss=1.235155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=180 train loss <loss>=1.0061460971832275\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch [180]#011Speed: 529.41 samples/sec#011loss=1.006146\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch[185] avg_epoch_loss=1.237646\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=185 train loss <loss>=1.3278074860572815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch [185]#011Speed: 1376.25 samples/sec#011loss=1.327807\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch[190] avg_epoch_loss=1.248303\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=190 train loss <loss>=1.644739818572998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch [190]#011Speed: 872.40 samples/sec#011loss=1.644740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch[195] avg_epoch_loss=1.276791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=195 train loss <loss>=2.365052914619446\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch [195]#011Speed: 1190.98 samples/sec#011loss=2.365053\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch[200] avg_epoch_loss=1.276830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=200 train loss <loss>=1.2783298254013062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch [200]#011Speed: 855.59 samples/sec#011loss=1.278330\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch[205] avg_epoch_loss=1.278940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=205 train loss <loss>=1.363762378692627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch [205]#011Speed: 1312.10 samples/sec#011loss=1.363762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch[210] avg_epoch_loss=1.280366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=210 train loss <loss>=1.3391271352767944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch [210]#011Speed: 796.46 samples/sec#011loss=1.339127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch[215] avg_epoch_loss=1.280856\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=215 train loss <loss>=1.3015296936035157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch [215]#011Speed: 1348.34 samples/sec#011loss=1.301530\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch[220] avg_epoch_loss=1.280240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=220 train loss <loss>=1.2536452770233155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch [220]#011Speed: 862.20 samples/sec#011loss=1.253645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch[225] avg_epoch_loss=1.278220\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=225 train loss <loss>=1.1889219760894776\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch [225]#011Speed: 1354.60 samples/sec#011loss=1.188922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch[230] avg_epoch_loss=1.275838\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=230 train loss <loss>=1.1681614875793458\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch [230]#011Speed: 854.50 samples/sec#011loss=1.168161\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch[235] avg_epoch_loss=1.272709\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=235 train loss <loss>=1.1281487226486206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch [235]#011Speed: 1361.06 samples/sec#011loss=1.128149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch[240] avg_epoch_loss=1.267172\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=240 train loss <loss>=1.0058167338371278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch [240]#011Speed: 767.85 samples/sec#011loss=1.005817\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch[245] avg_epoch_loss=1.261999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=245 train loss <loss>=1.0127063751220704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch [245]#011Speed: 1359.60 samples/sec#011loss=1.012706\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch[250] avg_epoch_loss=1.257621\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=250 train loss <loss>=1.0421804785728455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch [250]#011Speed: 834.99 samples/sec#011loss=1.042180\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch[255] avg_epoch_loss=1.256443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=255 train loss <loss>=1.1973092198371886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch [255]#011Speed: 1365.37 samples/sec#011loss=1.197309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch[260] avg_epoch_loss=1.259922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=260 train loss <loss>=1.4380678415298462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch [260]#011Speed: 849.39 samples/sec#011loss=1.438068\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch[265] avg_epoch_loss=1.254779\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=265 train loss <loss>=0.98628830909729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch [265]#011Speed: 1356.35 samples/sec#011loss=0.986288\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch[270] avg_epoch_loss=1.251420\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=270 train loss <loss>=1.0727446913719176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch [270]#011Speed: 652.11 samples/sec#011loss=1.072745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch[275] avg_epoch_loss=1.268268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=275 train loss <loss>=2.1814017057418824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch [275]#011Speed: 1048.33 samples/sec#011loss=2.181402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch[280] avg_epoch_loss=1.266158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=280 train loss <loss>=1.1497368335723877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch [280]#011Speed: 752.47 samples/sec#011loss=1.149737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch[285] avg_epoch_loss=1.266051\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=285 train loss <loss>=1.2600306510925292\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch [285]#011Speed: 1348.35 samples/sec#011loss=1.260031\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch[290] avg_epoch_loss=1.264284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=290 train loss <loss>=1.1632087469100951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch [290]#011Speed: 820.44 samples/sec#011loss=1.163209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch[295] avg_epoch_loss=1.264460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=295 train loss <loss>=1.2747018814086915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch [295]#011Speed: 1319.31 samples/sec#011loss=1.274702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[300] avg_epoch_loss=1.262466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=300 train loss <loss>=1.1444212675094605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [300]#011Speed: 796.70 samples/sec#011loss=1.144421\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[305] avg_epoch_loss=1.261254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=305 train loss <loss>=1.1882685422897339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [305]#011Speed: 1282.87 samples/sec#011loss=1.188269\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[310] avg_epoch_loss=1.259959\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=310 train loss <loss>=1.1807273626327515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [310]#011Speed: 867.39 samples/sec#011loss=1.180727\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[315] avg_epoch_loss=1.256805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=315 train loss <loss>=1.0606006503105163\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [315]#011Speed: 1367.46 samples/sec#011loss=1.060601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[320] avg_epoch_loss=1.255262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=320 train loss <loss>=1.1577602863311767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [320]#011Speed: 850.08 samples/sec#011loss=1.157760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[325] avg_epoch_loss=1.253954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=325 train loss <loss>=1.1699575901031494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [325]#011Speed: 1346.86 samples/sec#011loss=1.169958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[330] avg_epoch_loss=1.252213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=330 train loss <loss>=1.1387073278427124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [330]#011Speed: 862.24 samples/sec#011loss=1.138707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch[335] avg_epoch_loss=1.249007\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=335 train loss <loss>=1.0367954611778258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch [335]#011Speed: 1243.17 samples/sec#011loss=1.036795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch[340] avg_epoch_loss=1.246113\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=340 train loss <loss>=1.0516493201255799\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch [340]#011Speed: 851.79 samples/sec#011loss=1.051649\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch[345] avg_epoch_loss=1.244382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=345 train loss <loss>=1.12629314661026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch [345]#011Speed: 1372.70 samples/sec#011loss=1.126293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch[350] avg_epoch_loss=1.240405\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=350 train loss <loss>=0.9652140498161316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch [350]#011Speed: 850.73 samples/sec#011loss=0.965214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch[355] avg_epoch_loss=1.240952\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=355 train loss <loss>=1.2793522357940674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch [355]#011Speed: 1319.62 samples/sec#011loss=1.279352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch[360] avg_epoch_loss=1.239314\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=360 train loss <loss>=1.1226968169212341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch [360]#011Speed: 841.72 samples/sec#011loss=1.122697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch[365] avg_epoch_loss=1.237571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=365 train loss <loss>=1.1117440223693849\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch [365]#011Speed: 1257.25 samples/sec#011loss=1.111744\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch[370] avg_epoch_loss=1.239482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=370 train loss <loss>=1.3793116927146911\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch [370]#011Speed: 544.05 samples/sec#011loss=1.379312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch[375] avg_epoch_loss=1.239617\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=375 train loss <loss>=1.2496373414993287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch [375]#011Speed: 848.19 samples/sec#011loss=1.249637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch[380] avg_epoch_loss=1.238611\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=380 train loss <loss>=1.16294686794281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch [380]#011Speed: 617.59 samples/sec#011loss=1.162947\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch[385] avg_epoch_loss=1.236451\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=385 train loss <loss>=1.0718721747398376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch [385]#011Speed: 1356.19 samples/sec#011loss=1.071872\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[390] avg_epoch_loss=1.233274\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=390 train loss <loss>=0.9880045533180237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [390]#011Speed: 767.73 samples/sec#011loss=0.988005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[395] avg_epoch_loss=1.235459\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=395 train loss <loss>=1.4063725471496582\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [395]#011Speed: 1295.07 samples/sec#011loss=1.406373\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[400] avg_epoch_loss=1.234299\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=400 train loss <loss>=1.1423911094665526\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [400]#011Speed: 830.46 samples/sec#011loss=1.142391\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[405] avg_epoch_loss=1.231923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=405 train loss <loss>=1.0413501262664795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [405]#011Speed: 1335.89 samples/sec#011loss=1.041350\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[410] avg_epoch_loss=1.229786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=410 train loss <loss>=1.0562950372695923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [410]#011Speed: 864.75 samples/sec#011loss=1.056295\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[415] avg_epoch_loss=1.227289\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=415 train loss <loss>=1.0220707297325133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [415]#011Speed: 1366.66 samples/sec#011loss=1.022071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[420] avg_epoch_loss=1.226482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=420 train loss <loss>=1.159303879737854\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [420]#011Speed: 835.43 samples/sec#011loss=1.159304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch[425] avg_epoch_loss=1.224346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=425 train loss <loss>=1.0445268988609313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch [425]#011Speed: 1020.71 samples/sec#011loss=1.044527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch[430] avg_epoch_loss=1.222743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=430 train loss <loss>=1.0861154556274415\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch [430]#011Speed: 701.29 samples/sec#011loss=1.086115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch[435] avg_epoch_loss=1.224255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=435 train loss <loss>=1.3545716762542725\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch [435]#011Speed: 1179.25 samples/sec#011loss=1.354572\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch[440] avg_epoch_loss=1.222446\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=440 train loss <loss>=1.064713752269745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch [440]#011Speed: 848.61 samples/sec#011loss=1.064714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch[445] avg_epoch_loss=1.220869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=445 train loss <loss>=1.0818342804908752\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch [445]#011Speed: 1348.19 samples/sec#011loss=1.081834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[450] avg_epoch_loss=1.219567\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=450 train loss <loss>=1.1033507704734802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [450]#011Speed: 839.34 samples/sec#011loss=1.103351\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[455] avg_epoch_loss=1.221033\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=455 train loss <loss>=1.3532626628875732\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [455]#011Speed: 1236.99 samples/sec#011loss=1.353263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[460] avg_epoch_loss=1.220442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=460 train loss <loss>=1.1665980100631714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [460]#011Speed: 824.80 samples/sec#011loss=1.166598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[465] avg_epoch_loss=1.218961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=465 train loss <loss>=1.0823760509490967\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [465]#011Speed: 1361.44 samples/sec#011loss=1.082376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[470] avg_epoch_loss=1.216426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=470 train loss <loss>=0.9801885962486268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [470]#011Speed: 843.87 samples/sec#011loss=0.980189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[475] avg_epoch_loss=1.214724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=475 train loss <loss>=1.0544370889663697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [475]#011Speed: 1287.71 samples/sec#011loss=1.054437\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[480] avg_epoch_loss=1.212236\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=480 train loss <loss>=0.9753236293792724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [480]#011Speed: 849.00 samples/sec#011loss=0.975324\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch[485] avg_epoch_loss=1.214439\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=485 train loss <loss>=1.4263409972190857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch [485]#011Speed: 1221.34 samples/sec#011loss=1.426341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch[490] avg_epoch_loss=1.215697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=490 train loss <loss>=1.3379872560501098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch [490]#011Speed: 830.51 samples/sec#011loss=1.337987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch[495] avg_epoch_loss=1.214190\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=495 train loss <loss>=1.066230881214142\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch [495]#011Speed: 1359.35 samples/sec#011loss=1.066231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch[500] avg_epoch_loss=1.212137\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=500 train loss <loss>=1.0084755063056945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch [500]#011Speed: 847.13 samples/sec#011loss=1.008476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch[505] avg_epoch_loss=1.210431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=505 train loss <loss>=1.0394826173782348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch [505]#011Speed: 1315.83 samples/sec#011loss=1.039483\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch[510] avg_epoch_loss=1.208891\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=510 train loss <loss>=1.0530263662338257\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch [510]#011Speed: 833.96 samples/sec#011loss=1.053026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[515] avg_epoch_loss=1.208217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=515 train loss <loss>=1.139312195777893\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [515]#011Speed: 1353.73 samples/sec#011loss=1.139312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[520] avg_epoch_loss=1.206230\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=520 train loss <loss>=1.001208519935608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [520]#011Speed: 803.24 samples/sec#011loss=1.001209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[525] avg_epoch_loss=1.204983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=525 train loss <loss>=1.0750566720962524\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [525]#011Speed: 1320.45 samples/sec#011loss=1.075057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[530] avg_epoch_loss=1.202676\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=530 train loss <loss>=0.9599546432495117\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [530]#011Speed: 860.49 samples/sec#011loss=0.959955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[535] avg_epoch_loss=1.204289\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=535 train loss <loss>=1.3756592869758606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [535]#011Speed: 1371.23 samples/sec#011loss=1.375659\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[540] avg_epoch_loss=1.203262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=540 train loss <loss>=1.093112325668335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [540]#011Speed: 919.89 samples/sec#011loss=1.093112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[545] avg_epoch_loss=1.200940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=545 train loss <loss>=0.9497390747070312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [545]#011Speed: 1362.17 samples/sec#011loss=0.949739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] processed a total of 17548 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717360.6069915, \"EndTime\": 1620717380.0171654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 19410.11095046997, \"count\": 1, \"min\": 19410.11095046997, \"max\": 19410.11095046997}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=904.0568371748502 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, train loss <loss>=1.1999961616563015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_3b4e50f4-9087-41f9-a50e-d5c79f61b6ba-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717380.0173016, \"EndTime\": 1620717380.0284007, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.373353958129883, \"count\": 1, \"min\": 10.373353958129883, \"max\": 10.373353958129883}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch[0] avg_epoch_loss=1.039583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=1.03958261013031\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch[5] avg_epoch_loss=1.036236\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=1.0362363457679749\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch [5]#011Speed: 1333.83 samples/sec#011loss=1.036236\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch[10] avg_epoch_loss=0.993206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=0.941569697856903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch [10]#011Speed: 802.98 samples/sec#011loss=0.941570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch[15] avg_epoch_loss=1.050928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=15 train loss <loss>=1.1779156804084778\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch [15]#011Speed: 1360.38 samples/sec#011loss=1.177916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch[20] avg_epoch_loss=1.067241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=20 train loss <loss>=1.1194446325302123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch [20]#011Speed: 853.77 samples/sec#011loss=1.119445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch[25] avg_epoch_loss=1.077845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=25 train loss <loss>=1.1223817706108092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch [25]#011Speed: 1313.25 samples/sec#011loss=1.122382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch[30] avg_epoch_loss=1.086982\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=30 train loss <loss>=1.1344940662384033\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch [30]#011Speed: 826.53 samples/sec#011loss=1.134494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch[35] avg_epoch_loss=1.095834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=35 train loss <loss>=1.150717067718506\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch [35]#011Speed: 1164.72 samples/sec#011loss=1.150717\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch[40] avg_epoch_loss=1.094512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=40 train loss <loss>=1.0849953651428224\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch [40]#011Speed: 629.38 samples/sec#011loss=1.084995\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch[45] avg_epoch_loss=1.093012\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=45 train loss <loss>=1.0807113528251648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch [45]#011Speed: 1342.90 samples/sec#011loss=1.080711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch[50] avg_epoch_loss=1.095417\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=50 train loss <loss>=1.1175428748130798\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch [50]#011Speed: 837.96 samples/sec#011loss=1.117543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch[55] avg_epoch_loss=1.100869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=55 train loss <loss>=1.156474781036377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch [55]#011Speed: 1340.06 samples/sec#011loss=1.156475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch[60] avg_epoch_loss=1.101201\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=60 train loss <loss>=1.1049270749092102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch [60]#011Speed: 829.36 samples/sec#011loss=1.104927\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch[65] avg_epoch_loss=1.110835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=65 train loss <loss>=1.2283591985702516\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch [65]#011Speed: 1201.78 samples/sec#011loss=1.228359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch[70] avg_epoch_loss=1.105247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=70 train loss <loss>=1.0314926266670228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch [70]#011Speed: 842.74 samples/sec#011loss=1.031493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch[75] avg_epoch_loss=1.106250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=75 train loss <loss>=1.1204850316047668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch [75]#011Speed: 1334.08 samples/sec#011loss=1.120485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch[80] avg_epoch_loss=1.104010\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=80 train loss <loss>=1.0699642300605774\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch [80]#011Speed: 846.03 samples/sec#011loss=1.069964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch[85] avg_epoch_loss=1.107942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=85 train loss <loss>=1.1716498017311097\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch [85]#011Speed: 1355.93 samples/sec#011loss=1.171650\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[90] avg_epoch_loss=1.109479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=90 train loss <loss>=1.1359044551849364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [90]#011Speed: 857.94 samples/sec#011loss=1.135904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[95] avg_epoch_loss=1.118060\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=95 train loss <loss>=1.27423437833786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [95]#011Speed: 1347.40 samples/sec#011loss=1.274234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[100] avg_epoch_loss=1.113119\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=100 train loss <loss>=1.018255066871643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [100]#011Speed: 794.29 samples/sec#011loss=1.018255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[105] avg_epoch_loss=1.175767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=105 train loss <loss>=2.4412645578384398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [105]#011Speed: 1370.29 samples/sec#011loss=2.441265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[110] avg_epoch_loss=1.174845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=110 train loss <loss>=1.1552971601486206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [110]#011Speed: 874.00 samples/sec#011loss=1.155297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[115] avg_epoch_loss=1.178482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=115 train loss <loss>=1.2592284440994264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [115]#011Speed: 1301.38 samples/sec#011loss=1.259228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[120] avg_epoch_loss=1.178597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=120 train loss <loss>=1.1812655687332154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [120]#011Speed: 844.78 samples/sec#011loss=1.181266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch[125] avg_epoch_loss=1.177577\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=125 train loss <loss>=1.1528944969177246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch [125]#011Speed: 1358.42 samples/sec#011loss=1.152894\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch[130] avg_epoch_loss=1.173874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=130 train loss <loss>=1.0805550575256349\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch [130]#011Speed: 808.24 samples/sec#011loss=1.080555\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch[135] avg_epoch_loss=1.172729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=135 train loss <loss>=1.1427334785461425\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch [135]#011Speed: 1362.90 samples/sec#011loss=1.142733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch[140] avg_epoch_loss=1.174576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=140 train loss <loss>=1.2247879266738892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch [140]#011Speed: 820.08 samples/sec#011loss=1.224788\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch[145] avg_epoch_loss=1.168689\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=145 train loss <loss>=1.0027024865150451\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch [145]#011Speed: 1360.97 samples/sec#011loss=1.002702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch[150] avg_epoch_loss=1.165213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=150 train loss <loss>=1.0637009501457215\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch [150]#011Speed: 854.68 samples/sec#011loss=1.063701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch[155] avg_epoch_loss=1.164166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=155 train loss <loss>=1.1325406074523925\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch [155]#011Speed: 1355.99 samples/sec#011loss=1.132541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch[160] avg_epoch_loss=1.160384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=160 train loss <loss>=1.0423766493797302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch [160]#011Speed: 575.01 samples/sec#011loss=1.042377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch[165] avg_epoch_loss=1.159731\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=165 train loss <loss>=1.1387144804000855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch [165]#011Speed: 1087.55 samples/sec#011loss=1.138714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch[170] avg_epoch_loss=1.159641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=170 train loss <loss>=1.156655728816986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch [170]#011Speed: 839.63 samples/sec#011loss=1.156656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch[175] avg_epoch_loss=1.154098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=175 train loss <loss>=0.9645320177078247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch [175]#011Speed: 1321.45 samples/sec#011loss=0.964532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch[180] avg_epoch_loss=1.158389\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=180 train loss <loss>=1.3094240069389342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch [180]#011Speed: 840.61 samples/sec#011loss=1.309424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch[185] avg_epoch_loss=1.153568\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=185 train loss <loss>=0.9790367603302002\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch [185]#011Speed: 1205.12 samples/sec#011loss=0.979037\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch[190] avg_epoch_loss=1.149523\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=190 train loss <loss>=0.9990558862686157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch [190]#011Speed: 655.06 samples/sec#011loss=0.999056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch[195] avg_epoch_loss=1.163445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=195 train loss <loss>=1.695276129245758\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch [195]#011Speed: 777.32 samples/sec#011loss=1.695276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch[200] avg_epoch_loss=1.167297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=200 train loss <loss>=1.318299150466919\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch [200]#011Speed: 760.11 samples/sec#011loss=1.318299\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch[205] avg_epoch_loss=1.167691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=205 train loss <loss>=1.1835355520248414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch [205]#011Speed: 1349.53 samples/sec#011loss=1.183536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[210] avg_epoch_loss=1.173287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=210 train loss <loss>=1.4038155555725098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [210]#011Speed: 853.50 samples/sec#011loss=1.403816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[215] avg_epoch_loss=1.172136\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=215 train loss <loss>=1.1235957622528077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [215]#011Speed: 1224.50 samples/sec#011loss=1.123596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[220] avg_epoch_loss=1.169420\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=220 train loss <loss>=1.052073347568512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [220]#011Speed: 800.83 samples/sec#011loss=1.052073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[225] avg_epoch_loss=1.166678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=225 train loss <loss>=1.0454883217811584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [225]#011Speed: 1363.02 samples/sec#011loss=1.045488\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[230] avg_epoch_loss=1.164911\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=230 train loss <loss>=1.0850545406341552\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [230]#011Speed: 864.69 samples/sec#011loss=1.085055\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[235] avg_epoch_loss=1.184599\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=235 train loss <loss>=2.0941876649856566\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [235]#011Speed: 1297.75 samples/sec#011loss=2.094188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[240] avg_epoch_loss=1.182987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=240 train loss <loss>=1.1069018125534058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [240]#011Speed: 813.16 samples/sec#011loss=1.106902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch[245] avg_epoch_loss=1.182796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=245 train loss <loss>=1.1735527753829955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch [245]#011Speed: 1353.54 samples/sec#011loss=1.173553\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch[250] avg_epoch_loss=1.181780\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=250 train loss <loss>=1.1318134307861327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch [250]#011Speed: 812.03 samples/sec#011loss=1.131813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch[255] avg_epoch_loss=1.180839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=255 train loss <loss>=1.133593702316284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch [255]#011Speed: 1334.49 samples/sec#011loss=1.133594\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch[260] avg_epoch_loss=1.179677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=260 train loss <loss>=1.1201954126358031\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch [260]#011Speed: 825.32 samples/sec#011loss=1.120195\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch[265] avg_epoch_loss=1.194164\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=265 train loss <loss>=1.9503593444824219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch [265]#011Speed: 1298.01 samples/sec#011loss=1.950359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch[270] avg_epoch_loss=1.193355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=270 train loss <loss>=1.150333857536316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch [270]#011Speed: 838.38 samples/sec#011loss=1.150334\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[275] avg_epoch_loss=1.190968\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=275 train loss <loss>=1.0615883827209474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [275]#011Speed: 1350.69 samples/sec#011loss=1.061588\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[280] avg_epoch_loss=1.187825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=280 train loss <loss>=1.014358150959015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [280]#011Speed: 848.84 samples/sec#011loss=1.014358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[285] avg_epoch_loss=1.184578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=285 train loss <loss>=1.0020635008811951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [285]#011Speed: 1250.23 samples/sec#011loss=1.002064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[290] avg_epoch_loss=1.180741\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=290 train loss <loss>=0.9612534165382385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [290]#011Speed: 826.66 samples/sec#011loss=0.961253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[295] avg_epoch_loss=1.179775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=295 train loss <loss>=1.1235867977142333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [295]#011Speed: 1373.34 samples/sec#011loss=1.123587\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[300] avg_epoch_loss=1.178777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=300 train loss <loss>=1.1196950793266296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [300]#011Speed: 879.09 samples/sec#011loss=1.119695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[305] avg_epoch_loss=1.177824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=305 train loss <loss>=1.1204546689987183\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [305]#011Speed: 1352.30 samples/sec#011loss=1.120455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch[310] avg_epoch_loss=1.176205\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=310 train loss <loss>=1.0771085500717164\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch [310]#011Speed: 802.64 samples/sec#011loss=1.077109\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch[315] avg_epoch_loss=1.186459\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=315 train loss <loss>=1.8242642879486084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch [315]#011Speed: 1265.93 samples/sec#011loss=1.824264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch[320] avg_epoch_loss=1.185022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=320 train loss <loss>=1.0942039966583252\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch [320]#011Speed: 843.54 samples/sec#011loss=1.094204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch[325] avg_epoch_loss=1.183896\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=325 train loss <loss>=1.111574125289917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch [325]#011Speed: 1365.68 samples/sec#011loss=1.111574\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch[330] avg_epoch_loss=1.183568\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=330 train loss <loss>=1.1622186541557311\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch [330]#011Speed: 843.93 samples/sec#011loss=1.162219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch[335] avg_epoch_loss=1.181077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=335 train loss <loss>=1.0161906003952026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch [335]#011Speed: 1337.67 samples/sec#011loss=1.016191\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch[340] avg_epoch_loss=1.178906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=340 train loss <loss>=1.0329797744750977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch [340]#011Speed: 820.77 samples/sec#011loss=1.032980\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch[345] avg_epoch_loss=1.175507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=345 train loss <loss>=0.9437127113342285\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch [345]#011Speed: 1246.63 samples/sec#011loss=0.943713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch[350] avg_epoch_loss=1.172754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=350 train loss <loss>=0.9822677969932556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch [350]#011Speed: 765.67 samples/sec#011loss=0.982268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch[355] avg_epoch_loss=1.173860\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=355 train loss <loss>=1.2514979481697082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch [355]#011Speed: 1275.82 samples/sec#011loss=1.251498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch[360] avg_epoch_loss=1.171797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=360 train loss <loss>=1.0249037384986877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch [360]#011Speed: 601.54 samples/sec#011loss=1.024904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch[365] avg_epoch_loss=1.173997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=365 train loss <loss>=1.3328400611877442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch [365]#011Speed: 1343.18 samples/sec#011loss=1.332840\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch[370] avg_epoch_loss=1.174040\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=370 train loss <loss>=1.1771909713745117\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch [370]#011Speed: 851.88 samples/sec#011loss=1.177191\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch[375] avg_epoch_loss=1.182360\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=375 train loss <loss>=1.7996625185012818\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch [375]#011Speed: 1307.17 samples/sec#011loss=1.799663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch[380] avg_epoch_loss=1.183514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=380 train loss <loss>=1.2702970266342164\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch [380]#011Speed: 789.77 samples/sec#011loss=1.270297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch[385] avg_epoch_loss=1.184212\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=385 train loss <loss>=1.2373996019363402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch [385]#011Speed: 1362.36 samples/sec#011loss=1.237400\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch[390] avg_epoch_loss=1.184653\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=390 train loss <loss>=1.2187434673309325\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch [390]#011Speed: 833.94 samples/sec#011loss=1.218743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch[395] avg_epoch_loss=1.184431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=395 train loss <loss>=1.1670199394226075\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch [395]#011Speed: 1343.82 samples/sec#011loss=1.167020\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch[400] avg_epoch_loss=1.183260\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=400 train loss <loss>=1.0905145406723022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch [400]#011Speed: 825.25 samples/sec#011loss=1.090515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch[405] avg_epoch_loss=1.181557\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=405 train loss <loss>=1.0449682831764222\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch [405]#011Speed: 1355.78 samples/sec#011loss=1.044968\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch[410] avg_epoch_loss=1.181558\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=410 train loss <loss>=1.1816956520080566\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch [410]#011Speed: 817.37 samples/sec#011loss=1.181696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch[415] avg_epoch_loss=1.179891\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=415 train loss <loss>=1.0428395509719848\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch [415]#011Speed: 1358.27 samples/sec#011loss=1.042840\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch[420] avg_epoch_loss=1.179943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=420 train loss <loss>=1.1842761635780334\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch [420]#011Speed: 808.50 samples/sec#011loss=1.184276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch[425] avg_epoch_loss=1.179422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=425 train loss <loss>=1.1355121850967407\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch [425]#011Speed: 1290.60 samples/sec#011loss=1.135512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[430] avg_epoch_loss=1.177009\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=430 train loss <loss>=0.9714294791221618\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [430]#011Speed: 826.00 samples/sec#011loss=0.971429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[435] avg_epoch_loss=1.176406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=435 train loss <loss>=1.1244733572006225\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [435]#011Speed: 1364.32 samples/sec#011loss=1.124473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[440] avg_epoch_loss=1.174990\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=440 train loss <loss>=1.051451075077057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [440]#011Speed: 849.31 samples/sec#011loss=1.051451\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[445] avg_epoch_loss=1.175248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=445 train loss <loss>=1.1980541586875915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [445]#011Speed: 1124.70 samples/sec#011loss=1.198054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[450] avg_epoch_loss=1.172920\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=450 train loss <loss>=0.9652335524559021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [450]#011Speed: 859.93 samples/sec#011loss=0.965234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[455] avg_epoch_loss=1.171384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=455 train loss <loss>=1.032840943336487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [455]#011Speed: 1365.56 samples/sec#011loss=1.032841\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[460] avg_epoch_loss=1.169369\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=460 train loss <loss>=0.9856133699417114\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [460]#011Speed: 851.56 samples/sec#011loss=0.985613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch[465] avg_epoch_loss=1.186265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=465 train loss <loss>=2.744038224220276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch [465]#011Speed: 1268.11 samples/sec#011loss=2.744038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch[470] avg_epoch_loss=1.184756\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=470 train loss <loss>=1.044120717048645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch [470]#011Speed: 852.44 samples/sec#011loss=1.044121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch[475] avg_epoch_loss=1.183436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=475 train loss <loss>=1.0590895533561706\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch [475]#011Speed: 1246.49 samples/sec#011loss=1.059090\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch[480] avg_epoch_loss=1.182283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=480 train loss <loss>=1.0725120067596436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch [480]#011Speed: 822.79 samples/sec#011loss=1.072512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch[485] avg_epoch_loss=1.181298\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=485 train loss <loss>=1.0865420818328857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch [485]#011Speed: 1354.20 samples/sec#011loss=1.086542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch[490] avg_epoch_loss=1.179870\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=490 train loss <loss>=1.0410784244537354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch [490]#011Speed: 853.01 samples/sec#011loss=1.041078\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch[495] avg_epoch_loss=1.177757\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=495 train loss <loss>=0.9703274130821228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch [495]#011Speed: 1274.93 samples/sec#011loss=0.970327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch[500] avg_epoch_loss=1.176823\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=500 train loss <loss>=1.084175205230713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch [500]#011Speed: 828.01 samples/sec#011loss=1.084175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch[505] avg_epoch_loss=1.177158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=505 train loss <loss>=1.2106772303581237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch [505]#011Speed: 1354.05 samples/sec#011loss=1.210677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch[510] avg_epoch_loss=1.178730\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=510 train loss <loss>=1.3377936840057374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch [510]#011Speed: 741.65 samples/sec#011loss=1.337794\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch[515] avg_epoch_loss=1.176986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=515 train loss <loss>=0.9987629652023315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch [515]#011Speed: 1333.44 samples/sec#011loss=0.998763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch[520] avg_epoch_loss=1.175400\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=520 train loss <loss>=1.0117834091186524\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch [520]#011Speed: 613.93 samples/sec#011loss=1.011783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch[525] avg_epoch_loss=1.174248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=525 train loss <loss>=1.0541726708412171\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch [525]#011Speed: 1371.89 samples/sec#011loss=1.054173\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch[530] avg_epoch_loss=1.172351\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=530 train loss <loss>=0.9727334141731262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch [530]#011Speed: 851.36 samples/sec#011loss=0.972733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch[535] avg_epoch_loss=1.170915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=535 train loss <loss>=1.0184155702590942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch [535]#011Speed: 1306.11 samples/sec#011loss=1.018416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch[540] avg_epoch_loss=1.171069\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=540 train loss <loss>=1.187644362449646\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch [540]#011Speed: 960.45 samples/sec#011loss=1.187644\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch[545] avg_epoch_loss=1.169806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=545 train loss <loss>=1.033171570301056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch [545]#011Speed: 1367.66 samples/sec#011loss=1.033172\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] processed a total of 17447 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717380.02851, \"EndTime\": 1620717397.683204, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17654.630184173584, \"count\": 1, \"min\": 17654.630184173584, \"max\": 17654.630184173584}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=988.2294863239279 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, train loss <loss>=1.1698064283355252\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_99d7595c-ac85-43b8-8562-d82a9c6c8da7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717397.6832824, \"EndTime\": 1620717397.693364, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.396791458129883, \"count\": 1, \"min\": 9.396791458129883, \"max\": 9.396791458129883}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[9] Batch[0] avg_epoch_loss=1.170805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=1.170804500579834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[9] Batch[5] avg_epoch_loss=0.998538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=0.9985377689202627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[9] Batch [5]#011Speed: 1264.80 samples/sec#011loss=0.998538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch[10] avg_epoch_loss=0.977236\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=0.951674473285675\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch [10]#011Speed: 829.74 samples/sec#011loss=0.951674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch[15] avg_epoch_loss=0.949100\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=15 train loss <loss>=0.8871992945671081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch [15]#011Speed: 1329.50 samples/sec#011loss=0.887199\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch[20] avg_epoch_loss=0.966333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=20 train loss <loss>=1.021478283405304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch [20]#011Speed: 796.85 samples/sec#011loss=1.021478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch[25] avg_epoch_loss=0.977013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=25 train loss <loss>=1.0218705415725708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch [25]#011Speed: 1227.91 samples/sec#011loss=1.021871\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch[30] avg_epoch_loss=0.974455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=30 train loss <loss>=0.9611510276794434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch [30]#011Speed: 841.81 samples/sec#011loss=0.961151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch[35] avg_epoch_loss=0.998055\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=35 train loss <loss>=1.1443796515464784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch [35]#011Speed: 1302.31 samples/sec#011loss=1.144380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[40] avg_epoch_loss=1.014682\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=40 train loss <loss>=1.1343950271606444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [40]#011Speed: 831.68 samples/sec#011loss=1.134395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[45] avg_epoch_loss=1.027111\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=45 train loss <loss>=1.1290271878242493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [45]#011Speed: 1342.69 samples/sec#011loss=1.129027\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[50] avg_epoch_loss=1.042093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=50 train loss <loss>=1.179923450946808\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [50]#011Speed: 857.22 samples/sec#011loss=1.179923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[55] avg_epoch_loss=1.064588\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=55 train loss <loss>=1.2940365552902222\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [55]#011Speed: 1287.64 samples/sec#011loss=1.294037\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[60] avg_epoch_loss=1.065663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=60 train loss <loss>=1.077702236175537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [60]#011Speed: 821.25 samples/sec#011loss=1.077702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[65] avg_epoch_loss=1.063885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=65 train loss <loss>=1.042197823524475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [65]#011Speed: 1349.34 samples/sec#011loss=1.042198\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[70] avg_epoch_loss=1.080386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=70 train loss <loss>=1.298195767402649\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [70]#011Speed: 852.47 samples/sec#011loss=1.298196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch[75] avg_epoch_loss=1.077878\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=75 train loss <loss>=1.0422627329826355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch [75]#011Speed: 1306.13 samples/sec#011loss=1.042263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch[80] avg_epoch_loss=1.068079\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=80 train loss <loss>=0.9191354990005494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch [80]#011Speed: 659.17 samples/sec#011loss=0.919135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch[85] avg_epoch_loss=1.058999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=85 train loss <loss>=0.9119025826454162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch [85]#011Speed: 1311.00 samples/sec#011loss=0.911903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch[90] avg_epoch_loss=1.051209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=90 train loss <loss>=0.9172237396240235\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch [90]#011Speed: 796.58 samples/sec#011loss=0.917224\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch[95] avg_epoch_loss=1.041976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=95 train loss <loss>=0.8739474296569825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch [95]#011Speed: 1349.36 samples/sec#011loss=0.873947\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch[100] avg_epoch_loss=1.039996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=100 train loss <loss>=1.001961851119995\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch [100]#011Speed: 836.62 samples/sec#011loss=1.001962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch[105] avg_epoch_loss=1.039631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=105 train loss <loss>=1.0322750210762024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch [105]#011Speed: 1322.32 samples/sec#011loss=1.032275\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch[110] avg_epoch_loss=1.033955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=110 train loss <loss>=0.9136135101318359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch [110]#011Speed: 815.93 samples/sec#011loss=0.913614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch[115] avg_epoch_loss=1.033342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=115 train loss <loss>=1.0197318911552429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch [115]#011Speed: 1359.93 samples/sec#011loss=1.019732\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch[120] avg_epoch_loss=1.045311\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=120 train loss <loss>=1.3230019450187682\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch [120]#011Speed: 772.87 samples/sec#011loss=1.323002\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch[125] avg_epoch_loss=1.043450\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=125 train loss <loss>=0.9984181642532348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch [125]#011Speed: 1352.11 samples/sec#011loss=0.998418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch[130] avg_epoch_loss=1.049383\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=130 train loss <loss>=1.1988890767097473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch [130]#011Speed: 753.23 samples/sec#011loss=1.198889\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch[135] avg_epoch_loss=1.049042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=135 train loss <loss>=1.0400914549827576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch [135]#011Speed: 1155.18 samples/sec#011loss=1.040091\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch[140] avg_epoch_loss=1.090880\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=140 train loss <loss>=2.228872013092041\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch [140]#011Speed: 845.96 samples/sec#011loss=2.228872\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch[145] avg_epoch_loss=1.088192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=145 train loss <loss>=1.012415838241577\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch [145]#011Speed: 1341.99 samples/sec#011loss=1.012416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch[150] avg_epoch_loss=1.092701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=150 train loss <loss>=1.2243375778198242\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch [150]#011Speed: 801.04 samples/sec#011loss=1.224338\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch[155] avg_epoch_loss=1.094540\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=155 train loss <loss>=1.1500962495803833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch [155]#011Speed: 1346.75 samples/sec#011loss=1.150096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch[160] avg_epoch_loss=1.094603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=160 train loss <loss>=1.0965699553489685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch [160]#011Speed: 858.62 samples/sec#011loss=1.096570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[165] avg_epoch_loss=1.092596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=165 train loss <loss>=1.0279621720314025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [165]#011Speed: 1356.58 samples/sec#011loss=1.027962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[170] avg_epoch_loss=1.091770\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=170 train loss <loss>=1.064346432685852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [170]#011Speed: 835.65 samples/sec#011loss=1.064346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[175] avg_epoch_loss=1.088841\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=175 train loss <loss>=0.9886544346809387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [175]#011Speed: 1349.49 samples/sec#011loss=0.988654\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[180] avg_epoch_loss=1.088157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=180 train loss <loss>=1.0640934109687805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [180]#011Speed: 847.88 samples/sec#011loss=1.064093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[185] avg_epoch_loss=1.089617\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=185 train loss <loss>=1.142455017566681\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [185]#011Speed: 1153.01 samples/sec#011loss=1.142455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[190] avg_epoch_loss=1.107051\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=190 train loss <loss>=1.7556000113487245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [190]#011Speed: 838.38 samples/sec#011loss=1.755600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[195] avg_epoch_loss=1.119119\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=195 train loss <loss>=1.5801382899284362\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [195]#011Speed: 1278.56 samples/sec#011loss=1.580138\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch[200] avg_epoch_loss=1.125784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=200 train loss <loss>=1.3870440006256104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch [200]#011Speed: 858.38 samples/sec#011loss=1.387044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch[205] avg_epoch_loss=1.128574\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=205 train loss <loss>=1.2407277822494507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch [205]#011Speed: 1366.52 samples/sec#011loss=1.240728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch[210] avg_epoch_loss=1.130691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=210 train loss <loss>=1.2179224014282226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch [210]#011Speed: 861.09 samples/sec#011loss=1.217922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch[215] avg_epoch_loss=1.133214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=215 train loss <loss>=1.2396804809570312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch [215]#011Speed: 1209.78 samples/sec#011loss=1.239680\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch[220] avg_epoch_loss=1.131938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=220 train loss <loss>=1.0768072843551635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch [220]#011Speed: 649.40 samples/sec#011loss=1.076807\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch[225] avg_epoch_loss=1.147166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=225 train loss <loss>=1.8202452421188355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch [225]#011Speed: 855.36 samples/sec#011loss=1.820245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch[230] avg_epoch_loss=1.150285\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=230 train loss <loss>=1.2912736177444457\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch [230]#011Speed: 528.02 samples/sec#011loss=1.291274\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch[235] avg_epoch_loss=1.149770\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=235 train loss <loss>=1.1259599208831788\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch [235]#011Speed: 1360.30 samples/sec#011loss=1.125960\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch[240] avg_epoch_loss=1.149055\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=240 train loss <loss>=1.1153255343437194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch [240]#011Speed: 786.22 samples/sec#011loss=1.115326\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch[245] avg_epoch_loss=1.145104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=245 train loss <loss>=0.9546670317649841\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch [245]#011Speed: 1339.28 samples/sec#011loss=0.954667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch[250] avg_epoch_loss=1.141948\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=250 train loss <loss>=0.9866676449775695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch [250]#011Speed: 835.70 samples/sec#011loss=0.986668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch[255] avg_epoch_loss=1.141039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=255 train loss <loss>=1.0954177856445313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch [255]#011Speed: 1293.22 samples/sec#011loss=1.095418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch[260] avg_epoch_loss=1.140099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=260 train loss <loss>=1.0919639110565185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch [260]#011Speed: 821.14 samples/sec#011loss=1.091964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch[265] avg_epoch_loss=1.139385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=265 train loss <loss>=1.1021329522132874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch [265]#011Speed: 1374.12 samples/sec#011loss=1.102133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch[270] avg_epoch_loss=1.137605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=270 train loss <loss>=1.042897593975067\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch [270]#011Speed: 801.74 samples/sec#011loss=1.042898\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch[275] avg_epoch_loss=1.134482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=275 train loss <loss>=0.9652164816856384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch [275]#011Speed: 1297.04 samples/sec#011loss=0.965216\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch[280] avg_epoch_loss=1.129508\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=280 train loss <loss>=0.8549170613288879\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch [280]#011Speed: 806.48 samples/sec#011loss=0.854917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch[285] avg_epoch_loss=1.126786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=285 train loss <loss>=0.9738237261772156\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch [285]#011Speed: 1217.72 samples/sec#011loss=0.973824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch[290] avg_epoch_loss=1.124336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=290 train loss <loss>=0.9842075109481812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch [290]#011Speed: 678.59 samples/sec#011loss=0.984208\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch[295] avg_epoch_loss=1.123759\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=295 train loss <loss>=1.0901471853256226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch [295]#011Speed: 1338.54 samples/sec#011loss=1.090147\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch[300] avg_epoch_loss=1.125967\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=300 train loss <loss>=1.256700611114502\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch [300]#011Speed: 839.55 samples/sec#011loss=1.256701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch[305] avg_epoch_loss=1.126287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=305 train loss <loss>=1.1455289483070374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch [305]#011Speed: 1258.12 samples/sec#011loss=1.145529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch[310] avg_epoch_loss=1.125655\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=310 train loss <loss>=1.086968731880188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch [310]#011Speed: 836.62 samples/sec#011loss=1.086969\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch[315] avg_epoch_loss=1.135235\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=315 train loss <loss>=1.7311509370803833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch [315]#011Speed: 1355.33 samples/sec#011loss=1.731151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch[320] avg_epoch_loss=1.135179\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=320 train loss <loss>=1.1316413164138794\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch [320]#011Speed: 833.78 samples/sec#011loss=1.131641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch[325] avg_epoch_loss=1.135518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=325 train loss <loss>=1.1572545528411866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch [325]#011Speed: 1295.30 samples/sec#011loss=1.157255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch[330] avg_epoch_loss=1.134684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=330 train loss <loss>=1.0803051710128784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch [330]#011Speed: 837.10 samples/sec#011loss=1.080305\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch[335] avg_epoch_loss=1.133198\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=335 train loss <loss>=1.0348082423210143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch [335]#011Speed: 1128.61 samples/sec#011loss=1.034808\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch[340] avg_epoch_loss=1.130233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=340 train loss <loss>=0.9309995412826538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch [340]#011Speed: 815.96 samples/sec#011loss=0.931000\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[345] avg_epoch_loss=1.127597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=345 train loss <loss>=0.9478047728538513\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [345]#011Speed: 1287.54 samples/sec#011loss=0.947805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[350] avg_epoch_loss=1.125701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=350 train loss <loss>=0.9945625543594361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [350]#011Speed: 851.10 samples/sec#011loss=0.994563\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[355] avg_epoch_loss=1.124441\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=355 train loss <loss>=1.0359818816184998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [355]#011Speed: 1349.48 samples/sec#011loss=1.035982\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[360] avg_epoch_loss=1.126128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=360 train loss <loss>=1.2462327837944032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [360]#011Speed: 855.34 samples/sec#011loss=1.246233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[365] avg_epoch_loss=1.126141\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=365 train loss <loss>=1.1270769715309144\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [365]#011Speed: 1340.57 samples/sec#011loss=1.127077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[370] avg_epoch_loss=1.124105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=370 train loss <loss>=0.9750559806823731\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [370]#011Speed: 810.91 samples/sec#011loss=0.975056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[375] avg_epoch_loss=1.122355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=375 train loss <loss>=0.992490816116333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [375]#011Speed: 1355.08 samples/sec#011loss=0.992491\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch[380] avg_epoch_loss=1.129461\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=380 train loss <loss>=1.6638588547706603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch [380]#011Speed: 842.49 samples/sec#011loss=1.663859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch[385] avg_epoch_loss=1.130062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=385 train loss <loss>=1.17584331035614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch [385]#011Speed: 1345.42 samples/sec#011loss=1.175843\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch[390] avg_epoch_loss=1.129956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=390 train loss <loss>=1.1217361450195313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch [390]#011Speed: 775.98 samples/sec#011loss=1.121736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch[395] avg_epoch_loss=1.129187\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=395 train loss <loss>=1.0691075205802918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch [395]#011Speed: 1346.33 samples/sec#011loss=1.069108\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch[400] avg_epoch_loss=1.127584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=400 train loss <loss>=1.0005703926086427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch [400]#011Speed: 792.72 samples/sec#011loss=1.000570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch[405] avg_epoch_loss=1.129991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=405 train loss <loss>=1.323049247264862\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch [405]#011Speed: 1337.88 samples/sec#011loss=1.323049\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch[410] avg_epoch_loss=1.129405\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=410 train loss <loss>=1.0818235039711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch [410]#011Speed: 843.92 samples/sec#011loss=1.081824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch[415] avg_epoch_loss=1.127938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=415 train loss <loss>=1.0073879480361938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch [415]#011Speed: 1212.34 samples/sec#011loss=1.007388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch[420] avg_epoch_loss=1.137183\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=420 train loss <loss>=1.906321144104004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch [420]#011Speed: 857.54 samples/sec#011loss=1.906321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch[425] avg_epoch_loss=1.137333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=425 train loss <loss>=1.1499728918075562\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch [425]#011Speed: 1345.39 samples/sec#011loss=1.149973\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch[430] avg_epoch_loss=1.137935\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=430 train loss <loss>=1.1892539262771606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch [430]#011Speed: 775.09 samples/sec#011loss=1.189254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch[435] avg_epoch_loss=1.137338\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=435 train loss <loss>=1.0858741521835327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch [435]#011Speed: 1321.99 samples/sec#011loss=1.085874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch[440] avg_epoch_loss=1.136819\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=440 train loss <loss>=1.0915757775306703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch [440]#011Speed: 837.86 samples/sec#011loss=1.091576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch[445] avg_epoch_loss=1.135747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=445 train loss <loss>=1.0411500215530396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch [445]#011Speed: 1302.53 samples/sec#011loss=1.041150\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch[450] avg_epoch_loss=1.135083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=450 train loss <loss>=1.0759158372879027\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch [450]#011Speed: 643.06 samples/sec#011loss=1.075916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch[455] avg_epoch_loss=1.134909\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=455 train loss <loss>=1.1191540241241456\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch [455]#011Speed: 1318.07 samples/sec#011loss=1.119154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch[460] avg_epoch_loss=1.133691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=460 train loss <loss>=1.0226598024368285\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch [460]#011Speed: 796.69 samples/sec#011loss=1.022660\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch[465] avg_epoch_loss=1.132533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=465 train loss <loss>=1.0257149815559388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch [465]#011Speed: 1299.03 samples/sec#011loss=1.025715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[470] avg_epoch_loss=1.130677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=470 train loss <loss>=0.9577334880828857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [470]#011Speed: 854.09 samples/sec#011loss=0.957733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[475] avg_epoch_loss=1.145936\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=475 train loss <loss>=2.5832873582839966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [475]#011Speed: 1335.79 samples/sec#011loss=2.583287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[480] avg_epoch_loss=1.144271\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=480 train loss <loss>=0.9858061671257019\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [480]#011Speed: 842.89 samples/sec#011loss=0.985806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[485] avg_epoch_loss=1.143348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=485 train loss <loss>=1.0545894026756286\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [485]#011Speed: 1357.84 samples/sec#011loss=1.054589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[490] avg_epoch_loss=1.142260\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=490 train loss <loss>=1.036446213722229\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [490]#011Speed: 866.81 samples/sec#011loss=1.036446\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[495] avg_epoch_loss=1.140766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=495 train loss <loss>=0.9940580129623413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [495]#011Speed: 1230.50 samples/sec#011loss=0.994058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[500] avg_epoch_loss=1.139645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=500 train loss <loss>=1.0284518957138062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [500]#011Speed: 858.81 samples/sec#011loss=1.028452\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch[505] avg_epoch_loss=1.138165\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=505 train loss <loss>=0.9898720383644104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch [505]#011Speed: 1319.44 samples/sec#011loss=0.989872\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch[510] avg_epoch_loss=1.137734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=510 train loss <loss>=1.0940964341163635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch [510]#011Speed: 875.86 samples/sec#011loss=1.094096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch[515] avg_epoch_loss=1.136892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=515 train loss <loss>=1.0508328914642333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch [515]#011Speed: 1380.69 samples/sec#011loss=1.050833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch[520] avg_epoch_loss=1.134652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=520 train loss <loss>=0.9034939646720886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch [520]#011Speed: 857.50 samples/sec#011loss=0.903494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch[525] avg_epoch_loss=1.132250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=525 train loss <loss>=0.8819656729698181\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch [525]#011Speed: 1369.02 samples/sec#011loss=0.881966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch[530] avg_epoch_loss=1.129858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=530 train loss <loss>=0.8782430529594422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch [530]#011Speed: 812.14 samples/sec#011loss=0.878243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch[535] avg_epoch_loss=1.128059\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=535 train loss <loss>=0.9369762659072876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch [535]#011Speed: 1359.59 samples/sec#011loss=0.936976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch[540] avg_epoch_loss=1.127997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=540 train loss <loss>=1.1213817596435547\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch [540]#011Speed: 843.46 samples/sec#011loss=1.121382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch[545] avg_epoch_loss=1.128207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=545 train loss <loss>=1.1509323358535766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch [545]#011Speed: 1344.92 samples/sec#011loss=1.150932\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch[550] avg_epoch_loss=1.126735\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=550 train loss <loss>=0.9660319209098815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch [550]#011Speed: 1187.16 samples/sec#011loss=0.966032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] processed a total of 17661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717397.6934876, \"EndTime\": 1620717415.5047896, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17811.151266098022, \"count\": 1, \"min\": 17811.151266098022, \"max\": 17811.151266098022}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=991.5574332965368 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, train loss <loss>=1.1265391756011092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_c45c8404-cc09-4c11-a2a2-f8e82ff04c1c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717415.5049553, \"EndTime\": 1620717415.5155296, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.671449661254883, \"count\": 1, \"min\": 9.671449661254883, \"max\": 9.671449661254883}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[10] Batch[0] avg_epoch_loss=0.901921\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=0.9019213914871216\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[10] Batch[5] avg_epoch_loss=0.865864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=0.8658635715643564\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[10] Batch [5]#011Speed: 1306.44 samples/sec#011loss=0.865864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[10] Batch[10] avg_epoch_loss=0.905471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=0.9530003786087036\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[10] Batch [10]#011Speed: 786.79 samples/sec#011loss=0.953000\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch[15] avg_epoch_loss=0.916144\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=15 train loss <loss>=0.9396244645118713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch [15]#011Speed: 1355.17 samples/sec#011loss=0.939624\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch[20] avg_epoch_loss=0.921419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=20 train loss <loss>=0.9382966041564942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch [20]#011Speed: 820.03 samples/sec#011loss=0.938297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch[25] avg_epoch_loss=1.017010\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=25 train loss <loss>=1.4184955716133119\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch [25]#011Speed: 1359.13 samples/sec#011loss=1.418496\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch[30] avg_epoch_loss=1.026711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=30 train loss <loss>=1.077155065536499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch [30]#011Speed: 856.57 samples/sec#011loss=1.077155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch[35] avg_epoch_loss=1.026688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=35 train loss <loss>=1.0265453577041626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch [35]#011Speed: 1331.01 samples/sec#011loss=1.026545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch[40] avg_epoch_loss=1.025293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=40 train loss <loss>=1.0152513265609742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch [40]#011Speed: 777.60 samples/sec#011loss=1.015251\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch[45] avg_epoch_loss=1.015874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=45 train loss <loss>=0.9386318325996399\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch [45]#011Speed: 1296.21 samples/sec#011loss=0.938632\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch[50] avg_epoch_loss=1.019230\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=50 train loss <loss>=1.0501071572303773\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch [50]#011Speed: 820.45 samples/sec#011loss=1.050107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch[55] avg_epoch_loss=1.018116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=55 train loss <loss>=1.0067520260810852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch [55]#011Speed: 1372.07 samples/sec#011loss=1.006752\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch[60] avg_epoch_loss=1.020701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=60 train loss <loss>=1.049657368659973\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch [60]#011Speed: 634.93 samples/sec#011loss=1.049657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch[65] avg_epoch_loss=1.052008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=65 train loss <loss>=1.4339460611343384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch [65]#011Speed: 1355.85 samples/sec#011loss=1.433946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch[70] avg_epoch_loss=1.077327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=70 train loss <loss>=1.411542534828186\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch [70]#011Speed: 790.11 samples/sec#011loss=1.411543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[75] avg_epoch_loss=1.087614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=75 train loss <loss>=1.2336942434310914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [75]#011Speed: 1365.72 samples/sec#011loss=1.233694\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[80] avg_epoch_loss=1.088208\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=80 train loss <loss>=1.0972393989562987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [80]#011Speed: 839.44 samples/sec#011loss=1.097239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[85] avg_epoch_loss=1.112771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=85 train loss <loss>=1.5106884360313415\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [85]#011Speed: 1339.11 samples/sec#011loss=1.510688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[90] avg_epoch_loss=1.109488\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=90 train loss <loss>=1.0530166983604432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [90]#011Speed: 844.98 samples/sec#011loss=1.053017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[95] avg_epoch_loss=1.103182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=95 train loss <loss>=0.9884101152420044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [95]#011Speed: 1319.06 samples/sec#011loss=0.988410\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[100] avg_epoch_loss=1.129471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=100 train loss <loss>=1.6342183828353882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [100]#011Speed: 790.53 samples/sec#011loss=1.634218\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[105] avg_epoch_loss=1.133008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=105 train loss <loss>=1.2044533014297485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [105]#011Speed: 1240.96 samples/sec#011loss=1.204453\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch[110] avg_epoch_loss=1.133683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=110 train loss <loss>=1.1480037212371825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch [110]#011Speed: 825.11 samples/sec#011loss=1.148004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch[115] avg_epoch_loss=1.170018\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=115 train loss <loss>=1.9766409635543822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch [115]#011Speed: 1332.93 samples/sec#011loss=1.976641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch[120] avg_epoch_loss=1.168344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=120 train loss <loss>=1.1295196533203125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch [120]#011Speed: 872.07 samples/sec#011loss=1.129520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch[125] avg_epoch_loss=1.170372\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=125 train loss <loss>=1.219445037841797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch [125]#011Speed: 1360.17 samples/sec#011loss=1.219445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch[130] avg_epoch_loss=1.168949\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=130 train loss <loss>=1.1331037759780884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch [130]#011Speed: 848.25 samples/sec#011loss=1.133104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch[135] avg_epoch_loss=1.170198\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=135 train loss <loss>=1.2029208302497865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch [135]#011Speed: 1207.74 samples/sec#011loss=1.202921\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch[140] avg_epoch_loss=1.163743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=140 train loss <loss>=0.9881434082984925\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch [140]#011Speed: 791.16 samples/sec#011loss=0.988143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch[145] avg_epoch_loss=1.158546\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=145 train loss <loss>=1.011996293067932\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch [145]#011Speed: 1312.16 samples/sec#011loss=1.011996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch[150] avg_epoch_loss=1.189816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=150 train loss <loss>=2.1029135942459107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch [150]#011Speed: 837.21 samples/sec#011loss=2.102914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch[155] avg_epoch_loss=1.186464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=155 train loss <loss>=1.0852142572402954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch [155]#011Speed: 1285.71 samples/sec#011loss=1.085214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch[160] avg_epoch_loss=1.181313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=160 train loss <loss>=1.0206290483474731\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch [160]#011Speed: 824.72 samples/sec#011loss=1.020629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch[165] avg_epoch_loss=1.177034\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=165 train loss <loss>=1.039237105846405\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch [165]#011Speed: 1312.92 samples/sec#011loss=1.039237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch[170] avg_epoch_loss=1.171162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=170 train loss <loss>=0.9761968493461609\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch [170]#011Speed: 799.95 samples/sec#011loss=0.976197\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch[175] avg_epoch_loss=1.172135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=175 train loss <loss>=1.2054284811019897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch [175]#011Speed: 709.01 samples/sec#011loss=1.205428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch[180] avg_epoch_loss=1.167806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=180 train loss <loss>=1.015419864654541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch [180]#011Speed: 443.16 samples/sec#011loss=1.015420\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch[185] avg_epoch_loss=1.174273\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=185 train loss <loss>=1.408388602733612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch [185]#011Speed: 904.16 samples/sec#011loss=1.408389\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch[190] avg_epoch_loss=1.172569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=190 train loss <loss>=1.109165906906128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch [190]#011Speed: 496.19 samples/sec#011loss=1.109166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch[195] avg_epoch_loss=1.171674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=195 train loss <loss>=1.1375005006790162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch [195]#011Speed: 800.41 samples/sec#011loss=1.137501\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch[200] avg_epoch_loss=1.169947\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=200 train loss <loss>=1.1022197008132935\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch [200]#011Speed: 397.02 samples/sec#011loss=1.102220\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch[205] avg_epoch_loss=1.170520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=205 train loss <loss>=1.1935594201087951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch [205]#011Speed: 1069.12 samples/sec#011loss=1.193559\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch[210] avg_epoch_loss=1.169514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=210 train loss <loss>=1.1280729651451111\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch [210]#011Speed: 811.32 samples/sec#011loss=1.128073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch[215] avg_epoch_loss=1.165420\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=215 train loss <loss>=0.9926401376724243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch [215]#011Speed: 1370.59 samples/sec#011loss=0.992640\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch[220] avg_epoch_loss=1.161428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=220 train loss <loss>=0.9889744997024537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch [220]#011Speed: 671.82 samples/sec#011loss=0.988974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch[225] avg_epoch_loss=1.163292\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=225 train loss <loss>=1.2456790447235107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch [225]#011Speed: 723.32 samples/sec#011loss=1.245679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch[230] avg_epoch_loss=1.158536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=230 train loss <loss>=0.9436006546020508\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch [230]#011Speed: 489.23 samples/sec#011loss=0.943601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] Epoch[10] Batch[235] avg_epoch_loss=1.152427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=235 train loss <loss>=0.8701731920242309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] Epoch[10] Batch [235]#011Speed: 732.17 samples/sec#011loss=0.870173\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] Epoch[10] Batch[240] avg_epoch_loss=1.147585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=240 train loss <loss>=0.919051992893219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] Epoch[10] Batch [240]#011Speed: 514.83 samples/sec#011loss=0.919052\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] Epoch[10] Batch[245] avg_epoch_loss=1.145734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=245 train loss <loss>=1.056499457359314\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] Epoch[10] Batch [245]#011Speed: 744.09 samples/sec#011loss=1.056499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch[250] avg_epoch_loss=1.139626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=250 train loss <loss>=0.8391138076782226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch [250]#011Speed: 472.53 samples/sec#011loss=0.839114\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch[255] avg_epoch_loss=1.170655\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=255 train loss <loss>=2.728311836719513\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch [255]#011Speed: 692.67 samples/sec#011loss=2.728312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch[260] avg_epoch_loss=1.172414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=260 train loss <loss>=1.2624988794326781\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch [260]#011Speed: 538.69 samples/sec#011loss=1.262499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch[265] avg_epoch_loss=1.171203\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=265 train loss <loss>=1.1079831838607788\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch [265]#011Speed: 1236.10 samples/sec#011loss=1.107983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch[270] avg_epoch_loss=1.170503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=270 train loss <loss>=1.133233332633972\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch [270]#011Speed: 837.28 samples/sec#011loss=1.133233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch[275] avg_epoch_loss=1.170149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=275 train loss <loss>=1.150990629196167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch [275]#011Speed: 1126.67 samples/sec#011loss=1.150991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch[280] avg_epoch_loss=1.167893\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=280 train loss <loss>=1.0433367848396302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch [280]#011Speed: 828.95 samples/sec#011loss=1.043337\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch[285] avg_epoch_loss=1.164402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=285 train loss <loss>=0.9682324051856994\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch [285]#011Speed: 1295.60 samples/sec#011loss=0.968232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch[290] avg_epoch_loss=1.162494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=290 train loss <loss>=1.0533332228660583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch [290]#011Speed: 831.54 samples/sec#011loss=1.053333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch[295] avg_epoch_loss=1.159145\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=295 train loss <loss>=0.9642372846603393\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch [295]#011Speed: 1358.84 samples/sec#011loss=0.964237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch[300] avg_epoch_loss=1.156140\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=300 train loss <loss>=0.9782819747924805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch [300]#011Speed: 818.60 samples/sec#011loss=0.978282\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch[305] avg_epoch_loss=1.154332\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=305 train loss <loss>=1.0454866528511046\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch [305]#011Speed: 1278.00 samples/sec#011loss=1.045487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch[310] avg_epoch_loss=1.150338\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=310 train loss <loss>=0.9059083700180054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch [310]#011Speed: 822.18 samples/sec#011loss=0.905908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch[315] avg_epoch_loss=1.146455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=315 train loss <loss>=0.9049252510070801\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch [315]#011Speed: 1345.16 samples/sec#011loss=0.904925\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch[320] avg_epoch_loss=1.144069\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=320 train loss <loss>=0.9932819724082946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch [320]#011Speed: 836.04 samples/sec#011loss=0.993282\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch[325] avg_epoch_loss=1.141126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=325 train loss <loss>=0.9521263360977172\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch [325]#011Speed: 1363.73 samples/sec#011loss=0.952126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch[330] avg_epoch_loss=1.142712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=330 train loss <loss>=1.2461786270141602\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch [330]#011Speed: 657.89 samples/sec#011loss=1.246179\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[335] avg_epoch_loss=1.139433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=335 train loss <loss>=0.9223327994346618\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [335]#011Speed: 1361.97 samples/sec#011loss=0.922333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[340] avg_epoch_loss=1.137122\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=340 train loss <loss>=0.981857442855835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [340]#011Speed: 779.85 samples/sec#011loss=0.981857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[345] avg_epoch_loss=1.134505\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=345 train loss <loss>=0.9560099720954895\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [345]#011Speed: 1338.13 samples/sec#011loss=0.956010\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[350] avg_epoch_loss=1.131819\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=350 train loss <loss>=0.9459453463554383\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [350]#011Speed: 819.05 samples/sec#011loss=0.945945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[355] avg_epoch_loss=1.129121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=355 train loss <loss>=0.9397364020347595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [355]#011Speed: 1353.47 samples/sec#011loss=0.939736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[360] avg_epoch_loss=1.126256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=360 train loss <loss>=0.9222521781921387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [360]#011Speed: 849.06 samples/sec#011loss=0.922252\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[365] avg_epoch_loss=1.126317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=365 train loss <loss>=1.1307335257530213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [365]#011Speed: 1330.09 samples/sec#011loss=1.130734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch[370] avg_epoch_loss=1.127071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=370 train loss <loss>=1.1822471737861633\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch [370]#011Speed: 767.16 samples/sec#011loss=1.182247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch[375] avg_epoch_loss=1.125050\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=375 train loss <loss>=0.9750554323196411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch [375]#011Speed: 1353.69 samples/sec#011loss=0.975055\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch[380] avg_epoch_loss=1.122535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=380 train loss <loss>=0.933463704586029\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch [380]#011Speed: 838.35 samples/sec#011loss=0.933464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch[385] avg_epoch_loss=1.120277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=385 train loss <loss>=0.9481836676597595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch [385]#011Speed: 1346.46 samples/sec#011loss=0.948184\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch[390] avg_epoch_loss=1.118712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=390 train loss <loss>=0.9979102134704589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch [390]#011Speed: 863.15 samples/sec#011loss=0.997910\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch[395] avg_epoch_loss=1.119412\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=395 train loss <loss>=1.1741124749183656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch [395]#011Speed: 1356.74 samples/sec#011loss=1.174112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch[400] avg_epoch_loss=1.119729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=400 train loss <loss>=1.1448586940765382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch [400]#011Speed: 803.03 samples/sec#011loss=1.144859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch[405] avg_epoch_loss=1.120239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=405 train loss <loss>=1.1611648440361022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch [405]#011Speed: 1364.27 samples/sec#011loss=1.161165\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch[410] avg_epoch_loss=1.118380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=410 train loss <loss>=0.9674111723899841\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch [410]#011Speed: 846.15 samples/sec#011loss=0.967411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch[415] avg_epoch_loss=1.126792\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=415 train loss <loss>=1.8182317972183228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch [415]#011Speed: 1296.48 samples/sec#011loss=1.818232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch[420] avg_epoch_loss=1.126518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=420 train loss <loss>=1.1037386417388917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch [420]#011Speed: 873.73 samples/sec#011loss=1.103739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch[425] avg_epoch_loss=1.126003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=425 train loss <loss>=1.0826421976089478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch [425]#011Speed: 1324.41 samples/sec#011loss=1.082642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[430] avg_epoch_loss=1.125877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=430 train loss <loss>=1.1151516437530518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [430]#011Speed: 838.94 samples/sec#011loss=1.115152\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[435] avg_epoch_loss=1.124687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=435 train loss <loss>=1.022090232372284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [435]#011Speed: 1182.98 samples/sec#011loss=1.022090\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[440] avg_epoch_loss=1.123119\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=440 train loss <loss>=0.9864005208015442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [440]#011Speed: 843.84 samples/sec#011loss=0.986401\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[445] avg_epoch_loss=1.121687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=445 train loss <loss>=0.995348858833313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [445]#011Speed: 1292.62 samples/sec#011loss=0.995349\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[450] avg_epoch_loss=1.121660\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=450 train loss <loss>=1.119274413585663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [450]#011Speed: 853.40 samples/sec#011loss=1.119274\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[455] avg_epoch_loss=1.120939\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=455 train loss <loss>=1.0559378862380981\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [455]#011Speed: 1347.53 samples/sec#011loss=1.055938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[460] avg_epoch_loss=1.121222\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=460 train loss <loss>=1.146996808052063\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [460]#011Speed: 844.16 samples/sec#011loss=1.146997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch[465] avg_epoch_loss=1.134877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=465 train loss <loss>=2.393892157077789\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch [465]#011Speed: 1352.55 samples/sec#011loss=2.393892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch[470] avg_epoch_loss=1.134690\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=470 train loss <loss>=1.1172589540481568\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch [470]#011Speed: 817.18 samples/sec#011loss=1.117259\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch[475] avg_epoch_loss=1.134422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=475 train loss <loss>=1.1091310024261474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch [475]#011Speed: 1367.76 samples/sec#011loss=1.109131\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch[480] avg_epoch_loss=1.133820\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=480 train loss <loss>=1.0765249252319335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch [480]#011Speed: 861.23 samples/sec#011loss=1.076525\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch[485] avg_epoch_loss=1.132913\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=485 train loss <loss>=1.0457171678543091\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch [485]#011Speed: 1346.04 samples/sec#011loss=1.045717\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch[490] avg_epoch_loss=1.131450\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=490 train loss <loss>=0.9892154574394226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch [490]#011Speed: 649.86 samples/sec#011loss=0.989215\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[495] avg_epoch_loss=1.129470\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=495 train loss <loss>=0.9350264310836792\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [495]#011Speed: 1367.41 samples/sec#011loss=0.935026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[500] avg_epoch_loss=1.128699\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=500 train loss <loss>=1.0522448301315308\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [500]#011Speed: 818.18 samples/sec#011loss=1.052245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[505] avg_epoch_loss=1.126411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=505 train loss <loss>=0.8971303462982178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [505]#011Speed: 1342.86 samples/sec#011loss=0.897130\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[510] avg_epoch_loss=1.124156\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=510 train loss <loss>=0.8959341645240784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [510]#011Speed: 860.66 samples/sec#011loss=0.895934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[515] avg_epoch_loss=1.122549\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=515 train loss <loss>=0.9583521604537963\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [515]#011Speed: 1348.86 samples/sec#011loss=0.958352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[520] avg_epoch_loss=1.122885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=520 train loss <loss>=1.1575168251991272\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [520]#011Speed: 852.09 samples/sec#011loss=1.157517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[525] avg_epoch_loss=1.122692\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=525 train loss <loss>=1.102633500099182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [525]#011Speed: 1335.80 samples/sec#011loss=1.102634\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[10] Batch[530] avg_epoch_loss=1.122075\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=530 train loss <loss>=1.0571882724761963\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[10] Batch [530]#011Speed: 809.52 samples/sec#011loss=1.057188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[10] Batch[535] avg_epoch_loss=1.120604\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=535 train loss <loss>=0.964364230632782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[10] Batch [535]#011Speed: 1369.71 samples/sec#011loss=0.964364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[10] Batch[540] avg_epoch_loss=1.120615\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=540 train loss <loss>=1.1217184662818909\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[10] Batch [540]#011Speed: 1121.44 samples/sec#011loss=1.121718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] processed a total of 17410 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717415.5156744, \"EndTime\": 1620717434.5469275, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 19031.18658065796, \"count\": 1, \"min\": 19031.18658065796, \"max\": 19031.18658065796}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=914.8090227338512 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, train loss <loss>=1.1188817831354403\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_6b703284-f5c4-4df7-bb0f-bf8e06c6ba11-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717434.5470006, \"EndTime\": 1620717434.5570211, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.188413619995117, \"count\": 1, \"min\": 9.188413619995117, \"max\": 9.188413619995117}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[11] Batch[0] avg_epoch_loss=0.841986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=0.841985821723938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[11] Batch[5] avg_epoch_loss=0.916721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=0.916721115509669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[11] Batch [5]#011Speed: 1357.56 samples/sec#011loss=0.916721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[11] Batch[10] avg_epoch_loss=0.903590\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=0.8878321886062622\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[11] Batch [10]#011Speed: 819.20 samples/sec#011loss=0.887832\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch[15] avg_epoch_loss=0.900207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=15 train loss <loss>=0.8927656769752502\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch [15]#011Speed: 1358.87 samples/sec#011loss=0.892766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch[20] avg_epoch_loss=0.888910\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=20 train loss <loss>=0.8527597069740296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch [20]#011Speed: 811.11 samples/sec#011loss=0.852760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch[25] avg_epoch_loss=0.899512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=25 train loss <loss>=0.9440372943878174\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch [25]#011Speed: 1088.01 samples/sec#011loss=0.944037\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch[30] avg_epoch_loss=0.929762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=30 train loss <loss>=1.0870643734931946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch [30]#011Speed: 521.90 samples/sec#011loss=1.087064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch[35] avg_epoch_loss=0.948605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=35 train loss <loss>=1.0654295921325683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch [35]#011Speed: 845.73 samples/sec#011loss=1.065430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch[40] avg_epoch_loss=0.950289\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=40 train loss <loss>=0.9624164819717407\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch [40]#011Speed: 576.86 samples/sec#011loss=0.962416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch[45] avg_epoch_loss=0.943451\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=45 train loss <loss>=0.8873812794685364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch [45]#011Speed: 1339.42 samples/sec#011loss=0.887381\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch[50] avg_epoch_loss=0.933548\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=50 train loss <loss>=0.842434537410736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch [50]#011Speed: 787.39 samples/sec#011loss=0.842435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch[55] avg_epoch_loss=0.946160\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=55 train loss <loss>=1.074811041355133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch [55]#011Speed: 1330.85 samples/sec#011loss=1.074811\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch[60] avg_epoch_loss=0.956568\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=60 train loss <loss>=1.0731321573257446\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch [60]#011Speed: 845.28 samples/sec#011loss=1.073132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch[65] avg_epoch_loss=0.973783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=65 train loss <loss>=1.1838008642196656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch [65]#011Speed: 1353.32 samples/sec#011loss=1.183801\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch[70] avg_epoch_loss=0.977520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=70 train loss <loss>=1.026858377456665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch [70]#011Speed: 849.51 samples/sec#011loss=1.026858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch[75] avg_epoch_loss=0.980636\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=75 train loss <loss>=1.0248777866363525\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch [75]#011Speed: 1269.25 samples/sec#011loss=1.024878\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch[80] avg_epoch_loss=0.981518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=80 train loss <loss>=0.9949231505393982\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch [80]#011Speed: 850.98 samples/sec#011loss=0.994923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch[85] avg_epoch_loss=0.987975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=85 train loss <loss>=1.0925859928131103\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch [85]#011Speed: 1356.86 samples/sec#011loss=1.092586\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch[90] avg_epoch_loss=0.987909\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=90 train loss <loss>=0.9867731809616089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch [90]#011Speed: 843.21 samples/sec#011loss=0.986773\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch[95] avg_epoch_loss=0.991003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=95 train loss <loss>=1.0473020434379579\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch [95]#011Speed: 1361.76 samples/sec#011loss=1.047302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch[100] avg_epoch_loss=0.991541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=100 train loss <loss>=1.0018707871437074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch [100]#011Speed: 647.85 samples/sec#011loss=1.001871\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch[105] avg_epoch_loss=0.994808\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=105 train loss <loss>=1.0608165264129639\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch [105]#011Speed: 1208.88 samples/sec#011loss=1.060817\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch[110] avg_epoch_loss=0.999139\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=110 train loss <loss>=1.0909483432769775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch [110]#011Speed: 815.30 samples/sec#011loss=1.090948\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch[115] avg_epoch_loss=0.999074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=115 train loss <loss>=0.9976304650306702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch [115]#011Speed: 1363.89 samples/sec#011loss=0.997630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch[120] avg_epoch_loss=0.996057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=120 train loss <loss>=0.9260641813278199\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch [120]#011Speed: 846.07 samples/sec#011loss=0.926064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch[125] avg_epoch_loss=0.992898\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=125 train loss <loss>=0.9164579629898071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch [125]#011Speed: 1367.88 samples/sec#011loss=0.916458\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch[130] avg_epoch_loss=0.992578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=130 train loss <loss>=0.9844934940338135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch [130]#011Speed: 843.84 samples/sec#011loss=0.984493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch[135] avg_epoch_loss=0.989678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=135 train loss <loss>=0.913716721534729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch [135]#011Speed: 1361.31 samples/sec#011loss=0.913717\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch[140] avg_epoch_loss=0.990989\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=140 train loss <loss>=1.0266301155090332\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch [140]#011Speed: 808.41 samples/sec#011loss=1.026630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch[145] avg_epoch_loss=0.999093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=145 train loss <loss>=1.2276298761367799\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch [145]#011Speed: 1377.32 samples/sec#011loss=1.227630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch[150] avg_epoch_loss=0.998307\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=150 train loss <loss>=0.9753745675086976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch [150]#011Speed: 856.40 samples/sec#011loss=0.975375\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch[155] avg_epoch_loss=1.000486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=155 train loss <loss>=1.0662775993347169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch [155]#011Speed: 1343.87 samples/sec#011loss=1.066278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[160] avg_epoch_loss=0.998380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=160 train loss <loss>=0.9326583027839661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [160]#011Speed: 806.82 samples/sec#011loss=0.932658\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[165] avg_epoch_loss=0.998699\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=165 train loss <loss>=1.008981418609619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [165]#011Speed: 1337.04 samples/sec#011loss=1.008981\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[170] avg_epoch_loss=0.999168\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=170 train loss <loss>=1.0147318959236145\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [170]#011Speed: 805.86 samples/sec#011loss=1.014732\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[175] avg_epoch_loss=0.994398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=175 train loss <loss>=0.8312787055969239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [175]#011Speed: 1350.32 samples/sec#011loss=0.831279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[180] avg_epoch_loss=0.990845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=180 train loss <loss>=0.8657931566238404\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [180]#011Speed: 823.84 samples/sec#011loss=0.865793\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[185] avg_epoch_loss=0.990979\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=185 train loss <loss>=0.9957963109016419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [185]#011Speed: 1356.57 samples/sec#011loss=0.995796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[190] avg_epoch_loss=0.990430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=190 train loss <loss>=0.9700319409370423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [190]#011Speed: 852.42 samples/sec#011loss=0.970032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch[195] avg_epoch_loss=0.990409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=195 train loss <loss>=0.9895969986915588\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch [195]#011Speed: 1311.65 samples/sec#011loss=0.989597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch[200] avg_epoch_loss=0.990796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=200 train loss <loss>=1.0059666156768798\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch [200]#011Speed: 817.45 samples/sec#011loss=1.005967\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch[205] avg_epoch_loss=1.008296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=205 train loss <loss>=1.7118128180503844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch [205]#011Speed: 1241.05 samples/sec#011loss=1.711813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch[210] avg_epoch_loss=1.009864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=210 train loss <loss>=1.0744449377059937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch [210]#011Speed: 842.14 samples/sec#011loss=1.074445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch[215] avg_epoch_loss=1.012024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=215 train loss <loss>=1.1031695127487182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch [215]#011Speed: 1364.44 samples/sec#011loss=1.103170\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch[220] avg_epoch_loss=1.016753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=220 train loss <loss>=1.221053147315979\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch [220]#011Speed: 836.79 samples/sec#011loss=1.221053\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[225] avg_epoch_loss=1.016475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=225 train loss <loss>=1.00419442653656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [225]#011Speed: 1337.52 samples/sec#011loss=1.004194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[230] avg_epoch_loss=1.016412\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=230 train loss <loss>=1.0135593175888062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [230]#011Speed: 853.90 samples/sec#011loss=1.013559\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[235] avg_epoch_loss=1.016604\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=235 train loss <loss>=1.0254730224609374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [235]#011Speed: 1245.65 samples/sec#011loss=1.025473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[240] avg_epoch_loss=1.028385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=240 train loss <loss>=1.5844708323478698\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [240]#011Speed: 861.89 samples/sec#011loss=1.584471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[245] avg_epoch_loss=1.026781\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=245 train loss <loss>=0.9494678735733032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [245]#011Speed: 1361.99 samples/sec#011loss=0.949468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[250] avg_epoch_loss=1.025354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=250 train loss <loss>=0.9551161646842956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [250]#011Speed: 861.20 samples/sec#011loss=0.955116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[255] avg_epoch_loss=1.025600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=255 train loss <loss>=1.0379401922225953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [255]#011Speed: 1375.89 samples/sec#011loss=1.037940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch[260] avg_epoch_loss=1.025720\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=260 train loss <loss>=1.0318696618080139\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch [260]#011Speed: 798.49 samples/sec#011loss=1.031870\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch[265] avg_epoch_loss=1.028509\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=265 train loss <loss>=1.1741149425506592\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch [265]#011Speed: 972.15 samples/sec#011loss=1.174115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch[270] avg_epoch_loss=1.027548\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=270 train loss <loss>=0.9763995051383972\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch [270]#011Speed: 782.40 samples/sec#011loss=0.976400\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch[275] avg_epoch_loss=1.027711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=275 train loss <loss>=1.036565113067627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch [275]#011Speed: 1377.35 samples/sec#011loss=1.036565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch[280] avg_epoch_loss=1.028951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=280 train loss <loss>=1.0973763942718506\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch [280]#011Speed: 841.34 samples/sec#011loss=1.097376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch[285] avg_epoch_loss=1.028390\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=285 train loss <loss>=0.9969009518623352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch [285]#011Speed: 1366.33 samples/sec#011loss=0.996901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch[290] avg_epoch_loss=1.026760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=290 train loss <loss>=0.9335174798965454\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch [290]#011Speed: 812.24 samples/sec#011loss=0.933517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch[295] avg_epoch_loss=1.028558\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=295 train loss <loss>=1.1331730246543885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch [295]#011Speed: 1368.37 samples/sec#011loss=1.133173\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch[300] avg_epoch_loss=1.028487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=300 train loss <loss>=1.0243115663528441\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch [300]#011Speed: 811.15 samples/sec#011loss=1.024312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch[305] avg_epoch_loss=1.027148\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=305 train loss <loss>=0.9465125560760498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch [305]#011Speed: 1337.80 samples/sec#011loss=0.946513\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch[310] avg_epoch_loss=1.024865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=310 train loss <loss>=0.8851732850074768\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch [310]#011Speed: 844.46 samples/sec#011loss=0.885173\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch[315] avg_epoch_loss=1.025124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=315 train loss <loss>=1.0412174224853517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch [315]#011Speed: 1364.68 samples/sec#011loss=1.041217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[320] avg_epoch_loss=1.037059\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=320 train loss <loss>=1.791335129737854\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [320]#011Speed: 833.42 samples/sec#011loss=1.791335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[325] avg_epoch_loss=1.039740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=325 train loss <loss>=1.2118859767913819\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [325]#011Speed: 1345.77 samples/sec#011loss=1.211886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[330] avg_epoch_loss=1.040131\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=330 train loss <loss>=1.0656129837036132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [330]#011Speed: 818.31 samples/sec#011loss=1.065613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[335] avg_epoch_loss=1.041125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=335 train loss <loss>=1.106930673122406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [335]#011Speed: 1342.06 samples/sec#011loss=1.106931\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[340] avg_epoch_loss=1.040211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=340 train loss <loss>=0.9787827491760254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [340]#011Speed: 853.55 samples/sec#011loss=0.978783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[345] avg_epoch_loss=1.038217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=345 train loss <loss>=0.9022478818893432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [345]#011Speed: 1317.99 samples/sec#011loss=0.902248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[350] avg_epoch_loss=1.036047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=350 train loss <loss>=0.8859050512313843\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [350]#011Speed: 851.30 samples/sec#011loss=0.885905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch[355] avg_epoch_loss=1.034596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=355 train loss <loss>=0.9327014565467835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch [355]#011Speed: 1243.20 samples/sec#011loss=0.932701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch[360] avg_epoch_loss=1.034541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=360 train loss <loss>=1.0306230306625366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch [360]#011Speed: 836.51 samples/sec#011loss=1.030623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch[365] avg_epoch_loss=1.033354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=365 train loss <loss>=0.947683322429657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch [365]#011Speed: 1187.65 samples/sec#011loss=0.947683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch[370] avg_epoch_loss=1.033785\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=370 train loss <loss>=1.0652779936790466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch [370]#011Speed: 853.83 samples/sec#011loss=1.065278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch[375] avg_epoch_loss=1.032035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=375 train loss <loss>=0.9022295594215393\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch [375]#011Speed: 1368.13 samples/sec#011loss=0.902230\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch[380] avg_epoch_loss=1.031554\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=380 train loss <loss>=0.9953986406326294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch [380]#011Speed: 860.19 samples/sec#011loss=0.995399\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[385] avg_epoch_loss=1.033556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=385 train loss <loss>=1.1860504865646362\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [385]#011Speed: 1312.16 samples/sec#011loss=1.186050\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[390] avg_epoch_loss=1.035569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=390 train loss <loss>=1.190977156162262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [390]#011Speed: 858.80 samples/sec#011loss=1.190977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[395] avg_epoch_loss=1.036485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=395 train loss <loss>=1.1081688046455382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [395]#011Speed: 1341.95 samples/sec#011loss=1.108169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[400] avg_epoch_loss=1.038063\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=400 train loss <loss>=1.1630087733268737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [400]#011Speed: 742.86 samples/sec#011loss=1.163009\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[405] avg_epoch_loss=1.043505\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=405 train loss <loss>=1.4799325823783875\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [405]#011Speed: 1362.09 samples/sec#011loss=1.479933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[410] avg_epoch_loss=1.044065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=410 train loss <loss>=1.0895856022834778\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [410]#011Speed: 852.72 samples/sec#011loss=1.089586\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[415] avg_epoch_loss=1.046916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=415 train loss <loss>=1.281278419494629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [415]#011Speed: 1364.04 samples/sec#011loss=1.281278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch[420] avg_epoch_loss=1.047039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=420 train loss <loss>=1.0572776079177857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch [420]#011Speed: 870.87 samples/sec#011loss=1.057278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch[425] avg_epoch_loss=1.047407\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=425 train loss <loss>=1.078364634513855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch [425]#011Speed: 1044.08 samples/sec#011loss=1.078365\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch[430] avg_epoch_loss=1.047684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=430 train loss <loss>=1.0712584972381591\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch [430]#011Speed: 655.90 samples/sec#011loss=1.071258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch[435] avg_epoch_loss=1.047477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=435 train loss <loss>=1.0296518564224244\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch [435]#011Speed: 1379.10 samples/sec#011loss=1.029652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch[440] avg_epoch_loss=1.045800\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=440 train loss <loss>=0.8995957255363465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch [440]#011Speed: 843.96 samples/sec#011loss=0.899596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[445] avg_epoch_loss=1.044447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=445 train loss <loss>=0.9250762462615967\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [445]#011Speed: 1344.03 samples/sec#011loss=0.925076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[450] avg_epoch_loss=1.042725\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=450 train loss <loss>=0.8891488790512085\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [450]#011Speed: 835.98 samples/sec#011loss=0.889149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[455] avg_epoch_loss=1.042023\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=455 train loss <loss>=0.9786870002746582\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [455]#011Speed: 1351.84 samples/sec#011loss=0.978687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[460] avg_epoch_loss=1.040976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=460 train loss <loss>=0.9454440593719482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [460]#011Speed: 801.22 samples/sec#011loss=0.945444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[465] avg_epoch_loss=1.039322\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=465 train loss <loss>=0.8868314504623414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [465]#011Speed: 1347.44 samples/sec#011loss=0.886831\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[470] avg_epoch_loss=1.037953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=470 train loss <loss>=0.9103983044624329\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [470]#011Speed: 814.04 samples/sec#011loss=0.910398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[475] avg_epoch_loss=1.036629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=475 train loss <loss>=0.91194007396698\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [475]#011Speed: 1360.75 samples/sec#011loss=0.911940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch[480] avg_epoch_loss=1.050460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=480 train loss <loss>=2.3670993208885194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch [480]#011Speed: 832.42 samples/sec#011loss=2.367099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch[485] avg_epoch_loss=1.051098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=485 train loss <loss>=1.1125486373901368\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch [485]#011Speed: 1350.56 samples/sec#011loss=1.112549\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch[490] avg_epoch_loss=1.051264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=490 train loss <loss>=1.0673804521560668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch [490]#011Speed: 855.03 samples/sec#011loss=1.067380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch[495] avg_epoch_loss=1.050641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=495 train loss <loss>=0.9894744515419006\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch [495]#011Speed: 1231.87 samples/sec#011loss=0.989474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch[500] avg_epoch_loss=1.049627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=500 train loss <loss>=0.949037742614746\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch [500]#011Speed: 854.17 samples/sec#011loss=0.949038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch[505] avg_epoch_loss=1.048765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=505 train loss <loss>=0.9623983979225159\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch [505]#011Speed: 1354.32 samples/sec#011loss=0.962398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch[510] avg_epoch_loss=1.048355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=510 train loss <loss>=1.0067753314971923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch [510]#011Speed: 804.46 samples/sec#011loss=1.006775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch[515] avg_epoch_loss=1.047246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=515 train loss <loss>=0.9339086174964905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch [515]#011Speed: 1299.48 samples/sec#011loss=0.933909\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch[520] avg_epoch_loss=1.045606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=520 train loss <loss>=0.8763816356658936\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch [520]#011Speed: 851.89 samples/sec#011loss=0.876382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch[525] avg_epoch_loss=1.044296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=525 train loss <loss>=0.9078600525856018\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch [525]#011Speed: 1171.06 samples/sec#011loss=0.907860\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch[530] avg_epoch_loss=1.042878\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=530 train loss <loss>=0.8936717271804809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch [530]#011Speed: 862.47 samples/sec#011loss=0.893672\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch[535] avg_epoch_loss=1.044102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=535 train loss <loss>=1.1740981698036195\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch [535]#011Speed: 1349.93 samples/sec#011loss=1.174098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[11] Batch[540] avg_epoch_loss=1.046336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=540 train loss <loss>=1.285830056667328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[11] Batch [540]#011Speed: 838.91 samples/sec#011loss=1.285830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[11] Batch[545] avg_epoch_loss=1.046536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=545 train loss <loss>=1.0681750655174256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[11] Batch [545]#011Speed: 1340.16 samples/sec#011loss=1.068175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[11] Batch[550] avg_epoch_loss=1.047107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=550 train loss <loss>=1.109464693069458\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[11] Batch [550]#011Speed: 1310.16 samples/sec#011loss=1.109465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] processed a total of 17620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717434.5570836, \"EndTime\": 1620717452.26737, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17710.209131240845, \"count\": 1, \"min\": 17710.209131240845, \"max\": 17710.209131240845}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=994.895514725533 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, train loss <loss>=1.047107315431273\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_aa78f14e-11e8-4f88-a784-19dafd2f2e61-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717452.2674437, \"EndTime\": 1620717452.2773604, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.24062728881836, \"count\": 1, \"min\": 9.24062728881836, \"max\": 9.24062728881836}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch[0] avg_epoch_loss=1.940828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=1.9408282041549683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch[5] avg_epoch_loss=1.127660\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=1.127659837404887\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch [5]#011Speed: 1364.27 samples/sec#011loss=1.127660\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch[10] avg_epoch_loss=1.097202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=1.0606522917747498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch [10]#011Speed: 770.37 samples/sec#011loss=1.060652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch[15] avg_epoch_loss=1.045263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=15 train loss <loss>=0.9309965372085571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch [15]#011Speed: 1236.44 samples/sec#011loss=0.930997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[20] avg_epoch_loss=1.007045\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=20 train loss <loss>=0.8847486019134522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch [20]#011Speed: 845.94 samples/sec#011loss=0.884749\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[25] avg_epoch_loss=1.003979\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=25 train loss <loss>=0.9911038517951966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch [25]#011Speed: 1363.53 samples/sec#011loss=0.991104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[30] avg_epoch_loss=0.992409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=30 train loss <loss>=0.9322413325309753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch [30]#011Speed: 847.90 samples/sec#011loss=0.932241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[35] avg_epoch_loss=1.002711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=35 train loss <loss>=1.066586709022522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch [35]#011Speed: 1376.42 samples/sec#011loss=1.066587\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[40] avg_epoch_loss=0.997708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=40 train loss <loss>=0.9616826295852661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch [40]#011Speed: 636.80 samples/sec#011loss=0.961683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[45] avg_epoch_loss=0.978865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=45 train loss <loss>=0.8243542432785034\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch [45]#011Speed: 1361.52 samples/sec#011loss=0.824354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[50] avg_epoch_loss=0.964700\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=50 train loss <loss>=0.8343805074691772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [50]#011Speed: 835.74 samples/sec#011loss=0.834381\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch[55] avg_epoch_loss=0.979386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=55 train loss <loss>=1.1291826367378235\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [55]#011Speed: 1342.19 samples/sec#011loss=1.129183\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch[60] avg_epoch_loss=0.984918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=60 train loss <loss>=1.0468755841255188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [60]#011Speed: 817.20 samples/sec#011loss=1.046876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch[65] avg_epoch_loss=0.981406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=65 train loss <loss>=0.9385603308677674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [65]#011Speed: 1333.45 samples/sec#011loss=0.938560\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch[70] avg_epoch_loss=0.974284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=70 train loss <loss>=0.8802759766578674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [70]#011Speed: 798.85 samples/sec#011loss=0.880276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch[75] avg_epoch_loss=0.970643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=75 train loss <loss>=0.9189385294914245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [75]#011Speed: 1294.26 samples/sec#011loss=0.918939\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch[80] avg_epoch_loss=0.966460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=80 train loss <loss>=0.9028793573379517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [80]#011Speed: 863.00 samples/sec#011loss=0.902879\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch[85] avg_epoch_loss=0.969334\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=85 train loss <loss>=1.0158952474594116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch [85]#011Speed: 1235.75 samples/sec#011loss=1.015895\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch[90] avg_epoch_loss=1.001203\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=90 train loss <loss>=1.5493499398231507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch [90]#011Speed: 850.47 samples/sec#011loss=1.549350\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch[95] avg_epoch_loss=0.997187\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=95 train loss <loss>=0.9240965723991394\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch [95]#011Speed: 1320.97 samples/sec#011loss=0.924097\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch[100] avg_epoch_loss=0.994149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=100 train loss <loss>=0.9358165860176086\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch [100]#011Speed: 803.49 samples/sec#011loss=0.935817\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch[105] avg_epoch_loss=1.034467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=105 train loss <loss>=1.8488814949989318\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch [105]#011Speed: 1362.97 samples/sec#011loss=1.848881\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch[110] avg_epoch_loss=1.050972\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=110 train loss <loss>=1.4008773565292358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch [110]#011Speed: 843.06 samples/sec#011loss=1.400877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[115] avg_epoch_loss=1.059647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=115 train loss <loss>=1.2522510290145874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [115]#011Speed: 1352.89 samples/sec#011loss=1.252251\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[120] avg_epoch_loss=1.065384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=120 train loss <loss>=1.1984666585922241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [120]#011Speed: 823.80 samples/sec#011loss=1.198467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[125] avg_epoch_loss=1.065763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=125 train loss <loss>=1.0749297857284545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [125]#011Speed: 1347.06 samples/sec#011loss=1.074930\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[130] avg_epoch_loss=1.061990\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=130 train loss <loss>=0.9669141888618469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [130]#011Speed: 821.87 samples/sec#011loss=0.966914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[135] avg_epoch_loss=1.057740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=135 train loss <loss>=0.9464106678962707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [135]#011Speed: 1232.61 samples/sec#011loss=0.946411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[140] avg_epoch_loss=1.061004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=140 train loss <loss>=1.149767768383026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [140]#011Speed: 850.68 samples/sec#011loss=1.149768\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[145] avg_epoch_loss=1.058328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=145 train loss <loss>=0.9828704595565796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [145]#011Speed: 1280.87 samples/sec#011loss=0.982870\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch[150] avg_epoch_loss=1.057455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=150 train loss <loss>=1.0319611787796021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch [150]#011Speed: 844.90 samples/sec#011loss=1.031961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch[155] avg_epoch_loss=1.053932\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=155 train loss <loss>=0.947530210018158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch [155]#011Speed: 1372.12 samples/sec#011loss=0.947530\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch[160] avg_epoch_loss=1.049121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=160 train loss <loss>=0.8990199089050293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch [160]#011Speed: 859.66 samples/sec#011loss=0.899020\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch[165] avg_epoch_loss=1.044708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=165 train loss <loss>=0.9026183962821961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch [165]#011Speed: 1353.17 samples/sec#011loss=0.902618\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch[170] avg_epoch_loss=1.043551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=170 train loss <loss>=1.005126452445984\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch [170]#011Speed: 795.10 samples/sec#011loss=1.005126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch[175] avg_epoch_loss=1.043859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=175 train loss <loss>=1.0543957352638245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch [175]#011Speed: 1371.87 samples/sec#011loss=1.054396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch[180] avg_epoch_loss=1.038152\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=180 train loss <loss>=0.8372607350349426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch [180]#011Speed: 841.91 samples/sec#011loss=0.837261\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch[185] avg_epoch_loss=1.032996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=185 train loss <loss>=0.8463647842407227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch [185]#011Speed: 1361.88 samples/sec#011loss=0.846365\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch[190] avg_epoch_loss=1.030159\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=190 train loss <loss>=0.9246082186698914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch [190]#011Speed: 855.14 samples/sec#011loss=0.924608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch[195] avg_epoch_loss=1.030529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=195 train loss <loss>=1.044680082798004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch [195]#011Speed: 1266.08 samples/sec#011loss=1.044680\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch[200] avg_epoch_loss=1.072206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=200 train loss <loss>=2.705950379371643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch [200]#011Speed: 705.51 samples/sec#011loss=2.705950\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch[205] avg_epoch_loss=1.075698\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=205 train loss <loss>=1.216076421737671\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch [205]#011Speed: 1138.16 samples/sec#011loss=1.216076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch[210] avg_epoch_loss=1.077043\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=210 train loss <loss>=1.132433867454529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch [210]#011Speed: 841.82 samples/sec#011loss=1.132434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch[215] avg_epoch_loss=1.076390\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=215 train loss <loss>=1.0488269090652467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch [215]#011Speed: 1315.08 samples/sec#011loss=1.048827\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch[220] avg_epoch_loss=1.074802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=220 train loss <loss>=1.0061957597732545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch [220]#011Speed: 842.27 samples/sec#011loss=1.006196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch[225] avg_epoch_loss=1.090877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=225 train loss <loss>=1.80140620470047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch [225]#011Speed: 1366.46 samples/sec#011loss=1.801406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch[230] avg_epoch_loss=1.092185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=230 train loss <loss>=1.1512921094894408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch [230]#011Speed: 785.11 samples/sec#011loss=1.151292\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch[235] avg_epoch_loss=1.093346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=235 train loss <loss>=1.1469916105270386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch [235]#011Speed: 1306.75 samples/sec#011loss=1.146992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[240] avg_epoch_loss=1.091432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=240 train loss <loss>=1.0010809659957887\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [240]#011Speed: 832.09 samples/sec#011loss=1.001081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[245] avg_epoch_loss=1.089322\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=245 train loss <loss>=0.9876608490943909\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [245]#011Speed: 1322.54 samples/sec#011loss=0.987661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[250] avg_epoch_loss=1.089132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=250 train loss <loss>=1.0797825932502747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [250]#011Speed: 862.39 samples/sec#011loss=1.079783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[255] avg_epoch_loss=1.088028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=255 train loss <loss>=1.0326073527336121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [255]#011Speed: 1373.74 samples/sec#011loss=1.032607\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[260] avg_epoch_loss=1.087730\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=260 train loss <loss>=1.0724576234817504\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [260]#011Speed: 854.68 samples/sec#011loss=1.072458\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[265] avg_epoch_loss=1.105448\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=265 train loss <loss>=2.030309188365936\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [265]#011Speed: 1213.44 samples/sec#011loss=2.030309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[270] avg_epoch_loss=1.103973\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=270 train loss <loss>=1.0255407810211181\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [270]#011Speed: 844.92 samples/sec#011loss=1.025541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch[275] avg_epoch_loss=1.103924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=275 train loss <loss>=1.1012628078460693\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch [275]#011Speed: 1359.54 samples/sec#011loss=1.101263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch[280] avg_epoch_loss=1.126805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=280 train loss <loss>=2.3898300886154176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch [280]#011Speed: 779.15 samples/sec#011loss=2.389830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch[285] avg_epoch_loss=1.128276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=285 train loss <loss>=1.2109201431274415\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch [285]#011Speed: 1363.54 samples/sec#011loss=1.210920\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch[290] avg_epoch_loss=1.130002\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=290 train loss <loss>=1.2287692308425904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch [290]#011Speed: 847.25 samples/sec#011loss=1.228769\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch[295] avg_epoch_loss=1.132195\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=295 train loss <loss>=1.2598253965377808\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch [295]#011Speed: 1259.82 samples/sec#011loss=1.259825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch[300] avg_epoch_loss=1.133462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=300 train loss <loss>=1.2084704399108888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch [300]#011Speed: 863.19 samples/sec#011loss=1.208470\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[305] avg_epoch_loss=1.132743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=305 train loss <loss>=1.0894489526748656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [305]#011Speed: 1297.82 samples/sec#011loss=1.089449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[310] avg_epoch_loss=1.129924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=310 train loss <loss>=0.9573842525482178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [310]#011Speed: 849.67 samples/sec#011loss=0.957384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[315] avg_epoch_loss=1.126065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=315 train loss <loss>=0.8860162854194641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [315]#011Speed: 1362.53 samples/sec#011loss=0.886016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[320] avg_epoch_loss=1.127123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=320 train loss <loss>=1.194000792503357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [320]#011Speed: 861.07 samples/sec#011loss=1.194001\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[325] avg_epoch_loss=1.125835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=325 train loss <loss>=1.0431339383125304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [325]#011Speed: 1323.66 samples/sec#011loss=1.043134\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[330] avg_epoch_loss=1.125084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=330 train loss <loss>=1.0761579394340515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [330]#011Speed: 788.94 samples/sec#011loss=1.076158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[335] avg_epoch_loss=1.123530\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=335 train loss <loss>=1.02062908411026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [335]#011Speed: 1369.21 samples/sec#011loss=1.020629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch[340] avg_epoch_loss=1.120778\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=340 train loss <loss>=0.9358540296554565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch [340]#011Speed: 846.71 samples/sec#011loss=0.935854\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch[345] avg_epoch_loss=1.117346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=345 train loss <loss>=0.8832711696624755\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch [345]#011Speed: 1372.13 samples/sec#011loss=0.883271\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch[350] avg_epoch_loss=1.114385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=350 train loss <loss>=0.9094886660575867\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch [350]#011Speed: 864.41 samples/sec#011loss=0.909489\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch[355] avg_epoch_loss=1.116183\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=355 train loss <loss>=1.242435336112976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch [355]#011Speed: 1362.79 samples/sec#011loss=1.242435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch[360] avg_epoch_loss=1.118402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=360 train loss <loss>=1.2763617992401124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch [360]#011Speed: 831.83 samples/sec#011loss=1.276362\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch[365] avg_epoch_loss=1.116823\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=365 train loss <loss>=1.002821946144104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch [365]#011Speed: 1022.46 samples/sec#011loss=1.002822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch[370] avg_epoch_loss=1.115089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=370 train loss <loss>=0.9881432771682739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch [370]#011Speed: 802.53 samples/sec#011loss=0.988143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch[375] avg_epoch_loss=1.112817\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=375 train loss <loss>=0.9442385673522949\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch [375]#011Speed: 1343.33 samples/sec#011loss=0.944239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch[380] avg_epoch_loss=1.110163\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=380 train loss <loss>=0.9105796694755555\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch [380]#011Speed: 850.93 samples/sec#011loss=0.910580\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch[385] avg_epoch_loss=1.107542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=385 train loss <loss>=0.9078360080718995\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch [385]#011Speed: 1373.45 samples/sec#011loss=0.907836\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch[390] avg_epoch_loss=1.105874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=390 train loss <loss>=0.9770989894866944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch [390]#011Speed: 842.13 samples/sec#011loss=0.977099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch[395] avg_epoch_loss=1.104423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=395 train loss <loss>=0.9909334659576416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch [395]#011Speed: 1230.25 samples/sec#011loss=0.990933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[400] avg_epoch_loss=1.103679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=400 train loss <loss>=1.0447901129722594\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [400]#011Speed: 824.79 samples/sec#011loss=1.044790\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[405] avg_epoch_loss=1.106107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=405 train loss <loss>=1.3008405566215515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [405]#011Speed: 1304.31 samples/sec#011loss=1.300841\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[410] avg_epoch_loss=1.105746\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=410 train loss <loss>=1.0764254808425904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [410]#011Speed: 849.01 samples/sec#011loss=1.076425\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[415] avg_epoch_loss=1.104927\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=415 train loss <loss>=1.037586236000061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [415]#011Speed: 1324.36 samples/sec#011loss=1.037586\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[420] avg_epoch_loss=1.105048\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=420 train loss <loss>=1.1150985717773438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [420]#011Speed: 831.39 samples/sec#011loss=1.115099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[425] avg_epoch_loss=1.102626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=425 train loss <loss>=0.8987053513526917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [425]#011Speed: 1190.58 samples/sec#011loss=0.898705\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[430] avg_epoch_loss=1.100698\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=430 train loss <loss>=0.936486291885376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [430]#011Speed: 848.91 samples/sec#011loss=0.936486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch[435] avg_epoch_loss=1.098669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=435 train loss <loss>=0.9236957669258118\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch [435]#011Speed: 1043.44 samples/sec#011loss=0.923696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch[440] avg_epoch_loss=1.097952\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=440 train loss <loss>=1.0354903221130372\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch [440]#011Speed: 539.08 samples/sec#011loss=1.035490\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch[445] avg_epoch_loss=1.096209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=445 train loss <loss>=0.942463731765747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch [445]#011Speed: 842.74 samples/sec#011loss=0.942464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch[450] avg_epoch_loss=1.094779\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=450 train loss <loss>=0.9672344207763672\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch [450]#011Speed: 654.89 samples/sec#011loss=0.967234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch[455] avg_epoch_loss=1.093858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=455 train loss <loss>=1.0107565760612487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch [455]#011Speed: 1330.11 samples/sec#011loss=1.010757\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch[460] avg_epoch_loss=1.092218\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=460 train loss <loss>=0.942681360244751\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch [460]#011Speed: 803.74 samples/sec#011loss=0.942681\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch[465] avg_epoch_loss=1.090517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=465 train loss <loss>=0.9337014079093933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch [465]#011Speed: 1347.87 samples/sec#011loss=0.933701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch[470] avg_epoch_loss=1.091118\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=470 train loss <loss>=1.1471198081970215\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch [470]#011Speed: 848.80 samples/sec#011loss=1.147120\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch[475] avg_epoch_loss=1.088593\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=475 train loss <loss>=0.8507280111312866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch [475]#011Speed: 1342.02 samples/sec#011loss=0.850728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch[480] avg_epoch_loss=1.086673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=480 train loss <loss>=0.9038397073745728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch [480]#011Speed: 779.28 samples/sec#011loss=0.903840\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch[485] avg_epoch_loss=1.084996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=485 train loss <loss>=0.9237056612968445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch [485]#011Speed: 1310.39 samples/sec#011loss=0.923706\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch[490] avg_epoch_loss=1.082506\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=490 train loss <loss>=0.840455150604248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch [490]#011Speed: 843.91 samples/sec#011loss=0.840455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch[495] avg_epoch_loss=1.080196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=495 train loss <loss>=0.8533513426780701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch [495]#011Speed: 1338.00 samples/sec#011loss=0.853351\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch[500] avg_epoch_loss=1.077212\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=500 train loss <loss>=0.7811806559562683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch [500]#011Speed: 808.02 samples/sec#011loss=0.781181\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch[505] avg_epoch_loss=1.075426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=505 train loss <loss>=0.8965357780456543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch [505]#011Speed: 1335.31 samples/sec#011loss=0.896536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch[510] avg_epoch_loss=1.073057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=510 train loss <loss>=0.8332450032234192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch [510]#011Speed: 847.00 samples/sec#011loss=0.833245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch[515] avg_epoch_loss=1.072047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=515 train loss <loss>=0.9688687205314637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch [515]#011Speed: 1150.95 samples/sec#011loss=0.968869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch[520] avg_epoch_loss=1.070253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=520 train loss <loss>=0.8850950360298157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch [520]#011Speed: 839.32 samples/sec#011loss=0.885095\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch[525] avg_epoch_loss=1.068952\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=525 train loss <loss>=0.9333539009094238\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch [525]#011Speed: 1343.18 samples/sec#011loss=0.933354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch[530] avg_epoch_loss=1.067465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=530 train loss <loss>=0.9110610008239746\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch [530]#011Speed: 855.16 samples/sec#011loss=0.911061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch[535] avg_epoch_loss=1.066755\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=535 train loss <loss>=0.991332221031189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch [535]#011Speed: 1375.22 samples/sec#011loss=0.991332\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch[540] avg_epoch_loss=1.065228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=540 train loss <loss>=0.9015920400619507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch [540]#011Speed: 807.14 samples/sec#011loss=0.901592\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch[545] avg_epoch_loss=1.064047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=545 train loss <loss>=0.9362486481666565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch [545]#011Speed: 1228.20 samples/sec#011loss=0.936249\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] processed a total of 17588 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717452.2774825, \"EndTime\": 1620717469.9457338, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17668.187379837036, \"count\": 1, \"min\": 17668.187379837036, \"max\": 17668.187379837036}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=995.448627172823 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, train loss <loss>=1.0629779676957565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[0] avg_epoch_loss=1.001016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=1.0010156631469727\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[5] avg_epoch_loss=0.923061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=0.9230611622333527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch [5]#011Speed: 1338.82 samples/sec#011loss=0.923061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[10] avg_epoch_loss=0.897366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=0.8665308237075806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch [10]#011Speed: 844.69 samples/sec#011loss=0.866531\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[15] avg_epoch_loss=0.883530\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=15 train loss <loss>=0.8530908942222595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch [15]#011Speed: 1360.37 samples/sec#011loss=0.853091\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[20] avg_epoch_loss=0.847150\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=20 train loss <loss>=0.7307328104972839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch [20]#011Speed: 834.84 samples/sec#011loss=0.730733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[25] avg_epoch_loss=0.836255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=25 train loss <loss>=0.7904989719390869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch [25]#011Speed: 1346.90 samples/sec#011loss=0.790499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[30] avg_epoch_loss=0.824202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=30 train loss <loss>=0.7615258812904357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch [30]#011Speed: 791.60 samples/sec#011loss=0.761526\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch[35] avg_epoch_loss=0.824889\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=35 train loss <loss>=0.8291467189788818\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch [35]#011Speed: 1365.68 samples/sec#011loss=0.829147\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch[40] avg_epoch_loss=0.818653\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=40 train loss <loss>=0.7737532973289489\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch [40]#011Speed: 832.72 samples/sec#011loss=0.773753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch[45] avg_epoch_loss=0.813659\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=45 train loss <loss>=0.7727131247520447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch [45]#011Speed: 1353.24 samples/sec#011loss=0.772713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch[50] avg_epoch_loss=0.832309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=50 train loss <loss>=1.0038838505744934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch [50]#011Speed: 867.76 samples/sec#011loss=1.003884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch[55] avg_epoch_loss=0.841713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=55 train loss <loss>=0.9376350164413452\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch [55]#011Speed: 1277.19 samples/sec#011loss=0.937635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch[60] avg_epoch_loss=0.850225\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=60 train loss <loss>=0.945555853843689\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch [60]#011Speed: 796.96 samples/sec#011loss=0.945556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[65] avg_epoch_loss=0.871542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=65 train loss <loss>=1.1316189527511598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [65]#011Speed: 1341.07 samples/sec#011loss=1.131619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[70] avg_epoch_loss=0.880208\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=70 train loss <loss>=0.9945907592773438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [70]#011Speed: 844.52 samples/sec#011loss=0.994591\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[75] avg_epoch_loss=0.884621\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=75 train loss <loss>=0.9472959280014038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [75]#011Speed: 1377.77 samples/sec#011loss=0.947296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[80] avg_epoch_loss=0.888637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=80 train loss <loss>=0.94966721534729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [80]#011Speed: 849.57 samples/sec#011loss=0.949667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[85] avg_epoch_loss=0.888101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=85 train loss <loss>=0.8794243454933166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [85]#011Speed: 1368.01 samples/sec#011loss=0.879424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[90] avg_epoch_loss=0.884487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=90 train loss <loss>=0.8223208069801331\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [90]#011Speed: 845.44 samples/sec#011loss=0.822321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[95] avg_epoch_loss=0.884421\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=95 train loss <loss>=0.8832156777381897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [95]#011Speed: 1221.02 samples/sec#011loss=0.883216\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch[100] avg_epoch_loss=0.885395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=100 train loss <loss>=0.9040991783142089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch [100]#011Speed: 859.29 samples/sec#011loss=0.904099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch[105] avg_epoch_loss=0.888144\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=105 train loss <loss>=0.9436778664588928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch [105]#011Speed: 1344.27 samples/sec#011loss=0.943678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch[110] avg_epoch_loss=0.889348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=110 train loss <loss>=0.914876914024353\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch [110]#011Speed: 852.62 samples/sec#011loss=0.914877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch[115] avg_epoch_loss=1.090637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=115 train loss <loss>=5.559247088432312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch [115]#011Speed: 1356.88 samples/sec#011loss=5.559247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch[120] avg_epoch_loss=1.091382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=120 train loss <loss>=1.1086569547653198\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch [120]#011Speed: 782.76 samples/sec#011loss=1.108657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch[125] avg_epoch_loss=1.100623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=125 train loss <loss>=1.3242722034454346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch [125]#011Speed: 1240.07 samples/sec#011loss=1.324272\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch[130] avg_epoch_loss=1.113473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=130 train loss <loss>=1.4372793197631837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch [130]#011Speed: 850.84 samples/sec#011loss=1.437279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch[135] avg_epoch_loss=1.123635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=135 train loss <loss>=1.3898767709732056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch [135]#011Speed: 1346.06 samples/sec#011loss=1.389877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch[140] avg_epoch_loss=1.131931\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=140 train loss <loss>=1.3576061964035033\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch [140]#011Speed: 857.84 samples/sec#011loss=1.357606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch[145] avg_epoch_loss=1.136580\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=145 train loss <loss>=1.2676658630371094\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch [145]#011Speed: 1370.80 samples/sec#011loss=1.267666\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch[150] avg_epoch_loss=1.141600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=150 train loss <loss>=1.2881765127182008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch [150]#011Speed: 859.50 samples/sec#011loss=1.288177\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch[155] avg_epoch_loss=1.142648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=155 train loss <loss>=1.174310040473938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch [155]#011Speed: 1281.08 samples/sec#011loss=1.174310\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[160] avg_epoch_loss=1.142759\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=160 train loss <loss>=1.1462087154388427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [160]#011Speed: 788.17 samples/sec#011loss=1.146209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[165] avg_epoch_loss=1.139300\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=165 train loss <loss>=1.0279370546340942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [165]#011Speed: 1345.30 samples/sec#011loss=1.027937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[170] avg_epoch_loss=1.134921\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=170 train loss <loss>=0.9895232439041137\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [170]#011Speed: 832.22 samples/sec#011loss=0.989523\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[175] avg_epoch_loss=1.129918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=175 train loss <loss>=0.958821713924408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [175]#011Speed: 1355.85 samples/sec#011loss=0.958822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[180] avg_epoch_loss=1.126890\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=180 train loss <loss>=1.0202957153320313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [180]#011Speed: 859.03 samples/sec#011loss=1.020296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[185] avg_epoch_loss=1.131602\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=185 train loss <loss>=1.3021973729133607\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [185]#011Speed: 1349.14 samples/sec#011loss=1.302197\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[190] avg_epoch_loss=1.131847\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=190 train loss <loss>=1.1409447908401489\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [190]#011Speed: 799.18 samples/sec#011loss=1.140945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch[195] avg_epoch_loss=1.127083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=195 train loss <loss>=0.9451011061668396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch [195]#011Speed: 1304.34 samples/sec#011loss=0.945101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch[200] avg_epoch_loss=1.137267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=200 train loss <loss>=1.5364840030670166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch [200]#011Speed: 868.29 samples/sec#011loss=1.536484\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch[205] avg_epoch_loss=1.135630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=205 train loss <loss>=1.0698263764381408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch [205]#011Speed: 1340.43 samples/sec#011loss=1.069826\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch[210] avg_epoch_loss=1.136877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=210 train loss <loss>=1.1882697701454163\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch [210]#011Speed: 858.58 samples/sec#011loss=1.188270\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch[215] avg_epoch_loss=1.134048\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=215 train loss <loss>=1.0146520376205443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch [215]#011Speed: 1362.36 samples/sec#011loss=1.014652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch[220] avg_epoch_loss=1.131709\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=220 train loss <loss>=1.030637788772583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch [220]#011Speed: 806.90 samples/sec#011loss=1.030638\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[225] avg_epoch_loss=1.129598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=225 train loss <loss>=1.0363142371177674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [225]#011Speed: 1233.11 samples/sec#011loss=1.036314\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[230] avg_epoch_loss=1.135304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=230 train loss <loss>=1.3932123064994812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [230]#011Speed: 842.46 samples/sec#011loss=1.393212\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[235] avg_epoch_loss=1.131566\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=235 train loss <loss>=0.9588570356369018\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [235]#011Speed: 1339.02 samples/sec#011loss=0.958857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[240] avg_epoch_loss=1.126826\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=240 train loss <loss>=0.9031334638595581\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [240]#011Speed: 839.96 samples/sec#011loss=0.903133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[245] avg_epoch_loss=1.122572\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=245 train loss <loss>=0.9175213694572448\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [245]#011Speed: 1362.76 samples/sec#011loss=0.917521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[250] avg_epoch_loss=1.120467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=250 train loss <loss>=1.0168920636177063\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [250]#011Speed: 846.48 samples/sec#011loss=1.016892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[255] avg_epoch_loss=1.118913\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=255 train loss <loss>=1.04090496301651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [255]#011Speed: 1367.53 samples/sec#011loss=1.040905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch[260] avg_epoch_loss=1.116959\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=260 train loss <loss>=1.0169222712516786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch [260]#011Speed: 793.43 samples/sec#011loss=1.016922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch[265] avg_epoch_loss=1.112368\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=265 train loss <loss>=0.8727015018463135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch [265]#011Speed: 1372.59 samples/sec#011loss=0.872702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch[270] avg_epoch_loss=1.109737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=270 train loss <loss>=0.9697447896003724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch [270]#011Speed: 857.00 samples/sec#011loss=0.969745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch[275] avg_epoch_loss=1.104488\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=275 train loss <loss>=0.8199942946434021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch [275]#011Speed: 1359.82 samples/sec#011loss=0.819994\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch[280] avg_epoch_loss=1.101096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=280 train loss <loss>=0.913867962360382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch [280]#011Speed: 853.83 samples/sec#011loss=0.913868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch[285] avg_epoch_loss=1.100076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=285 train loss <loss>=1.042753314971924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch [285]#011Speed: 1370.79 samples/sec#011loss=1.042753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch[290] avg_epoch_loss=1.096966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=290 train loss <loss>=0.9190941572189331\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch [290]#011Speed: 803.33 samples/sec#011loss=0.919094\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch[295] avg_epoch_loss=1.097853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=295 train loss <loss>=1.1494487285614015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch [295]#011Speed: 1361.88 samples/sec#011loss=1.149449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch[300] avg_epoch_loss=1.100081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=300 train loss <loss>=1.2320188522338866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch [300]#011Speed: 853.09 samples/sec#011loss=1.232019\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch[305] avg_epoch_loss=1.098668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=305 train loss <loss>=1.0135825157165528\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch [305]#011Speed: 1369.91 samples/sec#011loss=1.013583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch[310] avg_epoch_loss=1.095964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=310 train loss <loss>=0.9304932475090026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch [310]#011Speed: 863.16 samples/sec#011loss=0.930493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch[315] avg_epoch_loss=1.094193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=315 train loss <loss>=0.9840402126312255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch [315]#011Speed: 1306.13 samples/sec#011loss=0.984040\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[320] avg_epoch_loss=1.090283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=320 train loss <loss>=0.8431262969970703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [320]#011Speed: 813.14 samples/sec#011loss=0.843126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[325] avg_epoch_loss=1.087291\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=325 train loss <loss>=0.8952221870422363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [325]#011Speed: 1240.56 samples/sec#011loss=0.895222\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[330] avg_epoch_loss=1.083503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=330 train loss <loss>=0.8365143775939942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [330]#011Speed: 795.47 samples/sec#011loss=0.836514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[335] avg_epoch_loss=1.080470\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=335 train loss <loss>=0.8797355532646179\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [335]#011Speed: 1333.58 samples/sec#011loss=0.879736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[340] avg_epoch_loss=1.076929\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=340 train loss <loss>=0.838943338394165\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [340]#011Speed: 873.52 samples/sec#011loss=0.838943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[345] avg_epoch_loss=1.073169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=345 train loss <loss>=0.8167161226272583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [345]#011Speed: 1332.14 samples/sec#011loss=0.816716\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[350] avg_epoch_loss=1.073511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=350 train loss <loss>=1.0972103357315064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [350]#011Speed: 847.75 samples/sec#011loss=1.097210\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch[355] avg_epoch_loss=1.072084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=355 train loss <loss>=0.9719178795814514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch [355]#011Speed: 1211.89 samples/sec#011loss=0.971918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch[360] avg_epoch_loss=1.068328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=360 train loss <loss>=0.8008889317512512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch [360]#011Speed: 813.52 samples/sec#011loss=0.800889\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch[365] avg_epoch_loss=1.065294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=365 train loss <loss>=0.8462058544158936\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch [365]#011Speed: 1295.75 samples/sec#011loss=0.846206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch[370] avg_epoch_loss=1.062691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=370 train loss <loss>=0.8721559405326843\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch [370]#011Speed: 598.21 samples/sec#011loss=0.872156\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch[375] avg_epoch_loss=1.060470\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=375 train loss <loss>=0.895660674571991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch [375]#011Speed: 678.39 samples/sec#011loss=0.895661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch[380] avg_epoch_loss=1.057763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=380 train loss <loss>=0.8541923046112061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch [380]#011Speed: 518.08 samples/sec#011loss=0.854192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch[385] avg_epoch_loss=1.055067\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=385 train loss <loss>=0.8496695280075073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch [385]#011Speed: 1106.50 samples/sec#011loss=0.849670\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch[390] avg_epoch_loss=1.052624\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=390 train loss <loss>=0.8639907240867615\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch [390]#011Speed: 847.62 samples/sec#011loss=0.863991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch[395] avg_epoch_loss=1.051322\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=395 train loss <loss>=0.949543571472168\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch [395]#011Speed: 1338.39 samples/sec#011loss=0.949544\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch[400] avg_epoch_loss=1.048975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=400 train loss <loss>=0.8630842447280884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch [400]#011Speed: 820.45 samples/sec#011loss=0.863084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch[405] avg_epoch_loss=1.047937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=405 train loss <loss>=0.9646506786346436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch [405]#011Speed: 1324.96 samples/sec#011loss=0.964651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch[410] avg_epoch_loss=1.051443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=410 train loss <loss>=1.336204731464386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch [410]#011Speed: 814.57 samples/sec#011loss=1.336205\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch[415] avg_epoch_loss=1.050919\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=415 train loss <loss>=1.0078187465667725\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch [415]#011Speed: 1352.95 samples/sec#011loss=1.007819\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch[420] avg_epoch_loss=1.050796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=420 train loss <loss>=1.0405870437622071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch [420]#011Speed: 854.91 samples/sec#011loss=1.040587\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch[425] avg_epoch_loss=1.050209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=425 train loss <loss>=1.0007539629936217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch [425]#011Speed: 1358.29 samples/sec#011loss=1.000754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch[430] avg_epoch_loss=1.049162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=430 train loss <loss>=0.959974753856659\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch [430]#011Speed: 859.85 samples/sec#011loss=0.959975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch[435] avg_epoch_loss=1.047171\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=435 train loss <loss>=0.8754945993423462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch [435]#011Speed: 1366.21 samples/sec#011loss=0.875495\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch[440] avg_epoch_loss=1.044804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=440 train loss <loss>=0.8384280800819397\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch [440]#011Speed: 795.21 samples/sec#011loss=0.838428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch[445] avg_epoch_loss=1.042410\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=445 train loss <loss>=0.8312833309173584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch [445]#011Speed: 1315.82 samples/sec#011loss=0.831283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch[450] avg_epoch_loss=1.043782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=450 train loss <loss>=1.1661691308021545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch [450]#011Speed: 815.14 samples/sec#011loss=1.166169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch[455] avg_epoch_loss=1.042626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=455 train loss <loss>=0.9383279800415039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch [455]#011Speed: 846.20 samples/sec#011loss=0.938328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch[460] avg_epoch_loss=1.040537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=460 train loss <loss>=0.8500176548957825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch [460]#011Speed: 501.93 samples/sec#011loss=0.850018\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch[465] avg_epoch_loss=1.038810\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=465 train loss <loss>=0.879630172252655\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch [465]#011Speed: 758.24 samples/sec#011loss=0.879630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch[470] avg_epoch_loss=1.040627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=470 train loss <loss>=1.2099042057991027\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch [470]#011Speed: 599.01 samples/sec#011loss=1.209904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch[475] avg_epoch_loss=1.038790\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=475 train loss <loss>=0.8657559514045715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch [475]#011Speed: 1334.33 samples/sec#011loss=0.865756\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch[480] avg_epoch_loss=1.048370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=480 train loss <loss>=1.9603663444519044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch [480]#011Speed: 857.32 samples/sec#011loss=1.960366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch[485] avg_epoch_loss=1.047075\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=485 train loss <loss>=0.9224978685379028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch [485]#011Speed: 1189.00 samples/sec#011loss=0.922498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] Epoch[13] Batch[490] avg_epoch_loss=1.045583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=490 train loss <loss>=0.900615394115448\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] Epoch[13] Batch [490]#011Speed: 412.13 samples/sec#011loss=0.900615\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] Epoch[13] Batch[495] avg_epoch_loss=1.044280\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=495 train loss <loss>=0.9162666201591492\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] Epoch[13] Batch [495]#011Speed: 745.17 samples/sec#011loss=0.916267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] Epoch[13] Batch[500] avg_epoch_loss=1.042887\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=500 train loss <loss>=0.9047030568122864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] Epoch[13] Batch [500]#011Speed: 468.01 samples/sec#011loss=0.904703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch[505] avg_epoch_loss=1.041071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=505 train loss <loss>=0.859181571006775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch [505]#011Speed: 797.10 samples/sec#011loss=0.859182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch[510] avg_epoch_loss=1.040261\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=510 train loss <loss>=0.9582895755767822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch [510]#011Speed: 460.57 samples/sec#011loss=0.958290\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch[515] avg_epoch_loss=1.037978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=515 train loss <loss>=0.8046345353126526\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch [515]#011Speed: 765.17 samples/sec#011loss=0.804635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch[520] avg_epoch_loss=1.036907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=520 train loss <loss>=0.92631094455719\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch [520]#011Speed: 472.46 samples/sec#011loss=0.926311\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch[525] avg_epoch_loss=1.034373\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=525 train loss <loss>=0.7704080939292908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch [525]#011Speed: 801.68 samples/sec#011loss=0.770408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch[530] avg_epoch_loss=1.032706\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=530 train loss <loss>=0.8573274374008178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch [530]#011Speed: 763.41 samples/sec#011loss=0.857327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch[535] avg_epoch_loss=1.034926\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=535 train loss <loss>=1.270651137828827\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch [535]#011Speed: 1336.08 samples/sec#011loss=1.270651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch[540] avg_epoch_loss=1.036645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=540 train loss <loss>=1.2209034085273742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch [540]#011Speed: 857.21 samples/sec#011loss=1.220903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch[545] avg_epoch_loss=1.035167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=545 train loss <loss>=0.8752912402153015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch [545]#011Speed: 1349.45 samples/sec#011loss=0.875291\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch[550] avg_epoch_loss=1.034494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=550 train loss <loss>=0.9610400915145874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch [550]#011Speed: 1145.78 samples/sec#011loss=0.961040\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] processed a total of 17679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717469.9459233, \"EndTime\": 1620717488.9358704, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 18989.048719406128, \"count\": 1, \"min\": 18989.048719406128, \"max\": 18989.048719406128}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=931.0043413538345 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, train loss <loss>=1.0342042567932583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_f1400874-11d7-4c91-8b84-77d93b4560ae-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717488.9359572, \"EndTime\": 1620717488.9458601, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.401321411132812, \"count\": 1, \"min\": 9.401321411132812, \"max\": 9.401321411132812}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[0] avg_epoch_loss=1.029626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=1.0296260118484497\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[5] avg_epoch_loss=1.015668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=1.015668163696925\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch [5]#011Speed: 1332.01 samples/sec#011loss=1.015668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[10] avg_epoch_loss=0.974316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=0.9246933937072754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch [10]#011Speed: 799.30 samples/sec#011loss=0.924693\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[15] avg_epoch_loss=0.969964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=15 train loss <loss>=0.9603905558586121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch [15]#011Speed: 1337.19 samples/sec#011loss=0.960391\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[20] avg_epoch_loss=0.968442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=20 train loss <loss>=0.9635694622993469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch [20]#011Speed: 856.25 samples/sec#011loss=0.963569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[25] avg_epoch_loss=0.999990\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=25 train loss <loss>=1.1324929475784302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch [25]#011Speed: 1342.59 samples/sec#011loss=1.132493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[30] avg_epoch_loss=0.994159\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=30 train loss <loss>=0.9638367056846618\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch [30]#011Speed: 851.10 samples/sec#011loss=0.963837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch[35] avg_epoch_loss=0.984207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=35 train loss <loss>=0.922507905960083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch [35]#011Speed: 1258.35 samples/sec#011loss=0.922508\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch[40] avg_epoch_loss=0.979131\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=40 train loss <loss>=0.9425854563713074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch [40]#011Speed: 819.70 samples/sec#011loss=0.942585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch[45] avg_epoch_loss=0.972233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=45 train loss <loss>=0.9156698703765869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch [45]#011Speed: 1299.67 samples/sec#011loss=0.915670\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch[50] avg_epoch_loss=0.974254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=50 train loss <loss>=0.9928405046463012\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch [50]#011Speed: 869.86 samples/sec#011loss=0.992841\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch[55] avg_epoch_loss=0.981631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=55 train loss <loss>=1.0568731665611266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch [55]#011Speed: 1357.41 samples/sec#011loss=1.056873\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch[60] avg_epoch_loss=0.973774\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=60 train loss <loss>=0.8857756376266479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch [60]#011Speed: 862.59 samples/sec#011loss=0.885776\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[65] avg_epoch_loss=0.969207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=65 train loss <loss>=0.9134996652603149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [65]#011Speed: 1349.32 samples/sec#011loss=0.913500\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[70] avg_epoch_loss=0.964954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=70 train loss <loss>=0.9088094353675842\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [70]#011Speed: 851.64 samples/sec#011loss=0.908809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[75] avg_epoch_loss=0.956123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=75 train loss <loss>=0.8307221889495849\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [75]#011Speed: 1166.76 samples/sec#011loss=0.830722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[80] avg_epoch_loss=0.950124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=80 train loss <loss>=0.8589408278465271\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [80]#011Speed: 828.88 samples/sec#011loss=0.858941\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[85] avg_epoch_loss=0.980078\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=85 train loss <loss>=1.4653268933296204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [85]#011Speed: 1362.53 samples/sec#011loss=1.465327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[90] avg_epoch_loss=0.975103\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=90 train loss <loss>=0.8895469903945923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [90]#011Speed: 838.68 samples/sec#011loss=0.889547\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[95] avg_epoch_loss=0.966822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=95 train loss <loss>=0.8160999178886413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [95]#011Speed: 1306.69 samples/sec#011loss=0.816100\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch[100] avg_epoch_loss=0.963474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=100 train loss <loss>=0.8991846203804016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch [100]#011Speed: 856.10 samples/sec#011loss=0.899185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch[105] avg_epoch_loss=0.973600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=105 train loss <loss>=1.1781619548797608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch [105]#011Speed: 1241.83 samples/sec#011loss=1.178162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch[110] avg_epoch_loss=0.986427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=110 train loss <loss>=1.2583440303802491\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch [110]#011Speed: 854.00 samples/sec#011loss=1.258344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch[115] avg_epoch_loss=0.984686\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=115 train loss <loss>=0.9460382103919983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch [115]#011Speed: 1374.11 samples/sec#011loss=0.946038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch[120] avg_epoch_loss=0.981490\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=120 train loss <loss>=0.9073546171188355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch [120]#011Speed: 840.12 samples/sec#011loss=0.907355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch[125] avg_epoch_loss=0.978881\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=125 train loss <loss>=0.9157302021980286\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch [125]#011Speed: 1360.15 samples/sec#011loss=0.915730\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch[130] avg_epoch_loss=0.972071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=130 train loss <loss>=0.8004549026489258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch [130]#011Speed: 866.75 samples/sec#011loss=0.800455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch[135] avg_epoch_loss=0.970337\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=135 train loss <loss>=0.9249029994010926\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch [135]#011Speed: 1375.63 samples/sec#011loss=0.924903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch[140] avg_epoch_loss=0.968648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=140 train loss <loss>=0.9227182626724243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch [140]#011Speed: 809.28 samples/sec#011loss=0.922718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch[145] avg_epoch_loss=0.966796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=145 train loss <loss>=0.9145565748214721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch [145]#011Speed: 1347.64 samples/sec#011loss=0.914557\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch[150] avg_epoch_loss=0.966853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=150 train loss <loss>=0.9685435891151428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch [150]#011Speed: 851.04 samples/sec#011loss=0.968544\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch[155] avg_epoch_loss=0.968369\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=155 train loss <loss>=1.01412672996521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch [155]#011Speed: 1353.04 samples/sec#011loss=1.014127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[160] avg_epoch_loss=0.970468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=160 train loss <loss>=1.0359673142433166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [160]#011Speed: 859.39 samples/sec#011loss=1.035967\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[165] avg_epoch_loss=0.967506\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=165 train loss <loss>=0.8721229434013367\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [165]#011Speed: 1371.26 samples/sec#011loss=0.872123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[170] avg_epoch_loss=0.963650\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=170 train loss <loss>=0.8356417417526245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [170]#011Speed: 805.80 samples/sec#011loss=0.835642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[175] avg_epoch_loss=0.966857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=175 train loss <loss>=1.0765204310417176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [175]#011Speed: 1368.27 samples/sec#011loss=1.076520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[180] avg_epoch_loss=0.967107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=180 train loss <loss>=0.9759037971496582\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [180]#011Speed: 871.32 samples/sec#011loss=0.975904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[185] avg_epoch_loss=0.976789\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=185 train loss <loss>=1.3272990226745605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [185]#011Speed: 1370.86 samples/sec#011loss=1.327299\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[190] avg_epoch_loss=0.984302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=190 train loss <loss>=1.2637633800506591\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [190]#011Speed: 848.98 samples/sec#011loss=1.263763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[195] avg_epoch_loss=0.984959\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=195 train loss <loss>=1.0100737929344177\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [195]#011Speed: 1344.40 samples/sec#011loss=1.010074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[200] avg_epoch_loss=0.989187\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=200 train loss <loss>=1.154928708076477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [200]#011Speed: 848.18 samples/sec#011loss=1.154929\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[205] avg_epoch_loss=0.991670\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=205 train loss <loss>=1.0915013551712036\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [205]#011Speed: 1244.60 samples/sec#011loss=1.091501\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[210] avg_epoch_loss=0.997778\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=210 train loss <loss>=1.2494143486022948\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [210]#011Speed: 855.28 samples/sec#011loss=1.249414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[215] avg_epoch_loss=0.996742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=215 train loss <loss>=0.9530029654502868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [215]#011Speed: 1362.59 samples/sec#011loss=0.953003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[220] avg_epoch_loss=0.995522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=220 train loss <loss>=0.9428343415260315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [220]#011Speed: 848.54 samples/sec#011loss=0.942834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[225] avg_epoch_loss=0.995219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=225 train loss <loss>=0.981829571723938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [225]#011Speed: 1325.97 samples/sec#011loss=0.981830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch[230] avg_epoch_loss=0.993089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=230 train loss <loss>=0.8967931628227234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch [230]#011Speed: 839.68 samples/sec#011loss=0.896793\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch[235] avg_epoch_loss=0.992112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=235 train loss <loss>=0.9469961047172546\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch [235]#011Speed: 1358.32 samples/sec#011loss=0.946996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch[240] avg_epoch_loss=0.990295\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=240 train loss <loss>=0.9045047044754029\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch [240]#011Speed: 761.26 samples/sec#011loss=0.904505\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch[245] avg_epoch_loss=0.986448\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=245 train loss <loss>=0.8010394096374511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch [245]#011Speed: 1326.60 samples/sec#011loss=0.801039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch[250] avg_epoch_loss=0.985029\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=250 train loss <loss>=0.9152035593986512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch [250]#011Speed: 637.79 samples/sec#011loss=0.915204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch[255] avg_epoch_loss=0.983381\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=255 train loss <loss>=0.9006844997406006\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch [255]#011Speed: 872.43 samples/sec#011loss=0.900684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch[260] avg_epoch_loss=0.982427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=260 train loss <loss>=0.9335410714149475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch [260]#011Speed: 523.63 samples/sec#011loss=0.933541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch[265] avg_epoch_loss=0.981411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=265 train loss <loss>=0.9284160971641541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch [265]#011Speed: 1333.54 samples/sec#011loss=0.928416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch[270] avg_epoch_loss=0.982430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=270 train loss <loss>=1.036610472202301\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch [270]#011Speed: 853.85 samples/sec#011loss=1.036610\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch[275] avg_epoch_loss=1.026444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=275 train loss <loss>=3.412000334262848\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch [275]#011Speed: 1346.95 samples/sec#011loss=3.412000\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch[280] avg_epoch_loss=1.030974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=280 train loss <loss>=1.2810240983963013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch [280]#011Speed: 831.44 samples/sec#011loss=1.281024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch[285] avg_epoch_loss=1.037695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=285 train loss <loss>=1.4154288053512574\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch [285]#011Speed: 1344.05 samples/sec#011loss=1.415429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch[290] avg_epoch_loss=1.043673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=290 train loss <loss>=1.3855952501296998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch [290]#011Speed: 863.44 samples/sec#011loss=1.385595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch[295] avg_epoch_loss=1.048580\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=295 train loss <loss>=1.3342136144638062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch [295]#011Speed: 1193.46 samples/sec#011loss=1.334214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch[300] avg_epoch_loss=1.052223\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=300 train loss <loss>=1.2678656339645387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch [300]#011Speed: 848.07 samples/sec#011loss=1.267866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch[305] avg_epoch_loss=1.056092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=305 train loss <loss>=1.2890153169631957\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch [305]#011Speed: 1351.67 samples/sec#011loss=1.289015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch[310] avg_epoch_loss=1.057185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=310 train loss <loss>=1.1240978717803956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch [310]#011Speed: 862.79 samples/sec#011loss=1.124098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[315] avg_epoch_loss=1.056933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=315 train loss <loss>=1.0412127733230592\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [315]#011Speed: 1338.42 samples/sec#011loss=1.041213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[320] avg_epoch_loss=1.056283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=320 train loss <loss>=1.015247917175293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [320]#011Speed: 862.59 samples/sec#011loss=1.015248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[325] avg_epoch_loss=1.054054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=325 train loss <loss>=0.9109395623207093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [325]#011Speed: 1361.64 samples/sec#011loss=0.910940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[330] avg_epoch_loss=1.051754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=330 train loss <loss>=0.901747751235962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [330]#011Speed: 824.58 samples/sec#011loss=0.901748\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[335] avg_epoch_loss=1.048191\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=335 train loss <loss>=0.8123515129089356\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [335]#011Speed: 1374.56 samples/sec#011loss=0.812352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[340] avg_epoch_loss=1.045930\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=340 train loss <loss>=0.893976354598999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [340]#011Speed: 859.91 samples/sec#011loss=0.893976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[345] avg_epoch_loss=1.042631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=345 train loss <loss>=0.8176425814628601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [345]#011Speed: 1358.57 samples/sec#011loss=0.817643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch[350] avg_epoch_loss=1.039245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=350 train loss <loss>=0.8049621224403382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch [350]#011Speed: 859.01 samples/sec#011loss=0.804962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch[355] avg_epoch_loss=1.038149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=355 train loss <loss>=0.9611884117126465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch [355]#011Speed: 1361.94 samples/sec#011loss=0.961188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch[360] avg_epoch_loss=1.035702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=360 train loss <loss>=0.8614672660827637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch [360]#011Speed: 781.70 samples/sec#011loss=0.861467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch[365] avg_epoch_loss=1.038759\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=365 train loss <loss>=1.2595121622085572\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch [365]#011Speed: 1337.24 samples/sec#011loss=1.259512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch[370] avg_epoch_loss=1.038607\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=370 train loss <loss>=1.0274221897125244\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch [370]#011Speed: 853.10 samples/sec#011loss=1.027422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch[375] avg_epoch_loss=1.041390\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=375 train loss <loss>=1.247960591316223\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch [375]#011Speed: 1337.38 samples/sec#011loss=1.247961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch[380] avg_epoch_loss=1.040246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=380 train loss <loss>=0.9541840553283691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch [380]#011Speed: 855.89 samples/sec#011loss=0.954184\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch[385] avg_epoch_loss=1.038404\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=385 train loss <loss>=0.8980303525924682\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch [385]#011Speed: 1358.36 samples/sec#011loss=0.898030\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch[390] avg_epoch_loss=1.037306\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=390 train loss <loss>=0.9525281906127929\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch [390]#011Speed: 845.38 samples/sec#011loss=0.952528\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch[395] avg_epoch_loss=1.035323\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=395 train loss <loss>=0.8803114175796509\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch [395]#011Speed: 1176.84 samples/sec#011loss=0.880311\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch[400] avg_epoch_loss=1.032996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=400 train loss <loss>=0.8486620664596558\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch [400]#011Speed: 854.10 samples/sec#011loss=0.848662\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch[405] avg_epoch_loss=1.033345\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=405 train loss <loss>=1.0613425850868226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch [405]#011Speed: 1314.16 samples/sec#011loss=1.061343\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[410] avg_epoch_loss=1.031679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=410 train loss <loss>=0.8963787913322449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [410]#011Speed: 850.81 samples/sec#011loss=0.896379\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[415] avg_epoch_loss=1.031406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=415 train loss <loss>=1.008939754962921\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [415]#011Speed: 1340.06 samples/sec#011loss=1.008940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[420] avg_epoch_loss=1.031611\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=420 train loss <loss>=1.048715054988861\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [420]#011Speed: 836.34 samples/sec#011loss=1.048715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[425] avg_epoch_loss=1.030244\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=425 train loss <loss>=0.9151348233222961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [425]#011Speed: 1228.46 samples/sec#011loss=0.915135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[430] avg_epoch_loss=1.039903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=430 train loss <loss>=1.8628472208976745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [430]#011Speed: 850.69 samples/sec#011loss=1.862847\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[435] avg_epoch_loss=1.041229\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=435 train loss <loss>=1.1555120944976807\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [435]#011Speed: 1301.17 samples/sec#011loss=1.155512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[440] avg_epoch_loss=1.040779\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=440 train loss <loss>=1.0015953421592712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [440]#011Speed: 845.91 samples/sec#011loss=1.001595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch[445] avg_epoch_loss=1.039630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=445 train loss <loss>=0.9382312297821045\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch [445]#011Speed: 1325.76 samples/sec#011loss=0.938231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch[450] avg_epoch_loss=1.038813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=450 train loss <loss>=0.9659932374954223\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch [450]#011Speed: 842.72 samples/sec#011loss=0.965993\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch[455] avg_epoch_loss=1.039151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=455 train loss <loss>=1.069635546207428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch [455]#011Speed: 1357.24 samples/sec#011loss=1.069636\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch[460] avg_epoch_loss=1.037571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=460 train loss <loss>=0.8934804320335388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch [460]#011Speed: 778.00 samples/sec#011loss=0.893480\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch[465] avg_epoch_loss=1.037674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=465 train loss <loss>=1.0471571445465089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch [465]#011Speed: 1321.58 samples/sec#011loss=1.047157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch[470] avg_epoch_loss=1.036843\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=470 train loss <loss>=0.9593422889709473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch [470]#011Speed: 849.51 samples/sec#011loss=0.959342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[475] avg_epoch_loss=1.034741\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=475 train loss <loss>=0.836784815788269\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [475]#011Speed: 1298.07 samples/sec#011loss=0.836785\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[480] avg_epoch_loss=1.034433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=480 train loss <loss>=1.0051083207130431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [480]#011Speed: 858.98 samples/sec#011loss=1.005108\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[485] avg_epoch_loss=1.035143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=485 train loss <loss>=1.1034452080726624\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [485]#011Speed: 1339.96 samples/sec#011loss=1.103445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[490] avg_epoch_loss=1.033803\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=490 train loss <loss>=0.9035564541816712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [490]#011Speed: 751.78 samples/sec#011loss=0.903556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[495] avg_epoch_loss=1.032026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=495 train loss <loss>=0.8574761986732483\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [495]#011Speed: 1350.48 samples/sec#011loss=0.857476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[500] avg_epoch_loss=1.029377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=500 train loss <loss>=0.7665803790092468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [500]#011Speed: 847.12 samples/sec#011loss=0.766580\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[505] avg_epoch_loss=1.026916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=505 train loss <loss>=0.7803159356117249\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [505]#011Speed: 1322.64 samples/sec#011loss=0.780316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch[510] avg_epoch_loss=1.025472\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=510 train loss <loss>=0.8793384075164795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch [510]#011Speed: 829.57 samples/sec#011loss=0.879338\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch[515] avg_epoch_loss=1.024308\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=515 train loss <loss>=0.905380392074585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch [515]#011Speed: 1312.49 samples/sec#011loss=0.905380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch[520] avg_epoch_loss=1.022369\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=520 train loss <loss>=0.8222496151924134\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch [520]#011Speed: 801.26 samples/sec#011loss=0.822250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch[525] avg_epoch_loss=1.020747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=525 train loss <loss>=0.8518021941184998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch [525]#011Speed: 1241.33 samples/sec#011loss=0.851802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch[530] avg_epoch_loss=1.018769\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=530 train loss <loss>=0.8106126189231873\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch [530]#011Speed: 843.76 samples/sec#011loss=0.810613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch[535] avg_epoch_loss=1.017507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=535 train loss <loss>=0.8834601163864135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch [535]#011Speed: 1339.23 samples/sec#011loss=0.883460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch[540] avg_epoch_loss=1.016157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=540 train loss <loss>=0.8714744687080384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch [540]#011Speed: 849.08 samples/sec#011loss=0.871474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch[545] avg_epoch_loss=1.018605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=545 train loss <loss>=1.2834646582603455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch [545]#011Speed: 1334.85 samples/sec#011loss=1.283465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch[550] avg_epoch_loss=1.016733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=550 train loss <loss>=0.8123136639595032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch [550]#011Speed: 924.86 samples/sec#011loss=0.812314\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch[555] avg_epoch_loss=1.015206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=555 train loss <loss>=0.8469874858856201\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch [555]#011Speed: 1341.60 samples/sec#011loss=0.846987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] processed a total of 17844 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717488.9459221, \"EndTime\": 1620717506.6009102, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17654.924869537354, \"count\": 1, \"min\": 17654.924869537354, \"max\": 17654.924869537354}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=1010.6982916706178 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #progress_metric: host=algo-1, completed 75.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, train loss <loss>=1.0146141645087992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_efa04013-0390-4159-9158-7fd4867ee79b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717506.6009912, \"EndTime\": 1620717506.6114419, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.536981582641602, \"count\": 1, \"min\": 9.536981582641602, \"max\": 9.536981582641602}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[15] Batch[0] avg_epoch_loss=0.720649\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=0.7206494808197021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[15] Batch[5] avg_epoch_loss=0.807433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=0.8074333667755127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[15] Batch [5]#011Speed: 1349.20 samples/sec#011loss=0.807433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[10] avg_epoch_loss=0.779746\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=0.7465214490890503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [10]#011Speed: 847.97 samples/sec#011loss=0.746521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[15] avg_epoch_loss=0.784284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=15 train loss <loss>=0.7942657709121704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [15]#011Speed: 1333.55 samples/sec#011loss=0.794266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[20] avg_epoch_loss=0.779344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=20 train loss <loss>=0.7635370254516601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [20]#011Speed: 868.13 samples/sec#011loss=0.763537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[25] avg_epoch_loss=0.783614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=25 train loss <loss>=0.8015475869178772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [25]#011Speed: 1269.58 samples/sec#011loss=0.801548\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[30] avg_epoch_loss=0.795628\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=30 train loss <loss>=0.8581024765968323\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [30]#011Speed: 808.01 samples/sec#011loss=0.858102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[35] avg_epoch_loss=0.809234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=35 train loss <loss>=0.8935905337333679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [35]#011Speed: 1265.03 samples/sec#011loss=0.893591\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[40] avg_epoch_loss=0.809518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=40 train loss <loss>=0.811559545993805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [40]#011Speed: 823.18 samples/sec#011loss=0.811560\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch[45] avg_epoch_loss=0.825362\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=45 train loss <loss>=0.955282986164093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch [45]#011Speed: 1307.52 samples/sec#011loss=0.955283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch[50] avg_epoch_loss=0.833527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=50 train loss <loss>=0.9086520195007324\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch [50]#011Speed: 861.40 samples/sec#011loss=0.908652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch[55] avg_epoch_loss=0.858478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=55 train loss <loss>=1.1129776000976563\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch [55]#011Speed: 1332.29 samples/sec#011loss=1.112978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch[60] avg_epoch_loss=0.869781\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=60 train loss <loss>=0.9963725447654724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch [60]#011Speed: 850.41 samples/sec#011loss=0.996373\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch[65] avg_epoch_loss=0.873888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=65 train loss <loss>=0.9239985466003418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch [65]#011Speed: 1223.95 samples/sec#011loss=0.923999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch[70] avg_epoch_loss=0.885316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=70 train loss <loss>=1.0361570239067077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch [70]#011Speed: 850.30 samples/sec#011loss=1.036157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[75] avg_epoch_loss=0.886375\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=75 train loss <loss>=0.9014223337173461\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [75]#011Speed: 1313.47 samples/sec#011loss=0.901422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[80] avg_epoch_loss=0.887341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=80 train loss <loss>=0.9020158290863037\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [80]#011Speed: 855.33 samples/sec#011loss=0.902016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[85] avg_epoch_loss=0.890918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=85 train loss <loss>=0.9488727807998657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [85]#011Speed: 1323.53 samples/sec#011loss=0.948873\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[90] avg_epoch_loss=0.911734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=90 train loss <loss>=1.2697597861289978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [90]#011Speed: 844.65 samples/sec#011loss=1.269760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[95] avg_epoch_loss=1.018357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=95 train loss <loss>=2.958890986442566\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [95]#011Speed: 1199.59 samples/sec#011loss=2.958891\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[100] avg_epoch_loss=1.018411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=100 train loss <loss>=1.0194604754447938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [100]#011Speed: 845.71 samples/sec#011loss=1.019460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[105] avg_epoch_loss=1.028742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=105 train loss <loss>=1.2374220371246338\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [105]#011Speed: 1339.42 samples/sec#011loss=1.237422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch[110] avg_epoch_loss=1.032579\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=110 train loss <loss>=1.113917350769043\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch [110]#011Speed: 855.37 samples/sec#011loss=1.113917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch[115] avg_epoch_loss=1.037499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=115 train loss <loss>=1.1467220544815064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch [115]#011Speed: 1333.73 samples/sec#011loss=1.146722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch[120] avg_epoch_loss=1.037459\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=120 train loss <loss>=1.036534583568573\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch [120]#011Speed: 826.13 samples/sec#011loss=1.036535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch[125] avg_epoch_loss=1.034007\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=125 train loss <loss>=0.9504850149154663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch [125]#011Speed: 1291.34 samples/sec#011loss=0.950485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch[130] avg_epoch_loss=1.028296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=130 train loss <loss>=0.8843762874603271\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch [130]#011Speed: 795.02 samples/sec#011loss=0.884376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch[135] avg_epoch_loss=1.021737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=135 train loss <loss>=0.8498705625534058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch [135]#011Speed: 1336.97 samples/sec#011loss=0.849871\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch[140] avg_epoch_loss=1.017866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=140 train loss <loss>=0.9125963091850281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch [140]#011Speed: 830.83 samples/sec#011loss=0.912596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch[145] avg_epoch_loss=1.013539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=145 train loss <loss>=0.891512930393219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch [145]#011Speed: 1309.10 samples/sec#011loss=0.891513\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch[150] avg_epoch_loss=1.010732\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=150 train loss <loss>=0.9287662982940674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch [150]#011Speed: 844.83 samples/sec#011loss=0.928766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch[155] avg_epoch_loss=1.004962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=155 train loss <loss>=0.8306949019432068\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch [155]#011Speed: 1258.75 samples/sec#011loss=0.830695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch[160] avg_epoch_loss=0.999428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=160 train loss <loss>=0.8267774105072021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch [160]#011Speed: 788.43 samples/sec#011loss=0.826777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch[165] avg_epoch_loss=0.994081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=165 train loss <loss>=0.8218993425369263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch [165]#011Speed: 1328.56 samples/sec#011loss=0.821899\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch[170] avg_epoch_loss=0.991038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=170 train loss <loss>=0.8900110006332398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch [170]#011Speed: 825.55 samples/sec#011loss=0.890011\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch[175] avg_epoch_loss=0.990392\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=175 train loss <loss>=0.9683093190193176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch [175]#011Speed: 1351.92 samples/sec#011loss=0.968309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch[180] avg_epoch_loss=0.985132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=180 train loss <loss>=0.7999931335449219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch [180]#011Speed: 844.89 samples/sec#011loss=0.799993\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch[185] avg_epoch_loss=0.981928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=185 train loss <loss>=0.8659086942672729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch [185]#011Speed: 1208.77 samples/sec#011loss=0.865909\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch[190] avg_epoch_loss=0.990711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=190 train loss <loss>=1.3174444317817688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch [190]#011Speed: 788.14 samples/sec#011loss=1.317444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch[195] avg_epoch_loss=1.002556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=195 train loss <loss>=1.4550279021263122\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch [195]#011Speed: 1244.68 samples/sec#011loss=1.455028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[200] avg_epoch_loss=1.007422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=200 train loss <loss>=1.1981943488121032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [200]#011Speed: 818.43 samples/sec#011loss=1.198194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[205] avg_epoch_loss=1.016067\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=205 train loss <loss>=1.363605296611786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [205]#011Speed: 1323.01 samples/sec#011loss=1.363605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[210] avg_epoch_loss=1.015749\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=210 train loss <loss>=1.0026421308517457\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [210]#011Speed: 844.85 samples/sec#011loss=1.002642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[215] avg_epoch_loss=1.016202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=215 train loss <loss>=1.0353041410446167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [215]#011Speed: 1344.16 samples/sec#011loss=1.035304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[220] avg_epoch_loss=1.015321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=220 train loss <loss>=0.9772464752197265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [220]#011Speed: 843.85 samples/sec#011loss=0.977246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[225] avg_epoch_loss=1.014464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=225 train loss <loss>=0.9765893697738648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [225]#011Speed: 1231.37 samples/sec#011loss=0.976589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[230] avg_epoch_loss=1.012328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=230 train loss <loss>=0.9158032774925232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [230]#011Speed: 838.54 samples/sec#011loss=0.915803\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch[235] avg_epoch_loss=1.013857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=235 train loss <loss>=1.084465205669403\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch [235]#011Speed: 1298.09 samples/sec#011loss=1.084465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch[240] avg_epoch_loss=1.009717\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=240 train loss <loss>=0.814341378211975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch [240]#011Speed: 835.26 samples/sec#011loss=0.814341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch[245] avg_epoch_loss=1.007170\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=245 train loss <loss>=0.8844188570976257\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch [245]#011Speed: 1324.78 samples/sec#011loss=0.884419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch[250] avg_epoch_loss=1.003429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=250 train loss <loss>=0.819340980052948\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch [250]#011Speed: 811.35 samples/sec#011loss=0.819341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch[255] avg_epoch_loss=0.999127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=255 train loss <loss>=0.7831808686256408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch [255]#011Speed: 1241.88 samples/sec#011loss=0.783181\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch[260] avg_epoch_loss=0.997240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=260 train loss <loss>=0.900625205039978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch [260]#011Speed: 828.91 samples/sec#011loss=0.900625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch[265] avg_epoch_loss=1.043102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=265 train loss <loss>=3.4371030569076537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch [265]#011Speed: 1206.09 samples/sec#011loss=3.437103\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch[270] avg_epoch_loss=1.045855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=270 train loss <loss>=1.1923001766204835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch [270]#011Speed: 845.43 samples/sec#011loss=1.192300\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch[275] avg_epoch_loss=1.046858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=275 train loss <loss>=1.1012169599533081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch [275]#011Speed: 1322.00 samples/sec#011loss=1.101217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch[280] avg_epoch_loss=1.048057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=280 train loss <loss>=1.1142258167266845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch [280]#011Speed: 825.82 samples/sec#011loss=1.114226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch[285] avg_epoch_loss=1.049106\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=285 train loss <loss>=1.1081042170524598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch [285]#011Speed: 1333.35 samples/sec#011loss=1.108104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch[290] avg_epoch_loss=1.049906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=290 train loss <loss>=1.0956426858901978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch [290]#011Speed: 795.18 samples/sec#011loss=1.095643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[295] avg_epoch_loss=1.051016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=295 train loss <loss>=1.1156229019165038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [295]#011Speed: 1326.44 samples/sec#011loss=1.115623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[300] avg_epoch_loss=1.049784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=300 train loss <loss>=0.9768514752388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [300]#011Speed: 846.16 samples/sec#011loss=0.976851\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[305] avg_epoch_loss=1.048720\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=305 train loss <loss>=0.9846695542335511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [305]#011Speed: 1306.41 samples/sec#011loss=0.984670\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[310] avg_epoch_loss=1.045515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=310 train loss <loss>=0.8493778944015503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [310]#011Speed: 839.62 samples/sec#011loss=0.849378\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[315] avg_epoch_loss=1.043172\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=315 train loss <loss>=0.8974056720733643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [315]#011Speed: 1290.10 samples/sec#011loss=0.897406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[320] avg_epoch_loss=1.041935\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=320 train loss <loss>=0.9637462377548218\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [320]#011Speed: 784.04 samples/sec#011loss=0.963746\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[325] avg_epoch_loss=1.042760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=325 train loss <loss>=1.0957828640937806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [325]#011Speed: 1307.58 samples/sec#011loss=1.095783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch[330] avg_epoch_loss=1.041310\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=330 train loss <loss>=0.9467233419418335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch [330]#011Speed: 821.10 samples/sec#011loss=0.946723\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch[335] avg_epoch_loss=1.037486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=335 train loss <loss>=0.7843524217605591\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch [335]#011Speed: 1325.69 samples/sec#011loss=0.784352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch[340] avg_epoch_loss=1.035000\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=340 train loss <loss>=0.8679542899131775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch [340]#011Speed: 830.97 samples/sec#011loss=0.867954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch[345] avg_epoch_loss=1.031917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=345 train loss <loss>=0.8216722846031189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch [345]#011Speed: 1290.07 samples/sec#011loss=0.821672\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch[350] avg_epoch_loss=1.028855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=350 train loss <loss>=0.8169057726860046\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch [350]#011Speed: 764.67 samples/sec#011loss=0.816906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch[355] avg_epoch_loss=1.025231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=355 train loss <loss>=0.7708424091339111\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch [355]#011Speed: 1328.69 samples/sec#011loss=0.770842\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch[360] avg_epoch_loss=1.024476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=360 train loss <loss>=0.9707503914833069\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch [360]#011Speed: 837.75 samples/sec#011loss=0.970750\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch[365] avg_epoch_loss=1.026163\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=365 train loss <loss>=1.1479207277297974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch [365]#011Speed: 1330.39 samples/sec#011loss=1.147921\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch[370] avg_epoch_loss=1.026976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=370 train loss <loss>=1.0864944577217102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch [370]#011Speed: 866.17 samples/sec#011loss=1.086494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch[375] avg_epoch_loss=1.028103\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=375 train loss <loss>=1.1117249965667724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch [375]#011Speed: 1280.69 samples/sec#011loss=1.111725\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch[380] avg_epoch_loss=1.024975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=380 train loss <loss>=0.7897954821586609\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch [380]#011Speed: 850.83 samples/sec#011loss=0.789795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch[385] avg_epoch_loss=1.022435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=385 train loss <loss>=0.8288923501968384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch [385]#011Speed: 1211.06 samples/sec#011loss=0.828892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch[390] avg_epoch_loss=1.019764\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=390 train loss <loss>=0.8135006785392761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch [390]#011Speed: 837.30 samples/sec#011loss=0.813501\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch[395] avg_epoch_loss=1.017049\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=395 train loss <loss>=0.8047762155532837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch [395]#011Speed: 1350.33 samples/sec#011loss=0.804776\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch[400] avg_epoch_loss=1.015044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=400 train loss <loss>=0.8562326550483703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch [400]#011Speed: 860.52 samples/sec#011loss=0.856233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch[405] avg_epoch_loss=1.013485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=405 train loss <loss>=0.8884349465370178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch [405]#011Speed: 1127.88 samples/sec#011loss=0.888435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch[410] avg_epoch_loss=1.023079\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=410 train loss <loss>=1.8021512269973754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch [410]#011Speed: 832.93 samples/sec#011loss=1.802151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch[415] avg_epoch_loss=1.031386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=415 train loss <loss>=1.714168906211853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch [415]#011Speed: 1230.94 samples/sec#011loss=1.714169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[420] avg_epoch_loss=1.031958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=420 train loss <loss>=1.079577875137329\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [420]#011Speed: 822.71 samples/sec#011loss=1.079578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[425] avg_epoch_loss=1.031382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=425 train loss <loss>=0.9828595757484436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [425]#011Speed: 1330.78 samples/sec#011loss=0.982860\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[430] avg_epoch_loss=1.033090\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=430 train loss <loss>=1.1786563873291016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [430]#011Speed: 844.52 samples/sec#011loss=1.178656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[435] avg_epoch_loss=1.032601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=435 train loss <loss>=0.9904015183448791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [435]#011Speed: 1343.42 samples/sec#011loss=0.990402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[440] avg_epoch_loss=1.031674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=440 train loss <loss>=0.9509155869483947\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [440]#011Speed: 751.43 samples/sec#011loss=0.950916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[445] avg_epoch_loss=1.030177\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=445 train loss <loss>=0.8980650424957275\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [445]#011Speed: 1363.17 samples/sec#011loss=0.898065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[450] avg_epoch_loss=1.030922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=450 train loss <loss>=1.0973716974258423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [450]#011Speed: 780.92 samples/sec#011loss=1.097372\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch[455] avg_epoch_loss=1.030192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=455 train loss <loss>=0.9643647313117981\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch [455]#011Speed: 1361.86 samples/sec#011loss=0.964365\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch[460] avg_epoch_loss=1.030160\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=460 train loss <loss>=1.0272817254066466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch [460]#011Speed: 868.95 samples/sec#011loss=1.027282\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch[465] avg_epoch_loss=1.027512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=465 train loss <loss>=0.7833279848098755\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch [465]#011Speed: 1368.73 samples/sec#011loss=0.783328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch[470] avg_epoch_loss=1.024939\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=470 train loss <loss>=0.7851339340209961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch [470]#011Speed: 831.33 samples/sec#011loss=0.785134\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch[475] avg_epoch_loss=1.041562\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=475 train loss <loss>=2.607511913776398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch [475]#011Speed: 1356.61 samples/sec#011loss=2.607512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch[480] avg_epoch_loss=1.041288\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=480 train loss <loss>=1.0152026891708374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch [480]#011Speed: 798.64 samples/sec#011loss=1.015203\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[485] avg_epoch_loss=1.041204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=485 train loss <loss>=1.033070480823517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [485]#011Speed: 1344.18 samples/sec#011loss=1.033070\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[490] avg_epoch_loss=1.041221\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=490 train loss <loss>=1.0429129362106324\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [490]#011Speed: 858.91 samples/sec#011loss=1.042913\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[495] avg_epoch_loss=1.039999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=495 train loss <loss>=0.9199373960494995\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [495]#011Speed: 1360.95 samples/sec#011loss=0.919937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[500] avg_epoch_loss=1.038743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=500 train loss <loss>=0.9141768097877503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [500]#011Speed: 851.02 samples/sec#011loss=0.914177\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[505] avg_epoch_loss=1.037409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=505 train loss <loss>=0.9037317156791687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [505]#011Speed: 1322.62 samples/sec#011loss=0.903732\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[510] avg_epoch_loss=1.037071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=510 train loss <loss>=1.00287606716156\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [510]#011Speed: 838.38 samples/sec#011loss=1.002876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[515] avg_epoch_loss=1.035256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=515 train loss <loss>=0.8497212052345275\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [515]#011Speed: 1267.93 samples/sec#011loss=0.849721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch[520] avg_epoch_loss=1.034359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=520 train loss <loss>=0.9418418526649475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch [520]#011Speed: 853.12 samples/sec#011loss=0.941842\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch[525] avg_epoch_loss=1.032452\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=525 train loss <loss>=0.8337154269218445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch [525]#011Speed: 1357.95 samples/sec#011loss=0.833715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch[530] avg_epoch_loss=1.031193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=530 train loss <loss>=0.8987293481826782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch [530]#011Speed: 864.39 samples/sec#011loss=0.898729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch[535] avg_epoch_loss=1.029541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=535 train loss <loss>=0.8541597247123718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch [535]#011Speed: 1359.31 samples/sec#011loss=0.854160\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch[540] avg_epoch_loss=1.028603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=540 train loss <loss>=0.9279718160629272\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch [540]#011Speed: 872.16 samples/sec#011loss=0.927972\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch[545] avg_epoch_loss=1.026008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=545 train loss <loss>=0.7452279567718506\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch [545]#011Speed: 1314.67 samples/sec#011loss=0.745228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[15] Batch[550] avg_epoch_loss=1.024265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=550 train loss <loss>=0.8339375257492065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[15] Batch [550]#011Speed: 1172.17 samples/sec#011loss=0.833938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] processed a total of 17639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717506.6115127, \"EndTime\": 1620717524.0361261, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17424.465894699097, \"count\": 1, \"min\": 17424.465894699097, \"max\": 17424.465894699097}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=1012.3052392909136 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, train loss <loss>=1.0234829178754834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch[0] avg_epoch_loss=0.797047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=0.7970466017723083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch[5] avg_epoch_loss=0.932989\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=0.9329885542392731\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch [5]#011Speed: 1346.51 samples/sec#011loss=0.932989\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch[10] avg_epoch_loss=0.899190\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=0.8586321234703064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch [10]#011Speed: 851.44 samples/sec#011loss=0.858632\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch[15] avg_epoch_loss=0.904999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=15 train loss <loss>=0.9177780151367188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch [15]#011Speed: 1361.50 samples/sec#011loss=0.917778\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch[20] avg_epoch_loss=0.949628\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=20 train loss <loss>=1.092440402507782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch [20]#011Speed: 828.82 samples/sec#011loss=1.092440\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch[25] avg_epoch_loss=0.995188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=25 train loss <loss>=1.1865386486053466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch [25]#011Speed: 1364.13 samples/sec#011loss=1.186539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch[30] avg_epoch_loss=0.995419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=30 train loss <loss>=0.9966210126876831\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch [30]#011Speed: 806.44 samples/sec#011loss=0.996621\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch[35] avg_epoch_loss=0.985824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=35 train loss <loss>=0.9263355493545532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch [35]#011Speed: 1342.99 samples/sec#011loss=0.926336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch[40] avg_epoch_loss=0.984475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=40 train loss <loss>=0.9747651576995849\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch [40]#011Speed: 852.07 samples/sec#011loss=0.974765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch[45] avg_epoch_loss=0.974666\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=45 train loss <loss>=0.8942323684692383\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch [45]#011Speed: 1354.87 samples/sec#011loss=0.894232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch[50] avg_epoch_loss=0.964345\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=50 train loss <loss>=0.8693933486938477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch [50]#011Speed: 836.48 samples/sec#011loss=0.869393\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch[55] avg_epoch_loss=0.960321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=55 train loss <loss>=0.9192746758460999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch [55]#011Speed: 1342.91 samples/sec#011loss=0.919275\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[60] avg_epoch_loss=0.949354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=60 train loss <loss>=0.8265271425247193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [60]#011Speed: 764.43 samples/sec#011loss=0.826527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[65] avg_epoch_loss=0.947710\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=65 train loss <loss>=0.9276430010795593\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [65]#011Speed: 1364.66 samples/sec#011loss=0.927643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[70] avg_epoch_loss=0.940677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=70 train loss <loss>=0.8478440761566162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [70]#011Speed: 870.33 samples/sec#011loss=0.847844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[75] avg_epoch_loss=0.932963\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=75 train loss <loss>=0.8234192252159118\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [75]#011Speed: 1371.30 samples/sec#011loss=0.823419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[80] avg_epoch_loss=0.927387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=80 train loss <loss>=0.8426368713378907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [80]#011Speed: 852.37 samples/sec#011loss=0.842637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[85] avg_epoch_loss=0.919454\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=85 train loss <loss>=0.7909366250038147\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [85]#011Speed: 1316.39 samples/sec#011loss=0.790937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[90] avg_epoch_loss=0.913809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=90 train loss <loss>=0.8167156100273132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [90]#011Speed: 787.58 samples/sec#011loss=0.816716\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch[95] avg_epoch_loss=1.026977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=95 train loss <loss>=3.086634600162506\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch [95]#011Speed: 1335.63 samples/sec#011loss=3.086635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch[100] avg_epoch_loss=1.021959\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=100 train loss <loss>=0.9256123661994934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch [100]#011Speed: 858.26 samples/sec#011loss=0.925612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch[105] avg_epoch_loss=1.022041\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=105 train loss <loss>=1.0237072467803956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch [105]#011Speed: 1266.17 samples/sec#011loss=1.023707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch[110] avg_epoch_loss=1.019879\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=110 train loss <loss>=0.9740318059921265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch [110]#011Speed: 569.84 samples/sec#011loss=0.974032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch[115] avg_epoch_loss=1.019570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=115 train loss <loss>=1.0127216577529907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch [115]#011Speed: 883.05 samples/sec#011loss=1.012722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch[120] avg_epoch_loss=1.014683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=120 train loss <loss>=0.9012968063354492\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch [120]#011Speed: 550.18 samples/sec#011loss=0.901297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch[125] avg_epoch_loss=1.008154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=125 train loss <loss>=0.850162148475647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch [125]#011Speed: 1327.62 samples/sec#011loss=0.850162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch[130] avg_epoch_loss=1.003551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=130 train loss <loss>=0.8875622391700745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch [130]#011Speed: 858.93 samples/sec#011loss=0.887562\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch[135] avg_epoch_loss=1.007901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=135 train loss <loss>=1.1218505501747131\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch [135]#011Speed: 1329.63 samples/sec#011loss=1.121851\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch[140] avg_epoch_loss=1.003183\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=140 train loss <loss>=0.8748589992523194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch [140]#011Speed: 857.24 samples/sec#011loss=0.874859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch[145] avg_epoch_loss=0.998109\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=145 train loss <loss>=0.8550351738929749\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch [145]#011Speed: 1342.57 samples/sec#011loss=0.855035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch[150] avg_epoch_loss=0.995596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=150 train loss <loss>=0.9222073316574096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch [150]#011Speed: 757.98 samples/sec#011loss=0.922207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch[155] avg_epoch_loss=0.990062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=155 train loss <loss>=0.8229416489601136\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch [155]#011Speed: 1344.03 samples/sec#011loss=0.822942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch[160] avg_epoch_loss=0.983308\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=160 train loss <loss>=0.7725776553153991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch [160]#011Speed: 598.30 samples/sec#011loss=0.772578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch[165] avg_epoch_loss=1.002399\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=165 train loss <loss>=1.617134404182434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch [165]#011Speed: 1223.64 samples/sec#011loss=1.617134\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch[170] avg_epoch_loss=0.999576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=170 train loss <loss>=0.905839717388153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch [170]#011Speed: 849.21 samples/sec#011loss=0.905840\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch[175] avg_epoch_loss=0.997685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=175 train loss <loss>=0.9330172777175904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch [175]#011Speed: 1354.31 samples/sec#011loss=0.933017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch[180] avg_epoch_loss=0.995650\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=180 train loss <loss>=0.9240345120429992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch [180]#011Speed: 762.80 samples/sec#011loss=0.924035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch[185] avg_epoch_loss=0.994436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=185 train loss <loss>=0.9504722952842712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch [185]#011Speed: 1369.74 samples/sec#011loss=0.950472\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch[190] avg_epoch_loss=0.992382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=190 train loss <loss>=0.9159832119941711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch [190]#011Speed: 862.08 samples/sec#011loss=0.915983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch[195] avg_epoch_loss=0.991518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=195 train loss <loss>=0.9585051774978638\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch [195]#011Speed: 1355.83 samples/sec#011loss=0.958505\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch[200] avg_epoch_loss=1.000027\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=200 train loss <loss>=1.3335822701454163\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch [200]#011Speed: 813.02 samples/sec#011loss=1.333582\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch[205] avg_epoch_loss=1.004447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=205 train loss <loss>=1.1821102738380431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch [205]#011Speed: 1301.72 samples/sec#011loss=1.182110\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[210] avg_epoch_loss=1.005729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=210 train loss <loss>=1.0585617065429687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [210]#011Speed: 765.35 samples/sec#011loss=1.058562\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[215] avg_epoch_loss=1.004286\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=215 train loss <loss>=0.9434008598327637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [215]#011Speed: 1247.64 samples/sec#011loss=0.943401\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[220] avg_epoch_loss=1.002815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=220 train loss <loss>=0.9392503142356873\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [220]#011Speed: 838.19 samples/sec#011loss=0.939250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[225] avg_epoch_loss=1.000601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=225 train loss <loss>=0.9027633190155029\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [225]#011Speed: 1325.88 samples/sec#011loss=0.902763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[230] avg_epoch_loss=0.996587\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=230 train loss <loss>=0.8151556968688964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [230]#011Speed: 862.41 samples/sec#011loss=0.815156\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[235] avg_epoch_loss=0.993569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=235 train loss <loss>=0.8541390538215637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [235]#011Speed: 1309.01 samples/sec#011loss=0.854139\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[240] avg_epoch_loss=0.988551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=240 train loss <loss>=0.7516795754432678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [240]#011Speed: 847.08 samples/sec#011loss=0.751680\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch[245] avg_epoch_loss=0.984492\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=245 train loss <loss>=0.7888745188713073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch [245]#011Speed: 1249.83 samples/sec#011loss=0.788875\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch[250] avg_epoch_loss=0.983498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=250 train loss <loss>=0.9345612049102783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch [250]#011Speed: 845.87 samples/sec#011loss=0.934561\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch[255] avg_epoch_loss=0.985207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=255 train loss <loss>=1.071018648147583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch [255]#011Speed: 1375.13 samples/sec#011loss=1.071019\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch[260] avg_epoch_loss=0.988558\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=260 train loss <loss>=1.1601007580757141\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch [260]#011Speed: 864.38 samples/sec#011loss=1.160101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch[265] avg_epoch_loss=0.989707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=265 train loss <loss>=1.0497101068496704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch [265]#011Speed: 1359.51 samples/sec#011loss=1.049710\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch[270] avg_epoch_loss=0.991941\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=270 train loss <loss>=1.1108073234558105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch [270]#011Speed: 844.02 samples/sec#011loss=1.110807\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[275] avg_epoch_loss=0.993282\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=275 train loss <loss>=1.0659358859062196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [275]#011Speed: 1258.56 samples/sec#011loss=1.065936\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[280] avg_epoch_loss=0.991039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=280 train loss <loss>=0.8672096014022828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [280]#011Speed: 801.64 samples/sec#011loss=0.867210\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[285] avg_epoch_loss=0.988874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=285 train loss <loss>=0.8672012209892273\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [285]#011Speed: 1380.24 samples/sec#011loss=0.867201\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[290] avg_epoch_loss=0.986615\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=290 train loss <loss>=0.8574398398399353\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [290]#011Speed: 869.50 samples/sec#011loss=0.857440\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[295] avg_epoch_loss=0.983982\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=295 train loss <loss>=0.8307448863983155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [295]#011Speed: 1284.14 samples/sec#011loss=0.830745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[300] avg_epoch_loss=0.983121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=300 train loss <loss>=0.9321542501449585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [300]#011Speed: 839.87 samples/sec#011loss=0.932154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[305] avg_epoch_loss=0.979280\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=305 train loss <loss>=0.7480172872543335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [305]#011Speed: 1290.01 samples/sec#011loss=0.748017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch[310] avg_epoch_loss=0.976961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=310 train loss <loss>=0.8350268483161927\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch [310]#011Speed: 772.30 samples/sec#011loss=0.835027\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch[315] avg_epoch_loss=0.974528\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=315 train loss <loss>=0.8232123851776123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch [315]#011Speed: 1330.13 samples/sec#011loss=0.823212\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch[320] avg_epoch_loss=0.974117\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=320 train loss <loss>=0.9481567978858948\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch [320]#011Speed: 849.05 samples/sec#011loss=0.948157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch[325] avg_epoch_loss=0.970991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=325 train loss <loss>=0.7703197240829468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch [325]#011Speed: 842.44 samples/sec#011loss=0.770320\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch[330] avg_epoch_loss=0.967387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=330 train loss <loss>=0.7323462247848511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch [330]#011Speed: 859.50 samples/sec#011loss=0.732346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch[335] avg_epoch_loss=0.963803\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=335 train loss <loss>=0.7265791058540344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch [335]#011Speed: 1364.28 samples/sec#011loss=0.726579\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch[340] avg_epoch_loss=0.961096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=340 train loss <loss>=0.7791828870773315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch [340]#011Speed: 803.46 samples/sec#011loss=0.779183\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch[345] avg_epoch_loss=0.957572\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=345 train loss <loss>=0.7172426342964172\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch [345]#011Speed: 1336.58 samples/sec#011loss=0.717243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch[350] avg_epoch_loss=0.956066\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=350 train loss <loss>=0.8518641710281372\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch [350]#011Speed: 857.62 samples/sec#011loss=0.851864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch[355] avg_epoch_loss=0.956153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=355 train loss <loss>=0.9622112035751342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch [355]#011Speed: 1362.88 samples/sec#011loss=0.962211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch[360] avg_epoch_loss=0.955191\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=360 train loss <loss>=0.8867545008659363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch [360]#011Speed: 821.40 samples/sec#011loss=0.886755\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch[365] avg_epoch_loss=0.954989\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=365 train loss <loss>=0.9403950929641723\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch [365]#011Speed: 1325.34 samples/sec#011loss=0.940395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch[370] avg_epoch_loss=0.951827\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=370 train loss <loss>=0.7203702211380005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch [370]#011Speed: 793.58 samples/sec#011loss=0.720370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch[375] avg_epoch_loss=0.949265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=375 train loss <loss>=0.7591666102409362\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch [375]#011Speed: 1272.66 samples/sec#011loss=0.759167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch[380] avg_epoch_loss=0.952240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=380 train loss <loss>=1.1759530663490296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch [380]#011Speed: 848.60 samples/sec#011loss=1.175953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch[385] avg_epoch_loss=0.949452\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=385 train loss <loss>=0.7370130062103272\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch [385]#011Speed: 1353.65 samples/sec#011loss=0.737013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch[390] avg_epoch_loss=0.947169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=390 train loss <loss>=0.770880663394928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch [390]#011Speed: 864.55 samples/sec#011loss=0.770881\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch[395] avg_epoch_loss=0.946573\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=395 train loss <loss>=0.8999713659286499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch [395]#011Speed: 1343.40 samples/sec#011loss=0.899971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[400] avg_epoch_loss=0.951201\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=400 train loss <loss>=1.317782747745514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [400]#011Speed: 855.60 samples/sec#011loss=1.317783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[405] avg_epoch_loss=0.950277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=405 train loss <loss>=0.8761539340019227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [405]#011Speed: 1274.71 samples/sec#011loss=0.876154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[410] avg_epoch_loss=0.948186\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=410 train loss <loss>=0.7783427596092224\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [410]#011Speed: 850.99 samples/sec#011loss=0.778343\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[415] avg_epoch_loss=0.947083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=415 train loss <loss>=0.8564838290214538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [415]#011Speed: 1375.14 samples/sec#011loss=0.856484\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[420] avg_epoch_loss=0.945877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=420 train loss <loss>=0.8455272197723389\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [420]#011Speed: 859.43 samples/sec#011loss=0.845527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[425] avg_epoch_loss=0.944214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=425 train loss <loss>=0.8041784882545471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [425]#011Speed: 1366.12 samples/sec#011loss=0.804178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[430] avg_epoch_loss=0.943059\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=430 train loss <loss>=0.8446871638298035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [430]#011Speed: 871.23 samples/sec#011loss=0.844687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch[435] avg_epoch_loss=0.941393\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=435 train loss <loss>=0.79771728515625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch [435]#011Speed: 1281.99 samples/sec#011loss=0.797717\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch[440] avg_epoch_loss=0.941150\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=440 train loss <loss>=0.9199630737304687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch [440]#011Speed: 758.79 samples/sec#011loss=0.919963\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch[445] avg_epoch_loss=0.941872\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=445 train loss <loss>=1.0055415630340576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch [445]#011Speed: 1344.59 samples/sec#011loss=1.005542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch[450] avg_epoch_loss=0.940699\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=450 train loss <loss>=0.8360968232154846\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch [450]#011Speed: 860.81 samples/sec#011loss=0.836097\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch[455] avg_epoch_loss=0.938836\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=455 train loss <loss>=0.7708266496658325\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch [455]#011Speed: 1370.34 samples/sec#011loss=0.770827\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch[460] avg_epoch_loss=0.938237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=460 train loss <loss>=0.8836078643798828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch [460]#011Speed: 850.11 samples/sec#011loss=0.883608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch[465] avg_epoch_loss=0.937771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=465 train loss <loss>=0.8948216915130616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch [465]#011Speed: 1309.97 samples/sec#011loss=0.894822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch[470] avg_epoch_loss=0.953714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=470 train loss <loss>=2.4396013975143434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch [470]#011Speed: 792.99 samples/sec#011loss=2.439601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch[475] avg_epoch_loss=0.953772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=475 train loss <loss>=0.9591955423355103\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch [475]#011Speed: 1339.21 samples/sec#011loss=0.959196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch[480] avg_epoch_loss=0.953169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=480 train loss <loss>=0.8957954287528992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch [480]#011Speed: 841.47 samples/sec#011loss=0.895795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch[485] avg_epoch_loss=0.952434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=485 train loss <loss>=0.8817296147346496\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch [485]#011Speed: 878.60 samples/sec#011loss=0.881730\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch[490] avg_epoch_loss=0.951629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=490 train loss <loss>=0.8733074307441712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch [490]#011Speed: 774.97 samples/sec#011loss=0.873307\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch[495] avg_epoch_loss=0.950267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=495 train loss <loss>=0.8165379405021668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch [495]#011Speed: 1219.17 samples/sec#011loss=0.816538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch[500] avg_epoch_loss=0.948944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=500 train loss <loss>=0.8177068829536438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch [500]#011Speed: 756.69 samples/sec#011loss=0.817707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch[505] avg_epoch_loss=0.947478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=505 train loss <loss>=0.8006160378456115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch [505]#011Speed: 1347.95 samples/sec#011loss=0.800616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch[510] avg_epoch_loss=0.946821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=510 train loss <loss>=0.8803268671035767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch [510]#011Speed: 859.99 samples/sec#011loss=0.880327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch[515] avg_epoch_loss=0.945394\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=515 train loss <loss>=0.7995520234107971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch [515]#011Speed: 1374.20 samples/sec#011loss=0.799552\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch[520] avg_epoch_loss=0.944171\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=520 train loss <loss>=0.8179462909698486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch [520]#011Speed: 806.65 samples/sec#011loss=0.817946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch[525] avg_epoch_loss=0.942941\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=525 train loss <loss>=0.814819598197937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch [525]#011Speed: 1340.36 samples/sec#011loss=0.814820\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch[530] avg_epoch_loss=0.942461\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=530 train loss <loss>=0.8919070601463318\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch [530]#011Speed: 495.93 samples/sec#011loss=0.891907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch[535] avg_epoch_loss=0.941749\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=535 train loss <loss>=0.8661078214645386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch [535]#011Speed: 772.59 samples/sec#011loss=0.866108\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch[540] avg_epoch_loss=0.940192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=540 train loss <loss>=0.7732685565948486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch [540]#011Speed: 620.65 samples/sec#011loss=0.773269\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch[545] avg_epoch_loss=0.938964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=545 train loss <loss>=0.8061271905899048\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch [545]#011Speed: 1293.34 samples/sec#011loss=0.806127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] processed a total of 17478 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717524.036199, \"EndTime\": 1620717541.970716, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17933.697938919067, \"count\": 1, \"min\": 17933.697938919067, \"max\": 17933.697938919067}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=974.579485683503 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #progress_metric: host=algo-1, completed 85.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, train loss <loss>=0.9385971584965149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_0483872e-8207-4f5b-ac38-cd437d0f4609-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717541.9708645, \"EndTime\": 1620717541.9839125, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 12.181282043457031, \"count\": 1, \"min\": 12.181282043457031, \"max\": 12.181282043457031}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch[0] avg_epoch_loss=0.698174\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=0.6981738805770874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch[5] avg_epoch_loss=0.716599\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=0.7165986796220144\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch [5]#011Speed: 701.71 samples/sec#011loss=0.716599\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch[10] avg_epoch_loss=0.741193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=0.7707068085670471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch [10]#011Speed: 484.41 samples/sec#011loss=0.770707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch[15] avg_epoch_loss=0.815750\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=15 train loss <loss>=0.9797732114791871\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch [15]#011Speed: 867.95 samples/sec#011loss=0.979773\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch[20] avg_epoch_loss=0.835685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=20 train loss <loss>=0.8994791269302368\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch [20]#011Speed: 835.60 samples/sec#011loss=0.899479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch[25] avg_epoch_loss=0.849589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=25 train loss <loss>=0.907983660697937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch [25]#011Speed: 1300.06 samples/sec#011loss=0.907984\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch[30] avg_epoch_loss=0.849295\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=30 train loss <loss>=0.8477661848068238\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch [30]#011Speed: 663.07 samples/sec#011loss=0.847766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch[35] avg_epoch_loss=0.846302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=35 train loss <loss>=0.8277504324913025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch [35]#011Speed: 859.54 samples/sec#011loss=0.827750\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch[40] avg_epoch_loss=0.837106\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=40 train loss <loss>=0.7708899140357971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch [40]#011Speed: 476.51 samples/sec#011loss=0.770890\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] Epoch[17] Batch[45] avg_epoch_loss=0.832717\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=45 train loss <loss>=0.7967288970947266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] Epoch[17] Batch [45]#011Speed: 761.14 samples/sec#011loss=0.796729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] Epoch[17] Batch[50] avg_epoch_loss=0.836481\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=50 train loss <loss>=0.8711070656776428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] Epoch[17] Batch [50]#011Speed: 463.77 samples/sec#011loss=0.871107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] Epoch[17] Batch[55] avg_epoch_loss=0.839312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=55 train loss <loss>=0.8681851863861084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] Epoch[17] Batch [55]#011Speed: 774.70 samples/sec#011loss=0.868185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch[60] avg_epoch_loss=0.845567\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=60 train loss <loss>=0.9156229972839356\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch [60]#011Speed: 367.19 samples/sec#011loss=0.915623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch[65] avg_epoch_loss=0.864724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=65 train loss <loss>=1.0984451413154601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch [65]#011Speed: 733.30 samples/sec#011loss=1.098445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch[70] avg_epoch_loss=0.861989\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=70 train loss <loss>=0.8258883714675903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch [70]#011Speed: 499.93 samples/sec#011loss=0.825888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch[75] avg_epoch_loss=0.858248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=75 train loss <loss>=0.8051182508468628\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch [75]#011Speed: 1306.48 samples/sec#011loss=0.805118\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[80] avg_epoch_loss=0.859303\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=80 train loss <loss>=0.8753488063812256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [80]#011Speed: 799.19 samples/sec#011loss=0.875349\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[85] avg_epoch_loss=0.861358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=85 train loss <loss>=0.8946413040161133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [85]#011Speed: 1361.35 samples/sec#011loss=0.894641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[90] avg_epoch_loss=0.889326\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=90 train loss <loss>=1.3703880667686463\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [90]#011Speed: 806.34 samples/sec#011loss=1.370388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[95] avg_epoch_loss=0.897481\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=95 train loss <loss>=1.0458871841430664\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [95]#011Speed: 1332.99 samples/sec#011loss=1.045887\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[100] avg_epoch_loss=0.904449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=100 train loss <loss>=1.0382413148880005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [100]#011Speed: 836.79 samples/sec#011loss=1.038241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[105] avg_epoch_loss=0.908477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=105 train loss <loss>=0.9898460984230042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [105]#011Speed: 1322.30 samples/sec#011loss=0.989846\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[110] avg_epoch_loss=0.912517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=110 train loss <loss>=0.9981670618057251\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [110]#011Speed: 830.88 samples/sec#011loss=0.998167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch[115] avg_epoch_loss=0.910432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=115 train loss <loss>=0.8641325950622558\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch [115]#011Speed: 1292.18 samples/sec#011loss=0.864133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch[120] avg_epoch_loss=0.911688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=120 train loss <loss>=0.9408371448516846\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch [120]#011Speed: 843.77 samples/sec#011loss=0.940837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch[125] avg_epoch_loss=0.913359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=125 train loss <loss>=0.9537972211837769\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch [125]#011Speed: 1177.32 samples/sec#011loss=0.953797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch[130] avg_epoch_loss=0.909625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=130 train loss <loss>=0.8155153632164002\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch [130]#011Speed: 860.31 samples/sec#011loss=0.815515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch[135] avg_epoch_loss=0.905049\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=135 train loss <loss>=0.7851668357849121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch [135]#011Speed: 1363.32 samples/sec#011loss=0.785167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch[140] avg_epoch_loss=0.902842\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=140 train loss <loss>=0.8428227066993713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch [140]#011Speed: 834.78 samples/sec#011loss=0.842823\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[145] avg_epoch_loss=0.902034\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=145 train loss <loss>=0.8792268991470337\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [145]#011Speed: 1328.47 samples/sec#011loss=0.879227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[150] avg_epoch_loss=0.909021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=150 train loss <loss>=1.1130638718605042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [150]#011Speed: 797.91 samples/sec#011loss=1.113064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[155] avg_epoch_loss=0.907016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=155 train loss <loss>=0.8464402556419373\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [155]#011Speed: 1242.07 samples/sec#011loss=0.846440\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[160] avg_epoch_loss=0.908709\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=160 train loss <loss>=0.9615324258804321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [160]#011Speed: 860.61 samples/sec#011loss=0.961532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[165] avg_epoch_loss=0.912124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=165 train loss <loss>=1.0220843195915221\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [165]#011Speed: 1355.12 samples/sec#011loss=1.022084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[170] avg_epoch_loss=0.911538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=170 train loss <loss>=0.8920980453491211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [170]#011Speed: 850.84 samples/sec#011loss=0.892098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[175] avg_epoch_loss=0.910162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=175 train loss <loss>=0.8631047368049621\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [175]#011Speed: 1333.42 samples/sec#011loss=0.863105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch[180] avg_epoch_loss=0.911121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=180 train loss <loss>=0.9448919892311096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch [180]#011Speed: 831.72 samples/sec#011loss=0.944892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch[185] avg_epoch_loss=0.914318\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=185 train loss <loss>=1.0300137162208558\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch [185]#011Speed: 1316.56 samples/sec#011loss=1.030014\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch[190] avg_epoch_loss=0.918196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=190 train loss <loss>=1.0624712228775024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch [190]#011Speed: 768.93 samples/sec#011loss=1.062471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch[195] avg_epoch_loss=0.920637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=195 train loss <loss>=1.0138863563537597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch [195]#011Speed: 1349.98 samples/sec#011loss=1.013886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch[200] avg_epoch_loss=0.921309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=200 train loss <loss>=0.9476434111595153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch [200]#011Speed: 854.71 samples/sec#011loss=0.947643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch[205] avg_epoch_loss=0.927908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=205 train loss <loss>=1.1931878209114075\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch [205]#011Speed: 1361.73 samples/sec#011loss=1.193188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch[210] avg_epoch_loss=0.935585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=210 train loss <loss>=1.2518767237663269\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch [210]#011Speed: 622.86 samples/sec#011loss=1.251877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch[215] avg_epoch_loss=0.936638\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=215 train loss <loss>=0.9810796499252319\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch [215]#011Speed: 1108.01 samples/sec#011loss=0.981080\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch[220] avg_epoch_loss=0.936719\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=220 train loss <loss>=0.9402111649513245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch [220]#011Speed: 792.14 samples/sec#011loss=0.940211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch[225] avg_epoch_loss=0.936177\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=225 train loss <loss>=0.9122191786766052\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch [225]#011Speed: 1372.23 samples/sec#011loss=0.912219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch[230] avg_epoch_loss=0.935425\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=230 train loss <loss>=0.9014635562896729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch [230]#011Speed: 843.75 samples/sec#011loss=0.901464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch[235] avg_epoch_loss=0.933042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=235 train loss <loss>=0.8229203701019288\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch [235]#011Speed: 1241.87 samples/sec#011loss=0.822920\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch[240] avg_epoch_loss=0.930576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=240 train loss <loss>=0.8141737461090088\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch [240]#011Speed: 760.29 samples/sec#011loss=0.814174\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch[245] avg_epoch_loss=0.929076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=245 train loss <loss>=0.8567833542823792\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch [245]#011Speed: 1316.88 samples/sec#011loss=0.856783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch[250] avg_epoch_loss=0.927859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=250 train loss <loss>=0.8679955124855041\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch [250]#011Speed: 797.44 samples/sec#011loss=0.867996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch[255] avg_epoch_loss=0.925241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=255 train loss <loss>=0.7937901616096497\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch [255]#011Speed: 1355.17 samples/sec#011loss=0.793790\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch[260] avg_epoch_loss=0.924571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=260 train loss <loss>=0.890316641330719\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch [260]#011Speed: 860.39 samples/sec#011loss=0.890317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch[265] avg_epoch_loss=0.924765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=265 train loss <loss>=0.9348661780357361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch [265]#011Speed: 1335.74 samples/sec#011loss=0.934866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch[270] avg_epoch_loss=0.934026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=270 train loss <loss>=1.4267136454582214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch [270]#011Speed: 844.77 samples/sec#011loss=1.426714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch[275] avg_epoch_loss=0.932816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=275 train loss <loss>=0.8672582745552063\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch [275]#011Speed: 1341.44 samples/sec#011loss=0.867258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch[280] avg_epoch_loss=0.932142\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=280 train loss <loss>=0.8949015021324158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch [280]#011Speed: 815.32 samples/sec#011loss=0.894902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch[285] avg_epoch_loss=0.931894\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=285 train loss <loss>=0.9179856181144714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch [285]#011Speed: 1356.71 samples/sec#011loss=0.917986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch[290] avg_epoch_loss=0.931754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=290 train loss <loss>=0.9237013697624207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch [290]#011Speed: 843.02 samples/sec#011loss=0.923701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch[295] avg_epoch_loss=0.930830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=295 train loss <loss>=0.877058470249176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch [295]#011Speed: 1358.79 samples/sec#011loss=0.877058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[300] avg_epoch_loss=0.928874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=300 train loss <loss>=0.8131285309791565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [300]#011Speed: 859.36 samples/sec#011loss=0.813129\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[305] avg_epoch_loss=0.928858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=305 train loss <loss>=0.9278526544570923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [305]#011Speed: 1327.19 samples/sec#011loss=0.927853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[310] avg_epoch_loss=0.930741\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=310 train loss <loss>=1.0459880590438844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [310]#011Speed: 845.92 samples/sec#011loss=1.045988\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[315] avg_epoch_loss=0.931071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=315 train loss <loss>=0.9516249775886536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [315]#011Speed: 1252.29 samples/sec#011loss=0.951625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[320] avg_epoch_loss=0.930074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=320 train loss <loss>=0.8670581936836242\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [320]#011Speed: 860.07 samples/sec#011loss=0.867058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[325] avg_epoch_loss=0.929708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=325 train loss <loss>=0.9061886429786682\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [325]#011Speed: 1381.29 samples/sec#011loss=0.906189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[330] avg_epoch_loss=0.928518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=330 train loss <loss>=0.8509313464164734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [330]#011Speed: 868.60 samples/sec#011loss=0.850931\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch[335] avg_epoch_loss=0.926200\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=335 train loss <loss>=0.7727714896202087\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch [335]#011Speed: 1321.39 samples/sec#011loss=0.772771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch[340] avg_epoch_loss=0.924754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=340 train loss <loss>=0.8275933504104614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch [340]#011Speed: 866.31 samples/sec#011loss=0.827593\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch[345] avg_epoch_loss=0.921877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=345 train loss <loss>=0.7256419658660889\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch [345]#011Speed: 1330.50 samples/sec#011loss=0.725642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch[350] avg_epoch_loss=0.920268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=350 train loss <loss>=0.8088877916336059\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch [350]#011Speed: 791.73 samples/sec#011loss=0.808888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch[355] avg_epoch_loss=0.920748\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=355 train loss <loss>=0.954459810256958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch [355]#011Speed: 1170.72 samples/sec#011loss=0.954460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch[360] avg_epoch_loss=0.918886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=360 train loss <loss>=0.7863306164741516\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch [360]#011Speed: 834.09 samples/sec#011loss=0.786331\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch[365] avg_epoch_loss=0.918412\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=365 train loss <loss>=0.8841532468795776\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch [365]#011Speed: 1344.88 samples/sec#011loss=0.884153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch[370] avg_epoch_loss=0.917519\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=370 train loss <loss>=0.8522112488746643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch [370]#011Speed: 848.35 samples/sec#011loss=0.852211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch[375] avg_epoch_loss=0.916766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=375 train loss <loss>=0.8608296632766723\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch [375]#011Speed: 842.16 samples/sec#011loss=0.860830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch[380] avg_epoch_loss=0.915885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=380 train loss <loss>=0.8496668815612793\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch [380]#011Speed: 764.68 samples/sec#011loss=0.849667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch[385] avg_epoch_loss=0.916280\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=385 train loss <loss>=0.9463539600372315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch [385]#011Speed: 1365.53 samples/sec#011loss=0.946354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch[390] avg_epoch_loss=0.916586\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=390 train loss <loss>=0.940267825126648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch [390]#011Speed: 809.24 samples/sec#011loss=0.940268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch[395] avg_epoch_loss=0.916551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=395 train loss <loss>=0.913791048526764\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch [395]#011Speed: 1283.78 samples/sec#011loss=0.913791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch[400] avg_epoch_loss=0.915970\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=400 train loss <loss>=0.869981563091278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch [400]#011Speed: 851.49 samples/sec#011loss=0.869982\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch[405] avg_epoch_loss=0.915398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=405 train loss <loss>=0.8694701194763184\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch [405]#011Speed: 1354.24 samples/sec#011loss=0.869470\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch[410] avg_epoch_loss=0.913985\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=410 train loss <loss>=0.7992368340492249\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch [410]#011Speed: 792.17 samples/sec#011loss=0.799237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch[415] avg_epoch_loss=0.913370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=415 train loss <loss>=0.8628151535987854\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch [415]#011Speed: 1352.07 samples/sec#011loss=0.862815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch[420] avg_epoch_loss=0.913704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=420 train loss <loss>=0.9415425658226013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch [420]#011Speed: 841.20 samples/sec#011loss=0.941543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[425] avg_epoch_loss=0.915859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=425 train loss <loss>=1.0972620010375977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [425]#011Speed: 1315.03 samples/sec#011loss=1.097262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[430] avg_epoch_loss=0.917005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=430 train loss <loss>=1.014686918258667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [430]#011Speed: 837.19 samples/sec#011loss=1.014687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[435] avg_epoch_loss=0.917613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=435 train loss <loss>=0.9700511693954468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [435]#011Speed: 1374.49 samples/sec#011loss=0.970051\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[440] avg_epoch_loss=0.917964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=440 train loss <loss>=0.9484986543655396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [440]#011Speed: 876.59 samples/sec#011loss=0.948499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[445] avg_epoch_loss=0.917543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=445 train loss <loss>=0.8804224014282227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [445]#011Speed: 1222.59 samples/sec#011loss=0.880422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[450] avg_epoch_loss=0.916547\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=450 train loss <loss>=0.8277329325675964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [450]#011Speed: 858.99 samples/sec#011loss=0.827733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[455] avg_epoch_loss=0.916452\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=455 train loss <loss>=0.9079173326492309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [455]#011Speed: 1367.69 samples/sec#011loss=0.907917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch[460] avg_epoch_loss=0.915522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=460 train loss <loss>=0.8306192994117737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch [460]#011Speed: 783.44 samples/sec#011loss=0.830619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch[465] avg_epoch_loss=0.914771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=465 train loss <loss>=0.8455777168273926\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch [465]#011Speed: 844.63 samples/sec#011loss=0.845578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch[470] avg_epoch_loss=0.913634\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=470 train loss <loss>=0.8077025890350342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch [470]#011Speed: 515.14 samples/sec#011loss=0.807703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch[475] avg_epoch_loss=0.912460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=475 train loss <loss>=0.8018091559410095\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch [475]#011Speed: 930.43 samples/sec#011loss=0.801809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch[480] avg_epoch_loss=0.911651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=480 train loss <loss>=0.8346910595893859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch [480]#011Speed: 853.32 samples/sec#011loss=0.834691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch[485] avg_epoch_loss=0.911599\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=485 train loss <loss>=0.9065271139144897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch [485]#011Speed: 1325.03 samples/sec#011loss=0.906527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch[490] avg_epoch_loss=0.910074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=490 train loss <loss>=0.7618758678436279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch [490]#011Speed: 825.54 samples/sec#011loss=0.761876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch[495] avg_epoch_loss=0.908963\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=495 train loss <loss>=0.7998523592948914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch [495]#011Speed: 1349.59 samples/sec#011loss=0.799852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch[500] avg_epoch_loss=0.906726\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=500 train loss <loss>=0.6847767472267151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch [500]#011Speed: 804.38 samples/sec#011loss=0.684777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch[505] avg_epoch_loss=0.907410\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=505 train loss <loss>=0.9760145783424378\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch [505]#011Speed: 1360.55 samples/sec#011loss=0.976015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch[510] avg_epoch_loss=0.906406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=510 train loss <loss>=0.8047980546951294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch [510]#011Speed: 864.22 samples/sec#011loss=0.804798\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch[515] avg_epoch_loss=0.905166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=515 train loss <loss>=0.7784466028213501\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch [515]#011Speed: 1329.68 samples/sec#011loss=0.778447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch[520] avg_epoch_loss=0.903666\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=520 train loss <loss>=0.7488564610481262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch [520]#011Speed: 867.83 samples/sec#011loss=0.748856\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch[525] avg_epoch_loss=0.902266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=525 train loss <loss>=0.7563891410827637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch [525]#011Speed: 1344.48 samples/sec#011loss=0.756389\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch[530] avg_epoch_loss=0.902915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=530 train loss <loss>=0.9712138295173645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch [530]#011Speed: 581.80 samples/sec#011loss=0.971214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch[535] avg_epoch_loss=0.902873\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=535 train loss <loss>=0.8983402371406555\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch [535]#011Speed: 1291.58 samples/sec#011loss=0.898340\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch[540] avg_epoch_loss=0.903198\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=540 train loss <loss>=0.9381088018417358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch [540]#011Speed: 882.31 samples/sec#011loss=0.938109\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[17] Batch[545] avg_epoch_loss=0.901647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=545 train loss <loss>=0.7337901711463928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[17] Batch [545]#011Speed: 1280.69 samples/sec#011loss=0.733790\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] processed a total of 17560 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717541.984576, \"EndTime\": 1620717561.138896, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 19154.24942970276, \"count\": 1, \"min\": 19154.24942970276, \"max\": 19154.24942970276}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=916.7629510355682 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, train loss <loss>=0.9012727438860687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_590c5e48-fc6d-4f88-b7b3-933a991aba04-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717561.1389625, \"EndTime\": 1620717561.1497493, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.945869445800781, \"count\": 1, \"min\": 9.945869445800781, \"max\": 9.945869445800781}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch[0] avg_epoch_loss=0.696413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=0.6964132189750671\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch[5] avg_epoch_loss=0.733663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=0.7336626946926117\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch [5]#011Speed: 1337.98 samples/sec#011loss=0.733663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch[10] avg_epoch_loss=0.783371\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=0.8430205583572388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch [10]#011Speed: 849.02 samples/sec#011loss=0.843021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch[15] avg_epoch_loss=0.829410\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=15 train loss <loss>=0.9306958079338074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch [15]#011Speed: 1237.18 samples/sec#011loss=0.930696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch[20] avg_epoch_loss=0.845190\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=20 train loss <loss>=0.8956859707832336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch [20]#011Speed: 855.40 samples/sec#011loss=0.895686\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch[25] avg_epoch_loss=0.880098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=25 train loss <loss>=1.0267120838165282\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch [25]#011Speed: 1321.57 samples/sec#011loss=1.026712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch[30] avg_epoch_loss=0.871523\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=30 train loss <loss>=0.826933228969574\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch [30]#011Speed: 856.91 samples/sec#011loss=0.826933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch[35] avg_epoch_loss=0.858347\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=35 train loss <loss>=0.7766569256782532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch [35]#011Speed: 1365.12 samples/sec#011loss=0.776657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch[40] avg_epoch_loss=0.861405\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=40 train loss <loss>=0.8834171414375305\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch [40]#011Speed: 851.52 samples/sec#011loss=0.883417\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch[45] avg_epoch_loss=0.872077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=45 train loss <loss>=0.9595921635627747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch [45]#011Speed: 1355.13 samples/sec#011loss=0.959592\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch[50] avg_epoch_loss=0.876712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=50 train loss <loss>=0.9193525075912475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch [50]#011Speed: 812.58 samples/sec#011loss=0.919353\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch[55] avg_epoch_loss=0.871213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=55 train loss <loss>=0.8151259660720825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch [55]#011Speed: 1366.65 samples/sec#011loss=0.815126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch[60] avg_epoch_loss=0.867519\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=60 train loss <loss>=0.826140820980072\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch [60]#011Speed: 844.40 samples/sec#011loss=0.826141\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch[65] avg_epoch_loss=0.867343\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=65 train loss <loss>=0.8652024149894715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch [65]#011Speed: 1378.85 samples/sec#011loss=0.865202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch[70] avg_epoch_loss=0.863833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=70 train loss <loss>=0.8175013661384583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch [70]#011Speed: 867.79 samples/sec#011loss=0.817501\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch[75] avg_epoch_loss=0.853686\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=75 train loss <loss>=0.7095940828323364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch [75]#011Speed: 1300.97 samples/sec#011loss=0.709594\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch[80] avg_epoch_loss=0.857763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=80 train loss <loss>=0.9197299480438232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch [80]#011Speed: 806.35 samples/sec#011loss=0.919730\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch[85] avg_epoch_loss=0.883667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=85 train loss <loss>=1.3033190965652466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch [85]#011Speed: 1168.52 samples/sec#011loss=1.303319\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[90] avg_epoch_loss=0.897693\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=90 train loss <loss>=1.1389365553855897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [90]#011Speed: 856.96 samples/sec#011loss=1.138937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[95] avg_epoch_loss=0.898736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=95 train loss <loss>=0.9177112221717835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [95]#011Speed: 1343.70 samples/sec#011loss=0.917711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[100] avg_epoch_loss=0.902232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=100 train loss <loss>=0.9693567872047424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [100]#011Speed: 869.50 samples/sec#011loss=0.969357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[105] avg_epoch_loss=0.901902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=105 train loss <loss>=0.8952333092689514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [105]#011Speed: 1375.11 samples/sec#011loss=0.895233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[110] avg_epoch_loss=0.901475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=110 train loss <loss>=0.8924303412437439\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [110]#011Speed: 800.32 samples/sec#011loss=0.892430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[115] avg_epoch_loss=0.898643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=115 train loss <loss>=0.8357670307159424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [115]#011Speed: 1363.32 samples/sec#011loss=0.835767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[120] avg_epoch_loss=0.895370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=120 train loss <loss>=0.819440734386444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [120]#011Speed: 848.55 samples/sec#011loss=0.819441\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch[125] avg_epoch_loss=0.894219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=125 train loss <loss>=0.8663575291633606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch [125]#011Speed: 1354.76 samples/sec#011loss=0.866358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch[130] avg_epoch_loss=0.954368\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=130 train loss <loss>=2.470133376121521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch [130]#011Speed: 835.99 samples/sec#011loss=2.470133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch[135] avg_epoch_loss=0.952651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=135 train loss <loss>=0.9076781511306763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch [135]#011Speed: 1327.52 samples/sec#011loss=0.907678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch[140] avg_epoch_loss=0.952326\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=140 train loss <loss>=0.9434652209281922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch [140]#011Speed: 856.49 samples/sec#011loss=0.943465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch[145] avg_epoch_loss=0.965232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=145 train loss <loss>=1.3292003989219665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch [145]#011Speed: 846.80 samples/sec#011loss=1.329200\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch[150] avg_epoch_loss=0.965927\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=150 train loss <loss>=0.986209261417389\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch [150]#011Speed: 794.56 samples/sec#011loss=0.986209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch[155] avg_epoch_loss=0.965880\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=155 train loss <loss>=0.9644572257995605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch [155]#011Speed: 1311.99 samples/sec#011loss=0.964457\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch[160] avg_epoch_loss=0.965313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=160 train loss <loss>=0.9476322293281555\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch [160]#011Speed: 859.78 samples/sec#011loss=0.947632\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch[165] avg_epoch_loss=0.961573\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=165 train loss <loss>=0.8411430597305298\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch [165]#011Speed: 1326.70 samples/sec#011loss=0.841143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch[170] avg_epoch_loss=0.956992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=170 train loss <loss>=0.8049071669578552\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch [170]#011Speed: 834.64 samples/sec#011loss=0.804907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch[175] avg_epoch_loss=0.951094\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=175 train loss <loss>=0.7493607878684998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch [175]#011Speed: 1208.99 samples/sec#011loss=0.749361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch[180] avg_epoch_loss=0.947722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=180 train loss <loss>=0.8290564179420471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch [180]#011Speed: 827.77 samples/sec#011loss=0.829056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[185] avg_epoch_loss=0.946314\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=185 train loss <loss>=0.8953157901763916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [185]#011Speed: 1271.76 samples/sec#011loss=0.895316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[190] avg_epoch_loss=0.954374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=190 train loss <loss>=1.2542272806167603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [190]#011Speed: 863.19 samples/sec#011loss=1.254227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[195] avg_epoch_loss=0.966227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=195 train loss <loss>=1.4189932584762572\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [195]#011Speed: 1370.85 samples/sec#011loss=1.418993\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[200] avg_epoch_loss=0.967642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=200 train loss <loss>=1.023138952255249\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [200]#011Speed: 862.05 samples/sec#011loss=1.023139\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[205] avg_epoch_loss=0.964384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=205 train loss <loss>=0.8334083914756775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [205]#011Speed: 1305.75 samples/sec#011loss=0.833408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[210] avg_epoch_loss=0.972077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=210 train loss <loss>=1.2889991879463196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [210]#011Speed: 808.02 samples/sec#011loss=1.288999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[215] avg_epoch_loss=0.976085\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=215 train loss <loss>=1.1452465891838073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [215]#011Speed: 1360.53 samples/sec#011loss=1.145247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch[220] avg_epoch_loss=0.974962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=220 train loss <loss>=0.9264420628547668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch [220]#011Speed: 863.75 samples/sec#011loss=0.926442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch[225] avg_epoch_loss=0.972503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=225 train loss <loss>=0.8637954235076905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch [225]#011Speed: 1366.01 samples/sec#011loss=0.863795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch[230] avg_epoch_loss=0.970739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=230 train loss <loss>=0.8910120606422425\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch [230]#011Speed: 851.71 samples/sec#011loss=0.891012\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch[235] avg_epoch_loss=0.977821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=235 train loss <loss>=1.3050029635429383\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch [235]#011Speed: 1369.16 samples/sec#011loss=1.305003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch[240] avg_epoch_loss=0.975679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=240 train loss <loss>=0.8745837092399598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch [240]#011Speed: 818.72 samples/sec#011loss=0.874584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch[245] avg_epoch_loss=0.971524\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=245 train loss <loss>=0.7712680459022522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch [245]#011Speed: 1209.58 samples/sec#011loss=0.771268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:29 INFO 140281140962944] Epoch[18] Batch[250] avg_epoch_loss=0.966806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=250 train loss <loss>=0.7346675038337708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:29 INFO 140281140962944] Epoch[18] Batch [250]#011Speed: 851.39 samples/sec#011loss=0.734668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:29 INFO 140281140962944] Epoch[18] Batch[255] avg_epoch_loss=0.963974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=255 train loss <loss>=0.8218137621879578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:29 INFO 140281140962944] Epoch[18] Batch [255]#011Speed: 1357.97 samples/sec#011loss=0.821814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch[20] avg_epoch_loss=0.857079\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=20 train loss <loss>=0.8667746901512146\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch [20]#011Speed: 857.42 samples/sec#011loss=0.866775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch[25] avg_epoch_loss=0.851830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=25 train loss <loss>=0.8297819256782532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch [25]#011Speed: 1364.89 samples/sec#011loss=0.829782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch[30] avg_epoch_loss=0.832414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=30 train loss <loss>=0.7314531326293945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch [30]#011Speed: 853.09 samples/sec#011loss=0.731453\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch[35] avg_epoch_loss=0.824527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=35 train loss <loss>=0.7756261587142944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch [35]#011Speed: 1351.19 samples/sec#011loss=0.775626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[40] avg_epoch_loss=0.812882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=40 train loss <loss>=0.7290380358695984\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [40]#011Speed: 783.39 samples/sec#011loss=0.729038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[45] avg_epoch_loss=0.821061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=45 train loss <loss>=0.8881293058395385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [45]#011Speed: 1313.43 samples/sec#011loss=0.888129\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[50] avg_epoch_loss=0.819584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=50 train loss <loss>=0.8059944152832031\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [50]#011Speed: 852.24 samples/sec#011loss=0.805994\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[55] avg_epoch_loss=0.815517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=55 train loss <loss>=0.7740318298339843\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [55]#011Speed: 1274.65 samples/sec#011loss=0.774032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[60] avg_epoch_loss=0.816021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=60 train loss <loss>=0.8216732621192933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [60]#011Speed: 819.75 samples/sec#011loss=0.821673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[65] avg_epoch_loss=0.816899\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=65 train loss <loss>=0.8276053309440613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [65]#011Speed: 1325.43 samples/sec#011loss=0.827605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[70] avg_epoch_loss=0.814511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=70 train loss <loss>=0.7829940557479859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [70]#011Speed: 790.80 samples/sec#011loss=0.782994\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch[75] avg_epoch_loss=0.810077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=75 train loss <loss>=0.7471100926399231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch [75]#011Speed: 1138.92 samples/sec#011loss=0.747110\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch[80] avg_epoch_loss=0.809942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=80 train loss <loss>=0.8078848958015442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch [80]#011Speed: 654.50 samples/sec#011loss=0.807885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch[85] avg_epoch_loss=0.807760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=85 train loss <loss>=0.7724166512489319\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch [85]#011Speed: 1340.47 samples/sec#011loss=0.772417\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch[90] avg_epoch_loss=0.802751\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=90 train loss <loss>=0.7165985465049743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch [90]#011Speed: 858.61 samples/sec#011loss=0.716599\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch[95] avg_epoch_loss=0.796363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=95 train loss <loss>=0.6801022291183472\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch [95]#011Speed: 1372.10 samples/sec#011loss=0.680102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch[100] avg_epoch_loss=0.793112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=100 train loss <loss>=0.7306856513023376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch [100]#011Speed: 801.39 samples/sec#011loss=0.730686\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch[105] avg_epoch_loss=0.804146\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=105 train loss <loss>=1.0270318031311034\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch [105]#011Speed: 1325.02 samples/sec#011loss=1.027032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch[110] avg_epoch_loss=0.974631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=110 train loss <loss>=4.588922107219696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch [110]#011Speed: 842.03 samples/sec#011loss=4.588922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch[115] avg_epoch_loss=0.971713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=115 train loss <loss>=0.9069395780563354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch [115]#011Speed: 1353.47 samples/sec#011loss=0.906940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch[120] avg_epoch_loss=0.974667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=120 train loss <loss>=1.0431975364685058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch [120]#011Speed: 846.16 samples/sec#011loss=1.043198\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch[125] avg_epoch_loss=0.980661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=125 train loss <loss>=1.1256993770599366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch [125]#011Speed: 1349.22 samples/sec#011loss=1.125699\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch[130] avg_epoch_loss=0.985614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=130 train loss <loss>=1.1104493379592895\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch [130]#011Speed: 852.02 samples/sec#011loss=1.110449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[135] avg_epoch_loss=0.991657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=135 train loss <loss>=1.1499707221984863\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [135]#011Speed: 1256.92 samples/sec#011loss=1.149971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[140] avg_epoch_loss=0.993757\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=140 train loss <loss>=1.0508772373199462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [140]#011Speed: 859.03 samples/sec#011loss=1.050877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[145] avg_epoch_loss=0.995748\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=145 train loss <loss>=1.051908254623413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [145]#011Speed: 1373.11 samples/sec#011loss=1.051908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[150] avg_epoch_loss=0.995471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=150 train loss <loss>=0.9873626708984375\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [150]#011Speed: 867.14 samples/sec#011loss=0.987363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[155] avg_epoch_loss=0.993094\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=155 train loss <loss>=0.9213024020195008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [155]#011Speed: 1355.25 samples/sec#011loss=0.921302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[160] avg_epoch_loss=0.987505\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=160 train loss <loss>=0.8131529808044433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [160]#011Speed: 862.49 samples/sec#011loss=0.813153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[165] avg_epoch_loss=0.982722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=165 train loss <loss>=0.8287063956260681\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [165]#011Speed: 1252.71 samples/sec#011loss=0.828706\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch[170] avg_epoch_loss=0.978743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=170 train loss <loss>=0.8466454148292542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch [170]#011Speed: 810.54 samples/sec#011loss=0.846645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch[175] avg_epoch_loss=0.973624\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=175 train loss <loss>=0.7985457062721253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch [175]#011Speed: 1331.91 samples/sec#011loss=0.798546\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch[180] avg_epoch_loss=0.968886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=180 train loss <loss>=0.8021023988723754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch [180]#011Speed: 868.96 samples/sec#011loss=0.802102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch[185] avg_epoch_loss=0.965697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=185 train loss <loss>=0.8502631545066833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch [185]#011Speed: 1350.89 samples/sec#011loss=0.850263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch[190] avg_epoch_loss=0.966386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=190 train loss <loss>=0.9920286655426025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch [190]#011Speed: 857.43 samples/sec#011loss=0.992029\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch[195] avg_epoch_loss=0.968379\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=195 train loss <loss>=1.0445026874542236\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch [195]#011Speed: 1323.77 samples/sec#011loss=1.044503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch[200] avg_epoch_loss=0.965221\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=200 train loss <loss>=0.841429340839386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch [200]#011Speed: 788.81 samples/sec#011loss=0.841429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch[205] avg_epoch_loss=0.961395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=205 train loss <loss>=0.8075654745101929\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch [205]#011Speed: 1307.04 samples/sec#011loss=0.807565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch[210] avg_epoch_loss=0.957003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=210 train loss <loss>=0.7760762929916382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch [210]#011Speed: 833.32 samples/sec#011loss=0.776076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch[215] avg_epoch_loss=0.950958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=215 train loss <loss>=0.6958403587341309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch [215]#011Speed: 1349.53 samples/sec#011loss=0.695840\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch[220] avg_epoch_loss=0.946489\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=220 train loss <loss>=0.7534227252006531\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch [220]#011Speed: 823.06 samples/sec#011loss=0.753423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch[225] avg_epoch_loss=0.941408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=225 train loss <loss>=0.7168308973312378\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch [225]#011Speed: 1318.97 samples/sec#011loss=0.716831\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch[230] avg_epoch_loss=0.936953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=230 train loss <loss>=0.7356151580810547\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch [230]#011Speed: 801.05 samples/sec#011loss=0.735615\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch[235] avg_epoch_loss=0.932253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=235 train loss <loss>=0.7150833010673523\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch [235]#011Speed: 1363.13 samples/sec#011loss=0.715083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch[240] avg_epoch_loss=0.928176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=240 train loss <loss>=0.7357670545578003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch [240]#011Speed: 591.98 samples/sec#011loss=0.735767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch[245] avg_epoch_loss=0.925914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=245 train loss <loss>=0.81686030626297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch [245]#011Speed: 1343.78 samples/sec#011loss=0.816860\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch[250] avg_epoch_loss=0.923691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=250 train loss <loss>=0.8143435955047608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch [250]#011Speed: 836.43 samples/sec#011loss=0.814344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch[255] avg_epoch_loss=0.923330\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=255 train loss <loss>=0.9051887631416321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch [255]#011Speed: 1345.56 samples/sec#011loss=0.905189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[260] avg_epoch_loss=0.919957\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=260 train loss <loss>=0.7472473502159118\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [260]#011Speed: 800.24 samples/sec#011loss=0.747247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[265] avg_epoch_loss=0.956947\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=265 train loss <loss>=2.887860691547394\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [265]#011Speed: 1332.10 samples/sec#011loss=2.887861\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[270] avg_epoch_loss=0.955989\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=270 train loss <loss>=0.9049871087074279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [270]#011Speed: 836.34 samples/sec#011loss=0.904987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[275] avg_epoch_loss=0.957070\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=275 train loss <loss>=1.0156849384307862\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [275]#011Speed: 1367.14 samples/sec#011loss=1.015685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[280] avg_epoch_loss=0.957103\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=280 train loss <loss>=0.9589444041252136\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [280]#011Speed: 858.07 samples/sec#011loss=0.958944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[285] avg_epoch_loss=0.957128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=285 train loss <loss>=0.9585152983665466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [285]#011Speed: 1328.03 samples/sec#011loss=0.958515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[290] avg_epoch_loss=0.956180\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=290 train loss <loss>=0.9019253253936768\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [290]#011Speed: 866.48 samples/sec#011loss=0.901925\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch[295] avg_epoch_loss=0.954894\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=295 train loss <loss>=0.8800986886024476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch [295]#011Speed: 1223.44 samples/sec#011loss=0.880099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch[300] avg_epoch_loss=0.953315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=300 train loss <loss>=0.8598279833793641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch [300]#011Speed: 864.12 samples/sec#011loss=0.859828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch[305] avg_epoch_loss=0.952136\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=305 train loss <loss>=0.8811689972877502\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch [305]#011Speed: 1342.06 samples/sec#011loss=0.881169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch[310] avg_epoch_loss=0.949711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=310 train loss <loss>=0.8012611627578735\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch [310]#011Speed: 852.91 samples/sec#011loss=0.801261\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch[315] avg_epoch_loss=0.947276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=315 train loss <loss>=0.7958235740661621\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch [315]#011Speed: 1330.19 samples/sec#011loss=0.795824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch[320] avg_epoch_loss=0.945804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=320 train loss <loss>=0.8527618646621704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch [320]#011Speed: 603.44 samples/sec#011loss=0.852762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch[325] avg_epoch_loss=0.942903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=325 train loss <loss>=0.7567030191421509\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch [325]#011Speed: 791.33 samples/sec#011loss=0.756703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch[330] avg_epoch_loss=0.941951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=330 train loss <loss>=0.879830801486969\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch [330]#011Speed: 520.91 samples/sec#011loss=0.879831\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch[335] avg_epoch_loss=0.938632\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=335 train loss <loss>=0.7189457654953003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch [335]#011Speed: 1252.66 samples/sec#011loss=0.718946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch[340] avg_epoch_loss=0.935294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=340 train loss <loss>=0.7109753012657165\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch [340]#011Speed: 852.60 samples/sec#011loss=0.710975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch[345] avg_epoch_loss=0.934058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=345 train loss <loss>=0.8497937440872192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch [345]#011Speed: 1352.29 samples/sec#011loss=0.849794\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch[350] avg_epoch_loss=0.931952\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=350 train loss <loss>=0.78618243932724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch [350]#011Speed: 796.00 samples/sec#011loss=0.786182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch[355] avg_epoch_loss=0.929335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=355 train loss <loss>=0.7456162929534912\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch [355]#011Speed: 1356.94 samples/sec#011loss=0.745616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch[360] avg_epoch_loss=0.929612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=360 train loss <loss>=0.9493066191673278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch [360]#011Speed: 862.82 samples/sec#011loss=0.949307\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch[365] avg_epoch_loss=0.929500\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=365 train loss <loss>=0.9214834094047546\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch [365]#011Speed: 1342.67 samples/sec#011loss=0.921483\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch[370] avg_epoch_loss=0.927911\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=370 train loss <loss>=0.8115490436553955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch [370]#011Speed: 786.68 samples/sec#011loss=0.811549\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch[375] avg_epoch_loss=0.925677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=375 train loss <loss>=0.7599242448806762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch [375]#011Speed: 1340.69 samples/sec#011loss=0.759924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch[380] avg_epoch_loss=0.923186\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=380 train loss <loss>=0.7358621835708619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch [380]#011Speed: 859.42 samples/sec#011loss=0.735862\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch[385] avg_epoch_loss=0.921087\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=385 train loss <loss>=0.7611217975616456\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch [385]#011Speed: 1216.43 samples/sec#011loss=0.761122\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch[390] avg_epoch_loss=0.919304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=390 train loss <loss>=0.781670331954956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch [390]#011Speed: 720.59 samples/sec#011loss=0.781670\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch[395] avg_epoch_loss=0.918409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=395 train loss <loss>=0.8484103322029114\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch [395]#011Speed: 785.36 samples/sec#011loss=0.848410\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch[400] avg_epoch_loss=0.918871\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=400 train loss <loss>=0.9554536581039429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch [400]#011Speed: 825.64 samples/sec#011loss=0.955454\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch[405] avg_epoch_loss=0.917939\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=405 train loss <loss>=0.8432280898094178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch [405]#011Speed: 1349.74 samples/sec#011loss=0.843228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch[410] avg_epoch_loss=0.915897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=410 train loss <loss>=0.750092351436615\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch [410]#011Speed: 870.14 samples/sec#011loss=0.750092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch[415] avg_epoch_loss=0.915175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=415 train loss <loss>=0.855825936794281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch [415]#011Speed: 1244.49 samples/sec#011loss=0.855826\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch[420] avg_epoch_loss=0.919587\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=420 train loss <loss>=1.28666433095932\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch [420]#011Speed: 719.82 samples/sec#011loss=1.286664\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch[425] avg_epoch_loss=0.918443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=425 train loss <loss>=0.8220848321914673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch [425]#011Speed: 939.28 samples/sec#011loss=0.822085\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch[430] avg_epoch_loss=0.916839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=430 train loss <loss>=0.7802309989929199\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch [430]#011Speed: 625.67 samples/sec#011loss=0.780231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[435] avg_epoch_loss=0.914867\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=435 train loss <loss>=0.7448638439178467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [435]#011Speed: 1335.75 samples/sec#011loss=0.744864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[440] avg_epoch_loss=0.913262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=440 train loss <loss>=0.7732873678207397\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [440]#011Speed: 811.51 samples/sec#011loss=0.773287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[445] avg_epoch_loss=0.912532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=445 train loss <loss>=0.8481820464134217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [445]#011Speed: 1367.40 samples/sec#011loss=0.848182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[450] avg_epoch_loss=0.911409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=450 train loss <loss>=0.8112055778503418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [450]#011Speed: 854.09 samples/sec#011loss=0.811206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[455] avg_epoch_loss=0.911076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=455 train loss <loss>=0.8810053706169129\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [455]#011Speed: 1376.21 samples/sec#011loss=0.881005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[460] avg_epoch_loss=0.911093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=460 train loss <loss>=0.9126548647880555\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [460]#011Speed: 851.13 samples/sec#011loss=0.912655\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[465] avg_epoch_loss=0.923333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=465 train loss <loss>=2.051843762397766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [465]#011Speed: 1330.67 samples/sec#011loss=2.051844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch[470] avg_epoch_loss=0.928517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=470 train loss <loss>=1.4117080211639403\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch [470]#011Speed: 856.67 samples/sec#011loss=1.411708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch[475] avg_epoch_loss=0.928354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=475 train loss <loss>=0.913043475151062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch [475]#011Speed: 1212.97 samples/sec#011loss=0.913043\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch[480] avg_epoch_loss=0.928952\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=480 train loss <loss>=0.9858282089233399\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch [480]#011Speed: 863.01 samples/sec#011loss=0.985828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch[485] avg_epoch_loss=0.928847\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=485 train loss <loss>=0.9187973618507386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch [485]#011Speed: 1298.84 samples/sec#011loss=0.918797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch[490] avg_epoch_loss=0.929057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=490 train loss <loss>=0.9494709372520447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch [490]#011Speed: 869.92 samples/sec#011loss=0.949471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch[495] avg_epoch_loss=0.928295\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=495 train loss <loss>=0.8533778309822082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch [495]#011Speed: 1350.86 samples/sec#011loss=0.853378\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[500] avg_epoch_loss=0.926550\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=500 train loss <loss>=0.7535178303718567\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch [500]#011Speed: 853.67 samples/sec#011loss=0.753518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[505] avg_epoch_loss=0.926959\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=505 train loss <loss>=0.9679010272026062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch [505]#011Speed: 1341.95 samples/sec#011loss=0.967901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[510] avg_epoch_loss=0.926905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=510 train loss <loss>=0.9214678525924682\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch [510]#011Speed: 819.00 samples/sec#011loss=0.921468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[515] avg_epoch_loss=0.924923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=515 train loss <loss>=0.7223652362823486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch [515]#011Speed: 1341.47 samples/sec#011loss=0.722365\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[520] avg_epoch_loss=0.924296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=520 train loss <loss>=0.8595388650894165\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch [520]#011Speed: 854.11 samples/sec#011loss=0.859539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[525] avg_epoch_loss=0.922812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=525 train loss <loss>=0.7682390332221984\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch [525]#011Speed: 1289.35 samples/sec#011loss=0.768239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[530] avg_epoch_loss=0.921315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=530 train loss <loss>=0.7637622475624084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch [530]#011Speed: 859.93 samples/sec#011loss=0.763762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch[535] avg_epoch_loss=0.920352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=535 train loss <loss>=0.8180817246437073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch [535]#011Speed: 1344.64 samples/sec#011loss=0.818082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch[540] avg_epoch_loss=0.921054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=540 train loss <loss>=0.9963193297386169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch [540]#011Speed: 786.00 samples/sec#011loss=0.996319\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch[545] avg_epoch_loss=0.919757\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=545 train loss <loss>=0.7794240117073059\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch [545]#011Speed: 1329.21 samples/sec#011loss=0.779424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] processed a total of 17583 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717578.663244, \"EndTime\": 1620717596.540914, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17876.915216445923, \"count\": 1, \"min\": 17876.915216445923, \"max\": 17876.915216445923}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=983.5497964009055 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, train loss <loss>=0.9192445795102553\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Final loss: 0.9012727438860687 (occurred at epoch 17)\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #quality_metric: host=algo-1, train final_loss <loss>=0.9012727438860687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 WARNING 140281140962944] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717596.5410306, \"EndTime\": 1620717596.5870986, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 44.99530792236328, \"count\": 1, \"min\": 44.99530792236328, \"max\": 44.99530792236328}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717596.587164, \"EndTime\": 1620717596.6189008, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 76.81393623352051, \"count\": 1, \"min\": 76.81393623352051, \"max\": 76.81393623352051}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717596.618993, \"EndTime\": 1620717596.6266437, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 7.579803466796875, \"count\": 1, \"min\": 7.579803466796875, \"max\": 7.579803466796875}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #memory_usage::<batchbuffer> = 0.2696990966796875 mb\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717596.6267598, \"EndTime\": 1620717596.6281588, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.042438507080078125, \"count\": 1, \"min\": 0.042438507080078125, \"max\": 0.042438507080078125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:59 INFO 140281140962944] Number of test batches scored: 10\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:02 INFO 140281140962944] Number of test batches scored: 20\u001b[0m\n",
      "\n",
      "2021-05-11 07:20:12 Uploading - Uploading generated training model\u001b[34m[05/11/2021 07:20:05 INFO 140281140962944] Number of test batches scored: 30\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.6/site-packages/numpy/ma/core.py:2788: UserWarning: Warning: converting a masked element to nan.\n",
      "  order=order, subok=True, ndmin=ndmin)\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717596.6282518, \"EndTime\": 1620717609.1200118, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 12491.92190170288, \"count\": 1, \"min\": 12491.92190170288, \"max\": 12491.92190170288}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, RMSE): 5.606467203227409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, mean_absolute_QuantileLoss): 21565.82130957709\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, mean_wQuantileLoss): 0.05954234706241449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.1]): 0.019259129169366153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.2]): 0.03471119688808139\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.3]): 0.04786356457841295\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.4]): 0.05903509831839482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.5]): 0.06817136183152951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.6]): 0.07519472586363227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.7]): 0.0794489183705086\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.8]): 0.07969780930169601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.9]): 0.07249931924010877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #quality_metric: host=algo-1, test RMSE <loss>=5.606467203227409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.05954234706241449\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717609.120082, \"EndTime\": 1620717609.1274393, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 7.159948348999023, \"count\": 1, \"min\": 7.159948348999023, \"max\": 7.159948348999023}, \"totaltime\": {\"sum\": 382374.2399215698, \"count\": 1, \"min\": 382374.2399215698, \"max\": 382374.2399215698}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-05-11 07:20:29 Completed - Training job completed\n",
      "Training seconds: 461\n",
      "Billable seconds: 461\n"
     ]
    }
   ],
   "source": [
    "dar_estimator.fit(inputs=dar_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mt-battery-deepar-2021-05-11-07-10-08-643'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_job_name = dar_estimator.latest_training_job.name\n",
    "dar_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_instance_type=\"ml.m5.large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mt-battery-deepar-2021-05-11-07-10-08-643'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_endpoint_name = sagemaker_session.endpoint_from_job(\n",
    "    job_name=dar_job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=infer_instance_type,\n",
    "    image_uri=dar_image_name,\n",
    "    role=role\n",
    ")\n",
    "dar_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances.append(train_tss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = {\n",
    "    \"instances\": instances,\n",
    "    \"configuration\": {\n",
    "         \"output_types\": [\"mean\", \"quantiles\"],\n",
    "         \"quantiles\": [\"0.1\",\"0.5\", \"0.9\",\"0.99\",\"0.999\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"instances\": [\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        1\n",
      "      ],\n",
      "      \"target\": [\n",
      "        76.0,\n",
      "        75.0,\n",
      "        75.0,\n",
      "        74.0,\n",
      "        74.0,\n",
      "        75.0,\n",
      "        75.0,\n",
      "        75.0,\n",
      "        73.0,\n",
      "        72.0,\n",
      "        71.0,\n",
      "        71.0,\n",
      "        70.0,\n",
      "        69.0,\n",
      "        69.0,\n",
      "        68.0,\n",
      "        68.0,\n",
      "        67.0,\n",
      "        66.0,\n",
      "        66.0,\n",
      "        65.0,\n",
      "        65.0,\n",
      "        64.0,\n",
      "        64.0,\n",
      "        63.0,\n",
      "        64.0,\n",
      "        65.0,\n",
      "        69.0\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"configuration\": {\n",
      "    \"output_types\": [\n",
      "      \"mean\",\n",
      "      \"quantiles\"\n",
      "    ],\n",
      "    \"quantiles\": [\n",
      "      \"0.1\",\n",
      "      \"0.5\",\n",
      "      \"0.9\",\n",
      "      \"0.99\",\n",
      "      \"0.999\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "inference_json = json.dumps(inference, indent=2)\n",
    "print(inference_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.predictor.Predictor at 0x7ff8f89525f8>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "\n",
    "\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    dar_endpoint_name, \n",
    "    sagemaker_session=sagemaker_session, \n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer())\n",
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'mean': [71.1284637451,\n",
       "    72.3249282837,\n",
       "    73.0628433228,\n",
       "    72.9008026123],\n",
       "   'quantiles': {'0.1': [68.7886962891,\n",
       "     69.7614974976,\n",
       "     70.4834442139,\n",
       "     70.0815658569],\n",
       "    '0.5': [71.0411529541, 72.1847610474, 73.2421646118, 72.8921966553],\n",
       "    '0.9': [73.9268264771, 75.0553207397, 75.9048233032, 75.8751602173],\n",
       "    '0.99': [76.6286773682, 77.4080276489, 77.9496307373, 80.5334777832],\n",
       "    '0.999': [76.6286773682, 77.4080276489, 77.9496307373, 80.5334777832]}}]}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mean': [71.1284637451, 72.3249282837, 73.0628433228, 72.9008026123],\n",
       "  'quantiles': {'0.1': [68.7886962891,\n",
       "    69.7614974976,\n",
       "    70.4834442139,\n",
       "    70.0815658569],\n",
       "   '0.5': [71.0411529541, 72.1847610474, 73.2421646118, 72.8921966553],\n",
       "   '0.9': [73.9268264771, 75.0553207397, 75.9048233032, 75.8751602173],\n",
       "   '0.99': [76.6286773682, 77.4080276489, 77.9496307373, 80.5334777832],\n",
       "   '0.999': [76.6286773682, 77.4080276489, 77.9496307373, 80.5334777832]}}]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = prediction[\"predictions\"]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': [71.1284637451, 72.3249282837, 73.0628433228, 72.9008026123],\n",
       " 'quantiles': {'0.1': [68.7886962891,\n",
       "   69.7614974976,\n",
       "   70.4834442139,\n",
       "   70.0815658569],\n",
       "  '0.5': [71.0411529541, 72.1847610474, 73.2421646118, 72.8921966553],\n",
       "  '0.9': [73.9268264771, 75.0553207397, 75.9048233032, 75.8751602173],\n",
       "  '0.99': [76.6286773682, 77.4080276489, 77.9496307373, 80.5334777832],\n",
       "  '0.999': [76.6286773682, 77.4080276489, 77.9496307373, 80.5334777832]}}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred0 = predictions[0]\n",
    "pred0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean = pred0[\"mean\"]\n",
    "quantiles = pred0[\"quantiles\"]\n",
    "q01 = quantiles[\"0.1\"]\n",
    "q90 = quantiles[\"0.9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([76., 75., 75., 75.])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = sample_test[\"battery\"][0:4].values\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff8f8175cf8>]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAD4CAYAAAC9vqK+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABHVUlEQVR4nO3deVzU1734/9eZYQcZFGQTdFxAxRVXXKLgloVEk2YzbVabmL1m6b0lXae/3vZy+22SJk2a1CxN06ZN2iZtFpImJoJmURPjvkRURFEExGWURWU5vz8+Aw7IMizDDMP7mQcPZj7r+zCGN2f5nKO01gghhBDeyuTpAIQQQoi2SKISQgjh1SRRCSGE8GqSqIQQQng1SVRCCCG8mp+nA+hOJpNJBwcHd+rc+vp6TCbfyNu+UhZfKQdIWbyRr5QDulaWqqoqrbX26h+ETyWq4OBgKisrO3VuXl4e6enp3RuQh/hKWXylHCBl8Ua+Ug7oWlmUUtXdG0338+osKoQQQkiiEkII4dUkUQkhhGiVUmqkUmqL09dppdRDjn0PKqW+UUrtVEr92l0x+FQflRBCiO6ltd4DTARQSpmBI8C/lFIZwBJggtb6nFIq2l0xSI1KCCGEq+YD+7XWB4F7gWyt9TkArXWZu27qtkTV1eqiUuoypdQepdQ+pVSWu+IUQgjhsqXA3xyvk4FLlFIblFJrlFJT3XVTtzX9daW66Dj+WWAhcBj4Sin1jtZ6l7viFUKIPspPKbXR6f1KrfXK5gcppQKAxcBjDecBA4A0YCrwd6XUMO2GJTl6qo+qsbqolPp/tF9dnAbs01oXACilXsdIbt2eqM7W1PHqukL0iTrSu/viQviI6tpqdpTvYNuxbXxz6ht2b9mNUgqTMl34wtRkm8LptVKYuPDarMwXbWvvGq5ct2G/WZnbva691k55dTkmZXIpHoVCKeXpj8IdarXWU1w47nJgk9a61PH+MPCWIzF9qZSqB6KAY90dYE8lqpaqi78EzgLf11p/1ez4QUCR0/vDwPSWLqyUWg4sB/Dz8yMvL69DgZ2v0zy3tpr+gfUk5+b6xD/EioqKDv8cvJGvlAN6X1lO152m4FwBBWcLKDhXQNH5Iuqpv3DAVs/F1q3+3rHDleO/hgTW5D/ltM/pfWvHNya/ds5v6XoN7xv2BdQHQJ5bfkLObuLC73GAfwMZQK5SKhkIAMrdcWO3Jyp3VxcdVdSVAKGhobozT2eXhR7kx//egWnQWOYmD+xMGF7FV56495VygHeXRWvNgdMH2Fy6mU1lm9hStoVDZw4BEGAKYGzUWBZEL2BSzCQmDJzApi82MTd9LvW6Hq019dQ3vq7TdS1ur9f1aIzvzfc7fzUc03BOPU6vnfbX6bp2r9v8Gs7n1FPPnj17GJE0wqXY2rpu89haKo8rP5PGL6frtnffhp/32aqzbv33pZQKxeiKudtp88vAy0qpHcB54DZ3NPtBz9SoOlNdPAIkOr1PcGxzixumJPLbD3fy+Ed7mJMU5RO1KiFac77uPLuO72JT2SY2l21mS9kWTp07BUBEYASp0alcl3wdqdGppESmEGAOaHK+cxNab5ZXnEf6qHRPh9Et3F1b11pXApHNtp0HbnbrjR16IlF1prr4FZCklBqKkaCWAt92V4ABfiaWDPfnpR12Pt5dxsKUGHfdSogeZz9nZ0vZlsba0o7yHZyvPw/AkPAhzE2Yy6SYSaRGp2INt8ofasLruDVRdaS6qJSKB17UWl+hta5VSj0AfAiYgZe11jvdGevMeD9Wl/jz+Ed7mD8qGpNJ/mcVvY/WmsMVh9lctplNpUZi2m/fD4Cf8iMlMoWlo5YyKXoSE6InEBUc5eGIhWifWxNVR6qLWuti4Aqn9+8D77szPmdmk+KhBUmseH0LH+woIXN8XE/dWohOq62vZc+JPY3NeJvLNlNebTRQ9PPvx4ToCVwx7ApSo1MZGzWWYL/OLYMjhCfJFEpOrhwfzzOr9/Hkx/lcNjYWs9SqhJepOF/BtmPbGpvxtpVvo7rWWKUhPjSeabHTmBQ9iYnRExkRMQKzyezhiIXoOklUTswmxcMLk7nvtU28s/UI16QmeDok0ceVVJY01pQ2l20m/2Q+9boekzIxsv9Irh5xdWNiig2N9XS4QriFJKpmLhsTS0pcOE99vJcrx8fjb+7dI5tE71FXX8e+U/uaJKajlUcBCPYLZnzUeJaPX05qdCrjo8YTFhDm4YiF6BmSqJoxmRSPLEzmzlc38tamw9w4dbCnQxI+qmG2h81lxvNLW8u2UlFTAcDA4IFMjJ7IrSm3khqdSvKAZPxN/h6OWAjPkETVgvmjo5mQGMHTn+zjmtQEAvykViW6rry6nC1lWxprS7uP76ZW1wIwImIElw29rLEZLyEsQYaJC+EgiaoFSikeXZjMrS9/yRsbi7glbYinQxK9TMNsD1vKtrCpdBNfHPmCY383nmlvmO3htjG3kRqdysToiVgCLR6OWAjvJYmqFZckRTHV2p9nVu/l+skJBPnL6CnRuobZHpyb8U6eOwkYsz0k+idyy4RbWp3tQQjROklUrVBK8eiikSxduZ7XNhziu7OHejok4UUaZntoaMZrPtvDnIQ5TIoxmvGGhg9lzZo1pI9N92zQQvRSkqjakDYsklkjInkubx83TUskJEB+XH1Rw2wPztMQ7Tu1DzBmexgdOZqlo5Y2NuPJbA9CdC/5zduORxaO5NrnvuBPXxzk3vThng5H9ICG2R4amvG2lG3hWLXRvxTmH8aE6AlcPvRyme1BiB4iiaodk4f0J2PkQP6wdj83pw2mX5AMEfY1lTWVbD221WjGK93cZLaHuNA4psZOldkehPAgSVQueGThSK565jNe/qyQFQuSPB2O6KKSypImzXh7Tu5pnO0huX8yV4+4mtToVFKjU2W2ByG8gCQqF4xLsHDpmBhe/LSA22YOISJERmz1FvW63pjtwWlRwOLKYqDZbA8DUxk/UGZ7EMIbSaJy0cMLk/lo16e88GkB/3XpKE+HI1rhPNvD5rLNbC3bypmaMwBEBUeRGp3KLSm3yGwPQvQikqhcNCo2nMxxcfzx80KWzRpKZFigp0MSwPHq402a8XYd39U428Nwy3AuHXppYzOezPYgRO8kiaoDHlqQzPvbj/KHtQX88IrRng6nz9FaU3i6sMmkrQdPHwRktgchfJkkqg4YER3G1amD+NMXhdw5eyjR4UGeDsmn1eiaJg/Vbinb0mS2h4nRE7k26VqZ7UEIN1JKjQTecNo0DPgpEAHcBRxzbP+hY8HbbieJqoNWzE/inS3F/D5vP7bFYzwdjs8pqyojryiP1UWr+bL4S2oO1QAwuN9g5iTMMZrxYlIZGj5UmvGE6AFa6z3ARACllBk4AvwLuAN4Umv9G3fHIImqg4ZEhnL9lAT+uuEQd80ZxqAIedizK7TW7Du1j9yiXHIP5bLj+A4AEvslMitsFksmL5HZHoTwHvOB/Vrrgz35h6Ikqk54YF4Sb359hGdW7+N/vzXO0+H0OrX1tWwu29yYnA5XHAZgXNQ4vpf6PTISMxgeMdyYH29IumeDFcL3+SmlNjq9X6m1XtnKsUuBvzm9f0ApdSuwEXhUa33SLQG646K+blBEMDdNS+S1DYe4d+5wBkeGeDokr1dVU8W64nWsLlrN2sNrOXXuFP4mf6bHTeeOsXeQnphOdEi0p8MUoi+q1VpPae8gpVQAsBh4zLHpOeAXgHZ8fxxY5o4AJVF10v0ZI3j9qyKe+mQvj98wwdPheKXy6nLWFK0htyiX9UfXc67uHOEB4cxJmENGYgazBs0i1D/U02EKIVxzObBJa10K0PAdQCn1AvCeu24siaqTosODuHXGEF767AD3ZQxn+ECZ0QCgwF5A7qFccoty2XZsGxpNfGg81yVfx7zEeaTGpMpDtkL0Tjfh1OynlIrTWh91vL0G2OGuG0ui6oJ75g7ntQ2HeOrjvTx9U6qnw/GIuvo6tpdvZ3XRanIP5VJ4uhCA0QNGc+/Ee5mXOI/k/skyQk+IXkwpFQosBO522vxrpdREjKa/wmb7upUkqi6IDAvk9plWnluzn/szRjAytp+nQ+oRZ2vPsv7oenKLcskryuPE2RP4KT+mxk7l26O/TUZihkzmKoQP0VpXApHNtt3SU/eXRNVFy+cM48/rDvLkqnyev2Wyp8Nxm5NnT7Lm8BpyD+Wy7ug6qmurCfMPY/ag2WQkZjA7YTbhAeGeDlMI4YMkUXVRREgA371kKL/9eC87jtgZO8h3pu0pOl3E6qLVrD60mi3HtlCv64kJiWHx8MXMS5zH1Nip+Julv0kI4V6SqLrBstlDeeWLQp5Ylc/Lt0/1dDidVq/r2Vm+03i+qSi3cbn15P7J3DXuLjIGZ5AyIEX6m4QQPUoSVTcID/Jn+Zxh/Po/e9h06CSTBvf3dEguO193ng1HNzT2Nx2rPoZZmZkUM4kfTP0B6YnpJPRL8HSYQog+TBJVN7lthpWXPj3AEx/l85c7p3s6nDbZz9n59MinrD60ms+PfE5VbRXBfsGN/U1zEubIzONCCK8hiaqbhAb6cW/6cP4nZzfrC46TNiyy/ZN6UHFFceOURRtLN1Kn64gKjuKKYVeQkZjB9LjpBJpljS0hhPdxW6Lq6tTwSqmHgTsxxuhvB+7QWp91V7zd4ea0IbzwaQFPfJTPG3enebQvR2vN7hO7G5PTnpN7AGMxwTvG3kFGYgZjo8ZiUiaPxSiEEK5wW6LqytTwSqlBwPeAFK11tVLq7xiTIb7irni7Q5C/mQcyRvCTt3fy2b5yLkka2KP3r6mvYWPJRv5x4h/88s1fUlJZgkmZmDhwIo9OfpSMwRkMCR/SozEJIURX9VTTX2emhvcDgpVSNUAIUOyu4LrTDVMTeX5NAY9/lM/sEVFur1VVnK/gsyOfsbpoNZ8d/owzNWfwV/7MTpjNfRPuY27iXAYEDXBrDEII4U5Ka+3+myj1MsZkhs8opWzA7cBp2pgaXim1AvglUA18pLX+TivXXg4sB/Dz85u8atWqTsVYUVFBWFj3zNe3pqiGP+48z0OTApkY3f1/C5ysPcn26u1sr9rO3rN7qaOOMFMYY4PHMj5kPIPqBjGgX+9PTt35mXialMX7+Eo5oGtlycjIqNJae/Xs0G5PVI6p4YuBMVrrUqVUDFDOhanh47TWy5qd0x94E7gROAX8A/in1vovbd0rNDRUV1ZWdirOvLw80tPTO3VuczV19Sx4Yg1hgX68+8BsTKau1aq01uw9tZfcQ7msLlrNruO7ABgSPoR5ifPIGJzB+KjxmE1moHvL4km+Ug6QsngjXykHdK0sSimvT1Q90fTXmanhFwAHtNbHHMe9BcwE2kxU3sLfbGLF/CQe+ftWPtxZwuXj4jp8jYbFBVcfWk1uUS5HKo6gUIwbOI4Vk1YwL3EeQy2yHLsQwvf1RKLqzNTwh4A0pVQIRtPffIxmwl5jycRBPJu7jyc/zmfRmFjMLtSqqmqq+Lz4c3IP5bL2yFrs5+wEmAJIi0/jznF3kp6YLkuyCyH6HLcmqo5MDa+Uigde1FpfobXeoJT6J7AJqAU2A60tjeyVzCbFwwuTeeCvm3lvWzFLJg5q8bjy6nLyivJYfWg1G45u4Hz9eSyBFuYmzCUjMYOZ8TMJ8ZcVhIUQfZdbE1VHpobXWhcDVzi9/xnwM3fG525XjI1jVOw+fvvxXjLHxeFnNqG15oD9gLF+U1Eu249tR6MZFDaIG0bewLzB80iNTsXPJM9iCyEEyMwUbmUyKR5ZmMzyP3/FU599BKHGhK8HTx8EYEzkGO6feD8ZgzNIikiS/iYhhGiBJCo3qa6tZn3xej49uRrLyI95pbACP5Mf02Onc8voW5ibOFcWFxRCCBdIoupGJ86eYE3RGnKLcllXvI6zdWfp59+P1IHT+WxrDD/MuJplM0d7OkwhhOhVJFF10cHTB8k9ZKzf1LC4YGxoLNckXUNGYgZTYqfgp/y4rmgdL6wp5ttTkwnyN3s6bCGE6DUkUXVQva5nR/kOcotyWX1oNQX2AgBGDRjF3ePvJiMxg1EDRl3U3/TowmS+/eIG/vblIe6YNdQToQshRIe1NsG41vq3jv2PAr8BBmqty90RgyQqF5yrO9e4uOCaojWNiwtOiZnCDSNvICMxg/iw+DavMXNEFDOGRfJs7n6WTh1McIDUqoQQ3q+NCcZRSiUCizCefXUbSVStsJ+zs/bwWnKLchsXFwzxCzEWFxycwSWDLunw4oKPLkrmuufX8eq6Qu6eO9xNkQshhNs0TjDueP8k8N/A2+68qSQqJ0cqjjT2N31d+jV1uo7o4GiuHHYlGYMzmBY7jQBzQKevP8U6gDnJA3l+zX6+kzaEsED58QshPM5PKeU8889KrXVrEywsxTHTkFJqCXBEa73V3Y/W9PnflGdrz/Li9hd5t/hdit80VhIZETGCZWOXMW/wPFIiU7p1ccFHFyaz5NnPeeXzAzwwL6nbriuEEJ1Uq7We0t5BjgnGFwOPOaa3+yFGs5/b9flEFWAO4J397xBqCuX7U77PvMR5JIYnuu1+ExIjWDA6hpVrC7hlhhVLsL/b7iWEEN2ocYJxpdQ4YCjQUJtKADYppaZprUu6+8Z9fh1ykzLx7jXvsiJ2BbeNuc2tSarBIwuTOX22lpc+LXD7vYQQops0TjCutd6utY7WWlu11lbgMDDJHUkKJFEBEGgO7NH7pcSHkzkujpc/L+RE5fkevbcQQnSU0wTjb3XqAjbL49gsYzp7f0lUHvLQgiQqz9fyh7X7PR2KEEK0SWtdqbWO1FrbW9lvbecZqt3ASmyWDdgs92CzdGjItCQqD0mK6cfVEwfxpy8KKTtz1tPhCCGE+9jsL2KzzwJuBazANmyWv2KzZLhyuiQqD1oxP4maOs1zeVKrEkL4OJvFDIxyfJUDW4FHsFleb+/UPj/qz5OsUaFcO2kQr204xPI5w4izBHs6JCGE6H42y5PAlcBq4FfY7F869vwfNsue9k6XGpWHPTgvCa01z+bu83QoQgjR/WwWBZwAJmKz3+2UpBpMa+8Skqg8LHFACDdOTeSNr4ooOlHl6XCEEKJ72ewauAGbvbKV/S0O0HAmicoLPJBhrO77u9V7PR2KEEK4wyZslqmdPbndRGXNyons7MWFa2ItQdw8fQhvbjrCgfKW/+gQQohebDqwDptlPzbLNmyW7dgs21w92ZXBFOutWTlbgD8CHxRmZ+pOBiracG/6cP725SGe+jif3y5N9XQ4QgjRnS7tysmuNP0lAyuBW4C91qycX1mzcpK7clNxsYH9ArltppW3txazt/SMp8MRQojuY7MfBBKBeY7XVXSg66ndAwuzM3VhduaqwuzMm4C7gNuAL61ZOWusWTkzOhm2aMHdc4YRGuDHkx/nezoUIYToPjbLz4AfAI85tvgDf3H19Hab/hx9VDdj1KhKgQeBdzBWfPwHxgy6ohv0Dw1g2eyhPP3JXnYW2xkT37GFGYUQwktdA6QCmwCw2YuxWfq5erIrVa91QDhwdWF2ZmZhduZbhdmZtYXZmRuB5zsRsGjDd2cPJTzIjydXSa1KCOEzzjuGqRtjHGyW0I6c3GaNypqVYwbeLczO/EVL+wuzM/+vIzcT7bME+7N8zjB+81E+W4pOMTExwtMhCSFEV/0dm+UPQAQ2y13AMuBFV09us0ZVmJ1ZB8zsWnyio26fNZQBoQE8IbUqIYQvsNl/A/wTeBMYCfwUm/1pV093ZXj6FmtWzjsY/VGND/kUZmd2bl0S0a6wQD/umTuMX73/DV8VnmCqdYCnQxJCiM6zWf4Pm/0HwKoWtrXLlT6qIOA4MA+4yvF1ZccjFR1xS5qVgf0C+c2He9BaHl0TQvRqC1vYdrmrJ7dboyrMzryjQ+GIbhEcYOb+9OHY3t3FF/uPM2tElKdDEkKIjrFZ7gXuA4Y3m4miH/CFq5dxZQqlZGtWzifWrJwdjvfjrVk5P27vPKXUSKXUFqev00qph5RSNqXUEaftV7RyfoRS6p9KqW+UUruVUn3uma2l0wYTZwni8Y+kViWE6JX+itEK9zYXWuSuAiZjs3/H1Yu40vT3AsZDWjUAhdmZ24Cl7Z2ktd6jtZ6otZ4ITMZ4Evlfjt1PNuzTWr/fyiWeAv6jtR4FTMBYyrhPCfI38+C8JDYdOkVe/jFPhyOEEB1js9ux2QuBWmz2g05fJ7BZ/uzqZVwZTBFSmJ35pTUrx3lbbQfDnQ/s11ofVEq1e7BSygLMAW4H0FqfB8538J4+4fopCTy3Zh9PfJRPevJAXPn5CdGttIaThVC8GUq2M+xgIagvISAU/EOM72299gsGkyzU0FsppUYCbzhtGgb8FIgElgD1QBlwu9a6uJXLjGnyzmbxw6jAuBZDe01K1qycD4AHgH8UZmdOsmblXAd8tzA70+WOMKXUy8AmrfUzSikbRgI6DWwEHtVan2x2/ESM+QV3YdSmvgZWaK0vmlpcKbUcWA7g5+c3edWqVc0PcUlFRQVhYWGdOtfdPjtSw4vbz/NgaiCTY9r/28Kby9IRvlIO6EVl0Zqgs2WEVeyn35l9jq/9+NdWAFCvzGgUZt2xv1XrTEHUmQOpMwc1ftWbAqkzB1+03djXcHzT/c23a5N/p4vaaz4TF3SlLBkZGVVaa5cewFVKmYEjGLOhn9Ran3Zs/x6QorW+p8kJNstjwA+BYIxWNQCFUfFYic3+GC5wJVENw0gaM4GTwAHgO4XZmQddLFgAUAyM0VqXKqVigHKMJ5R/AcRprZc1O2cKsB6YpbXeoJR6Cjittf5JW/cKDQ3VlZWdWyYjLy+P9PT0Tp3rbrV19Sx6ci3+ZhMfrLgEk6ntWpU3l6UjfKUc4KVl0RpOHzFqSsWboXiL8b36hLHf5A8xKRCfanzFTYToFPI++4L0S2bB+UqoqTK+t/Xa1eMaXtOB/liTn6MG56i9BYS49jogjB17Chg7aRoEhDlqgCEXXvuH9KpaYFf+fSmlOpKoFgE/01rParb9MWCw1vreFk+0Wf7X1aTUElea/nRhduYCa1ZOKGAqzM48Y83K6cj8fpdj1KZKARq+AyilXgDea+Gcw8BhrfUGx/t/AlkduKdP8TObWLEgiRWvbyFn+1GumhDv6ZBEb3T6qFNS2gxHt0Clo+9TmSE6BUZlXkhMMWPAL7Dla5n9ITjC+OpOWkNNtSNpVcD5qjZeNyRCR4KrcXpdVQ6nmm2vO9fkVmMBdrYRS0PCck5g7TVzOr9ubZ85ALyrCd9PKbXR6f1KrfXKVo5dCvyt4Y1S6pfArYAdyGj1Djb7Y9gs/YEkjEeeGravdSlAF455E5hUmJ3pXFX5J663L95E04LFaa2POt5eA+xofoLWukQpVaSUGqm13oPRx7XLxfv5pKvGx/P73P08+XE+l4+Nxc/ce/7aEx5wpvRCMmpITBWOvxGVCQaOhqRLIX7ihaTkH+zJiA1KORJDCIR28yMZdbVNktvGdWuZMn5Us6TnQs2w6oSRLGuqHImxgg7XAv0banYtJbMwRw3Q9dfm2uqu/GRqtdZT2jvI0Tq2mAszoKO1/hHwI0eN6gHgZy2ebLPcCawAEoAtQBrGPLLzXAmw1URlzcoZhdEBZrFm5XzLaVc4zhmxDUqpUIwHve522vxrRx+UBgob9iml4oEXtdYNw9UfBF5z/HAKgD79PJfJpHh4YRL3/GUTb28p5trJCZ4OSXiLimNOCcnx/UxDn7aCgSNh+LwLzXex44xfcn2N2Q/MFggyViWo6HcYhnTDDHFaQ+3ZC0mrzabN1mqJlY4EWNT0nGa1wNZM97fAgkNdL0vbmrSONfMa8D6tJSojSU0F1mOzZ2CzjAJ+5eqN26pRjcSYgSICY9x7gzMY61K1yzH4IbLZtltaObYYuMLp/Rag3Szfl1w6JpYx8eE89cleFk+Mx19qVX1P1YmmzXfFW+D0YcdOBVFJYJ19ofkudhwE+saAAa+llFEb9Q+G0Mj2j++IutoLiatJ0nNq9qyp5MDefYzs3ju3pHnrWJLWeq/j7RLgmzbOPYvNfhabBWyWQGz2b7BZXA651URVmJ35NvC2NStnTmF2ZpN2RGtWzqxWThNupJTi0UXJLHtlI29+fZil0wZ7OiThTtUnjUTk3Hx3yumv5gHDYXDahea72PEQFO6hYIVbmP3AHN7u53q0Ms+tiaqV1rFsx9D1euAgcE9L5zocxmaJAP4NrMJmOek4xyWu9FH9FpjUbNvvWtgmekDGyGgmJkbw9Cd7uWbSIAL9zJ4OSXSHs3Y4urVpTenkgQv7+1th0GSYeqfRfBc3ofsHMgjRilZax651+QI2+zUNr7BZcgEL8B9XT2+rj2oGxpD0gdasnEecdoUD8tvRQ5RSfH/RSG5+aQNvfFXErTOsng5JdNS5M3B0W9MmvBP7L+yPGGwko0m3OvqVJkCIzKAvfIDNEoKxCscubHaXJ3Foq0YVAIQ5jnFeMvg0cF1nYhTdY9aISKYNHcAzq/dxw5REgvzl7wavdb4Sjm4joegdeOuvRlIq30vjKLHwBKPpbuK3je9xqd3fzyGEp9gsi4GngRPAj4FngVLAis3yA2z2P7lymbb6qNYAa6xZOa+4+nCv6BlKKR5dmMyNK9fzl/UHufOSYZ4OSYDRsV26o2nzXfke0PWMAOgXZ9SQxl1/YQRe2EDPxiyEe/0CWITR1JcLjMdmL8BmiQY+AbqWqJxUWbNy/h/GUPXGYemF2ZkujX8X7jF9WCSXJEXxXN5+bpo2mNBAVz5K0W1qzjolpS3G92PfgK4z9odGw6BJkLIE4lP5orCKmZd+q81LCuGD6rHZjaXKbZYD2OwFxmt7GTaLy/NwufLb7TWMCQmvxBjVcRsgU3l7gUcWJnPN77/glS8KuT9jhKfD8V2156B0Z9MHaMt2Q73j/7OQKKOGNCrzwgi8fnFNZh84fzTPE5EL4Wkmx4wUJqDe8Vo17nORK4kqsjA78yVrVs4Kp+bArzoer+huqYP7M39UNCvXFnDLjCGEB3V+gk7hUHseju1uOtChdBfU1xj7gwcYyWjWogvNd5YEb5sSRwhvYcGYVLzhf5BNTvtcns7DlUTl+D+Uo9asnEyMCWZlCJKXeHhhMlf+7jNe+vQADy9M9nQ4vUtdjdFc19B0V7zZaM6rcwxGCrIYyWjG/RceoI0YLElJCFfZ7NbuuIwriep/rFk5FuBRjOenwoGHu+PmouvGDrJw2ZhYXv7sAHfMshIREuDpkLxTXS2U5zedkLVkuzH1DUBguDEMfPo9F5rv+g+VpCSEF2g3URVmZzbMbt727LjCYx5emMyHu0pYubaA/75slKfD8bz6Oji+r2nzXcl2YwoaMCb0jJtgPDzbUFPqP7RXLesgRF/S1gO/QcCNGGtQvQv8N3AJsB/4RWF2ZnmPRCjaNTK2H1eNj+ePnxeybHZHVmDxAfX1xsOyzqPvjm415kIDY3bpuAkw+XajPyk+FSJHSFISohdpq0b1Kkb/VChGs98O4BlgNvAKxihA4SUeWpDEe9uKeT5vP7N9dQ5SreFEgVPz3VYjOZ0/Y+z3CzLmu0u92VFTmghRyWCSB6KF8Aibpe3xDDb7CVcu01aiSinMzhxrzcrxAw4XZmfOdWz/jzUrZ6trUYqeMmxgGN+alMCf1x9kzOxWFrvrTbQmqLoUdv6raWI6azf2mwONmcEn3Hih+S5qpDGJpxDCW3yNMbpPAYMxWugUxqochwCXmoDa+r/6PEBhdmatNSunuNm+ug4GK3rAivlJ/HvzEd4rqOGa9g/3PlpD8SbY9Tbseoe0kwdgA8aS6LFjYey1F5rvokcbq8wKIbyXzW4kIpvlBeBf2OzvO95fDlzt6mXaSlQJ1qycpzGyX8NrHO8HdTxi4W6JA0K4YWoib3x5iMMnq0jo3wsWx6uvhyMbG5MT9kPGCqhD55IftYjkjJuMJdJbWxJdCNEbpGGzX1jH0Gb/AJvl166e3Fai+i+n1xub7Wv+XniJBzJG8PcvD/HM6n1kXzve0+G0rL4ODq2H3e8YyelMMZgDYFgGpGfByMshZADFeXkkx6d6OlohRNcVY7P8GPiL4/13MJ7JdUlbk9K6NFmg8C7xEcFkDPbjH18f5p65w7FGhXo6JENdLRz83Kg57X4XKsuMfqakhZDyc0i+tHGJcCGEz7kJY5n6f2H0Wa11bHOJ9Dz7oMxh/nxaXM/Tn+zliRsnei6Quho4sNZITt+8B1XHjeHiSQuNyVqTFkFgv/avI4To3YzRfSuwWUKx2Ss7erokKh8UEWji1hlWXvy0gPsyRjAiugfHq9eeg4I8R3LKgbOnjAdsky8zktOIBRDQC/rOhBDdx2aZCbyIscbhYGyWCcDd2Oz3uXK6JCofdfecYby2/iC//TifZ749yb03q6mG/auN5LTnAzh3GgItRl9TyhIYPg/8g9q/jhDCVz0JXAq8A4DNvhWbZY6rJ7c1M8XvaGN228LszO+5HqPoaZFhgdwxayjP5O7j/ozTjI4L794bnK+EvauM5LT3IzhfAcH9YfRiIzkNmysj9YTwAUqpkRhLPTUYBvwUY/T3VRiPMu0H7tBan2r1QjZ7EbYm/dAuP+bUVo1KRvb1cnddMow/rSvkyVX5rLx1StcveO4M5H/oSE6roLbaWItp3HVGcrJeIs82CeFjtNZ7gIkASikzcARjUMRI4DGtda1S6v+Ax4AftHKZIkfzn8Zm8QdWALtdjUFG/fkwS4g/d10yjCdW5bP9sJ1xCZ0YVVd9CvL/Ywwj3/cx1J2DsBhI/Y6RnAbPlNkghOg75gP7tdYHgYNO29cD17Vx3j3AUxi1sCPAR4BL/VPgQh+VNStnIEaWTEGWou917phl5eXPD/D4qj28csc0106qOgF73jdqTvtzjUUD+8XDlGVGckqcJvPnCeE7/JRSzi1oK7XWK1s5dinwtxa2L6Np82BzI7HZv9Nki80yC/jcpQBdOKZhKfpMZCn6XqdfkD/3zB1O9gff8PXBE0we0sockZXlxhDyXW8bQ8rra8EyGKbfDSlXw6DJMuO4EL6pVmvdbt+AUioAWIzRxOe8/UdALUauaM3vgOajulra1iJZir4PuHXGEF78tIDHP8rnr3elXdhxpsR4+HbX28bDuLreWJdp5oNGzSluoiwcKIRocDmwSWtd2rBBKXU7xkoa87XWFw++s1lmADOBgdgsjzjtCQdcbpaRpej7gJAAP+5NH8Ev3tvF19t2MLnqMyM5HVoHaGMpjEseNZJTzFhJTkKIltyEU7OfUuoyjHUK52qtq1o5JwDj2Sk/wPnp/tO03afVhCxF3xecPMit+h2mBf+FcW/lG9uix0D6Y0ZyipZVgYUQrVNKhQILgbudNj8DBAKrlPHH7Xqt9T1NTrTZ1wBrsFlewWY/SCfJUvS+6vh+x6Svb0PxZvyB+PBR/Pr4DaRfcyfTpkz3dIRCiF5Ca10JRDbbNqIDl3gRm+V6bPZTANgs/YHXsdkvdeVkV0b9/ZEWHvwtzM5c1oEgRU84lg+732byxtcg74CxbdBkWPBzSFlMv3Arb/8mj8/X1/DvyRolTXxCiJ4R1ZikAGz2k9gs0a6e7ErT33tOr4OAa3BhevY2nmaOAO7iwsjBH2qt32/lGmaMB4+PaK2vdCHWvkVrKNvtWMvpbThmPD9XHz4KLv0VjL4KIgY3Hh6Asbjif7+5jY93l7EwJcZDgQsh+ph6bJbB2OyHALBZhtDGzEfNudL096bze2tWzt+Az9o7r42nme8AntRa/8aF+BqeXu7m+X96Ma2hZPuF5HR8L6BgyEy4/Ncw+io2b8onfUZ6i6d/a9Igfp+3jydW5TN/VDQmk9SqhBBu9yPgM2yWNRiL714CLHf15M5MKZAEuFxlc2h8mtnV5ialVALGs1u/BB5p53Df1myJdk4eAGUypixKuxdGXQn9nGtH+a1eys9s4qEFyTz0xhb+s7OEK8bFuT9+IUTfZrP/B5tlEtDwfMxD2Ozlrp6uWhr67syalXOGplW0EuCx5jWtNm+i1MsY4++fUUrZgNsxhiduBB7VWp9s4Zx/Av+LMaTx+601/SmlluPIzH5+fpNXrVrlalhNVFRUEBbWg8thtEfXE346n4HHvmDgsXUEnSujXpk5FTGeYwNnUh41nZqAlqdEaq8s9Vrz48+rQcP/zA7G5KV9VV73mXSBlMX7+Eo5oGtlycjIqNJau2eFVZtlFDb7N44k1cJ++yZXLtNuouoqx9PMxcAYrXWpUioGKMdIfr8A4rTWy5qdcyVwhdb6PqVUOm0kKmehoaG6srLDa3IBkJeXR3p6eqfO7TatLdE+fJ4xK7ljifb2uFKW97cf5b7XNvHbGydydeqgbipA9/KKz6SbSFm8j6+UA7pWFqWUOxPVC9jsd2Gz5LawV2OzuzQVnyuj/j4pzM6c3962NjR5mrnZU80v0HSwRoNZwGKl1BUYAzjClVJ/0Vrf7OI9ew8PLdF+2ZhYRseF89uP87lyfBx+ZpkeSQjRzWz2uxzfu/RoU1vrUQUBIUCUNSunP0YHGBgDGzryJ3jzp5njtNZHHW+vAXY0P0Fr/RiO+aScalS+k6RaXaJ9EaQs7pEl2k0mxSMLk7nr1Y28tekIN0xNdOv9hBB9kM3yrbb3299y5TJt1ajuBh4C4oGvuZCoTmM8kdyuVp5m/rVSaiJG019hwz6lVDzwotb6Cleu3et44RLtC0ZHMyHBwlOf7OXq1EEE+EmtSgjRra5yfI/GmPNvteN9BvAF0LVEVZid+RTwlDUr58HC7MzfdSbCVp5mvqWVY4uBi5KU1joPyOvM/T3Oy5doV0rxyKKR3Pbyl7yxsYhb0oZ4LBYhhA+y2e8wvls+AlKw2Y863scBr7h6GVeGp9dbs3IiCrMzTwE4mgFvKszO/H3HIu4jWluiPWWxsVzG0LngF+DpKBvNSYpiypD+PLN6L9dPTiDIX9aZEkJ0u8TGJGUoBQa3dnBzriSquwqzM59teFOYnXnSmpVzFyCJqkEvXqJdKcWji0Zy0wvreW3DIb47e6inQxJC+J5PsFk+5MJ4hRuBj1092ZVEZbZm5ajC7EwNYM3KMWPMxtO3tbpE+82OJdpn9Jol2mcMj2Tm8Eiey9vHTdMSCQnoHXELIXoJm/0BbJZrgDmOLSux2f/l6umu/Eb6D/CGNSvnD473dzu29T0tLdEePsgnlmh/dFEy1z63jlfXHeSeucM9HY4QwvdsAs5gs3+MzRKCzdIPm/2MKye6kqh+gDHzw72O96uAFzoXZy/U0hLtEb63RPvkIQNIHzmQ59fs5zvTB9MvyDubKoUQvZDNchdGHhkADMd4xOl5jOn12uXKpLT1jgs+D2DNyrkEYwHF+zsXcS/Q0hLtA4b5/BLtjyxMZvEzn/PHzwv53vwkT4cjhPAd9wPTgA0A2Ox7u3uZD6xZOakYD+7eABzAxbHvvUng2XJY/3yfXqJ9fEIEi1JieOHTAm6bYcUSIrUqIUS3OIfNfh6bY5Ydm8WP7ljmw5qVk4yRnG7CmJvvDUAVZmf61iq/5yvh1auZcfhL430fX6L94YXJfPTUp7zwaQHfv3Skp8MRQviGNdgsPwSCsVkWAvcB77p6cls1qm+AT4ErC7Mz9wFYs3Ie7kqkXikgFPoPocA/mWGZD0FU327yGh0XzpXj4/jj5we4Y5aVyLBAT4ckhPCgNhbBPQLYgNHANK31xjYu8wPgTmA7xoC894EXXY2hrUT1LWApkGvNyvkP8DoXplHyLde+yKG8PIb18STV4KEFyby//Sh/WFvAD68Y7elwhBAe1MYiuCEYeeIPrZ4MYLOYgZ3Y7KPo5EC8VoerFWZn/rswO3MpMArIxZj3L9qalfOcNStnUWduJnqHEdFhXD1xEK+uK6TszFlPhyOE8B6Ni+BqrXc7kljbbPY6YA82i8szUTTnyqi/SuCvwF8d0yddj1GN+6izNxXeb8WCJN7eWszvc/djWzzG0+EIIdzHTynl3Gy3Umu9spVjl+K0GkYH9Ad2YrN8CVxYNNBmX+xSgB25U2F25klgpeNL+LAhkaFcPzmBv244xPI5w4iPCPZ0SEII96jVWk9p7yDHIriLcSzB1EE/6cQ5jWSuHNGqB+cn8damIzyTu49fXTPO0+EIITyrySK4LrFZgoB7gBEYAylewmav7eiNe/+UCsJtBkUEs3RaIn//qohDx6s8HY4QwrOaLILroj8BUzCS1OXA4525sSQq0ab7M0ZgNimeXr3X06EIITzEaRHct5y2XaOUOgzMAHKUUh+2cGoKNvvN2Ox/AK4DLunM/SVRiTbFhAdxS9oQ3tp0mIJjFZ4ORwjhAVrrSq11pNba7rTtX1rrBK11oNY6Rmt9aQun1jS+6kSTXwPpoxLtuid9OH/98hC//XgvT9+U6ulwhBC9xwRsltOO1wpjZorTjtcamz3clYtIohLtigoL5PaZVp5bs5/7M0YwMrafp0MSQvQGNnu3rHskTX/CJcvnDCMswI8nV+V7OhQhRB8jiUq4JCIkgGWzh/KfnSXsOGJv/wQhhOgmkqiEy757yVAswf5SqxJC9ChJVMJl4UH+LJ8zjE++KWPToZOeDkcI0UdIohIdcvtMK5GhAVKrEkL0GElUokNCA/24N304n+4tZ0PBcU+HI4ToA2R4uuiwm9OGsHJtAY+vyueN5Wko5ZvLlAk4VnWM3Sd2s/P4TnYf303+yXzqz9Xz+qrXiQmNISbE8RUaQ2xILDGhMYT5h8m/CdGtJFGJDgvyN/PAvBH89O2dfL7vOLOTojwdkugirTVlVWXsOr6LXSd2sfv4bnYd38Wx6mMAKBRWi5VxUeMoLi3Gfs7OnpN7OF59HI1ucq0Qv5AmSSw2NPai9+EB4ZLMhMskUYlOuXFqIs/n7ec3H+1h1ohI+aXTi2itKaksYdfxXUZN6YSRlE6cPQGASZkYZhlGWlwaKZEppESmMHLASEL9QwHIy8sjPT0dgJq6Go5VH6O0qpTSylJKq0opqSxpfL/u6DrKq8up1/VNYgj2C25SG2spqUUERsi/KwFIohKdFOhn5sH5STz21nZy95Qxb1SMp0MSLdBac7jicGMNafeJ3ew+vpuT54xRm2ZlZnjEcC4ZdEljUkrun0yIf4hL1/c3+xMfFk98WHyrx9TW11JeXd4kgZVWlTa+/rLkS45VHaNO1zU5L8AU0Ji0YkNjmyY1x/cBQQMwKelq93WSqESnXTc5gefy9vP4R/lkjIyWv349rF7XU3SmqDEpNTThnT5vTLXmZ/IjKSKJjMEZpAwwklJS/ySC/ILcGpefyY/Y0FhiQ2NbPaauvo7jZ4+3WCsrrSplc9lmSqtKqa1vOq+pv8mf6JDoi/rJGr43JDOzqVtm8hEe4rZEpZQaCbzhtGkY8FMgArgLOObY/kOt9fvNzk0EXgViAI2xNPJT7opVdI6/2cSK+Uk8+o+tfLizhMvGxnk6pD6jXtdTeLrwoppSRY0xw72/yZ/k/skssi5qrCklRSQRYA7wcOQtM5vMRIdEEx0SzThaXqSzXtdz4uwJSitLKakqaVIzK6ksYfux7Xxc9TE19TVNzvNTfgwMGXhRzay8spz+x/oTExLDwOCBksy8mNsSldZ6DzARQCllBo4A/wLuAJ7UWv+mjdNrgUe11puUUv2Ar5VSq7TWu9wVr+icq1MH8fu8fTyxKp+FKbGYTVKr6m519XUcsB9o7EvadXwX35z4hqpaYzHLQHMgI/uPJHNYZmNSGm4Zjr/Z38ORdy+TMhEVHEVUcBRjGNPiMVprTp472WrNbPeJ3eQW5XKu7hwAL7//MmA0gUYFR7XYXxYbYiS3qJAo/E2+9TPtLXqq6W8+sF9rfdCV5iGt9VHgqOP1GaXUbmAQIInKy5hNiocWJPPg3zbz3rZilkwc5OmQerXa+loK7AWNCWn38d3sObmH6tpqwBiEMLL/SJaMWNKYlIZahsovUAelFAOCBjAgaACjI0e3eIzWGvs5O++tfY/BKYMbk1nD970n9/LZkc8af+aN10YRFRx1cX9ZQ7NjaCzRwdE+9weCN1Ba6/aP6upNlHoZ2KS1fkYpZQNuB04DGzFqTq3Ox6OUsgJrgbFa69Mt7F8OLAfw8/ObvGrVqk7FWFFRQVhYWKfO9TY9XZZ6rfnp59XU1sMvZwd3W63K1z+TWl1LSU0JReeKOHT+EIfPH+ZIzRFqtNF0FagCSQhIIDEgsfErxj/G44MHfOVzaascWmuqdTWnak9xsu4kp2pPcaru1IXvjtdn9dmLzu1n6keEXwQR5ggi/CLob+7f+Lrhu7/q3mTWlc8kIyOjSmsd2q0BdTO3JyqlVABQDIzRWpcqpWKAcoy+p18AcVrrZa2cGwasAX6ptX6rpWOchYaG6srKyk7F6TzktrfzRFk+3FnC3X/+mv933Xiun5LYLdf0pc9kVe4q4sfHN6kp5Z/Mb+xPCfMPY3TkaEYPGE1KZAqjI0djDbd6PCm1xFc+l+4oR8X5iqZD8x19Z859aGfOn7novP6B/VsdyRgbGkt0SDTBfsE9UhallNcnqp5o+rscozZVCtDwHUAp9QLwXksnKaX8gTeB11xJUsKzFqXEMG6QhadX7+Xq1EH4m73vF2xPOVt7lvyT+cZAB8fIu/wT+dQdMoZf9wvoR0pkCjePvrkxKSX2S/TKpCTaFhYQRlhAGMMjhrd6TFVNVdPBH06DQI5WHmXzsc3Yz128dI4l0NLizB/O7119jKC364lEdRPwt4Y3Sqk4Rx8UwDXAjuYnKKMj6yVgt9b6iR6IUXSRUopHFiVzxx+/4h8bD/Pt6YM9HVKPqK6tZs+JPRdqSid2s//U/sZngiICI0iJTGFe+DwuS72M0ZGjSQhLkKH8fUiIfwjDLMMYZhnW6jHVtdWUVZW1Oghk5/GdjQ9kO+vn34+Y0BhCzoWQTrpb4m9jBPerju1WoBC4oa1unK5wa6JSSoUCC4G7nTb/Wik1EaPpr7Bhn1IqHnhRa30FMAu4BdiulNriOO+iYezCu6QnD2TS4Ah+t3ov35o0iCB/3xruW1VT1TgMvCEpFdgLGmddGBA0gJTIFOYmzGVM5BhGR44mLjQOpZTRNGNN92wBhNcK9gtmSPgQhoQPafWYc3XnKKssM2pnzjWzylLKz5W7LbY2RnBnAZ9orbOVUlmO9z9wRwxuTVRa60ogstm2W1o5thi4wvH6M0D+5OxllFI8umgk33lxA69/eYjbZw31dEiddub8Gb458U2TmlKhvbBxXruBwQNJiUxhwZAFpAwwmu9iQmKkpiTcJtAcSGJ4IonhF/cB5+Xl9VQYziO4l0BjNe5PQB69MVGJvmfm8EjShg3g2bz93Dh1MMEB3l+rsp+zX5SUDp4+2Lg/JiSGlMgULh96uVFTGjCagSEDPRixEN3KTym10en9Sq31ylaOXcqFrpwYp26cEowJGtwToLsuLPqmhlrV9c+v48/rC1k+p/VOZk84dfYUu07sajL67nDF4cb98aHxpESmsHj4YmOgw4DRRAZHtnFFIXq9Wq31lPYOcozgXgw81nyf1lorpdw2hFwSleh2U60DmJM8kOfXFPDt6UMIC/TMP7Pj1cebzOaw+/huiiuLG/cnhCWQEpnCtcnXNial/kH9PRKrEL1AkxHcQGnD4DilVBxQ5q4bS6ISbvHIwmSufvZzXvn8AA/MS3L7/Y5VHWuciLUhKZVWNT4JwZDwIUwYOIGlo5aSEpnCqAGjsARa3B6XED6kyQhu4B3gNiDb8f1td91YEpVwi4mJESwYHc3KtQXcMsOKJbh7nsTXWhtztjmeUWpISs0X+JsSO6Xx4dlRA0bRL6Bft9xfiL6olRHc2cDflVLfBQ4CN7jr/pKohNs8vDCZzKc/46XPDvDIwuQOn6+1priimN3HjaXQGx6edXWBPyFE92hlBPdxjFGAbieJSrjNmHgLV4yL5eXPDnDHTCv9Q9teYkJrTeHpQtYfXc/64vVsOLKBykPGlFhdXeBPCNF7SaISbvXQgmQ+2FHCH9YWkHX5qIv2l1eXs+HoBtYVr2P90fWN/UqDwgYxLngcC8Yu6LEF/oQQ3kkSlXCr5Jh+LJkQz5++KOS7s4cSGlTHxtKNRq3p6Hr2ntwLGPOaTYudxoz4GaTFpZHYL9GYzWFUumcLIITwOElUwq1q62u5dPI5PjjyETe88zKn6vdSW19LgCmASTGTyJyUSVp8GqP6j5IVVoUQLZJEJbqV1poDpw+wvng9646uY2PJRipqKgiIUpRVxHPTuG8z3zqb1OhUacoTQrhEEpXosmNVxxqb8tYfXU9ZlfHcX0JYApcNvYy0uDQSgsZz9e82czYmkRkzx3k4YiFEbyKJSnRYZU0lX5d+3TgAYt+pfYDRzzQ9djoz4mcwPW46if2aTp55w5Ry3viqiLvnDCdxgIzWE0K4RhKVaFdNfQ07y3c2JqZtx7ZRq2sJNAcyKXoSVw2/irS4NEYNGNXm4n8PzBvBP74+zO9W7+XX103owRIIIXozSVTiIlprCuwFjc8zfVX6FZU1lSgUKZEp3DbmNtLi00iNTiXQHOjydeMswXxn+mBeXXeQ+9JHYI2SB3OFEO2TRCUAKKsqY8PRDY3Jqaza6GdK7JfIFUOvYEb8DKbFTuvy/Hj3pg/n9S+LeOqTvTx548RuiFwI4eskUfVRlTWVbCzZyLqj61hfvJ799v0A9A/sz/S46aTFpTE9bjoJ/RK69b7R/YK4deYQVq4t4L704STFyBx8Qoi2SaLqI2rqa9h+bHvjyLztx7Y39jNNjpnMkhFLSItLY+SAkW32M3WHu+cM5y/rDvLbj/fy7HcmufVeQojeTxKVj9Jas//U/sbE9FXJV1TVVqFQjIkcw+1jb2dG3AwmRE/oUD9TdxgQGsB3Zw/l6dX7uK/Yzph4WW5DCNE6SVQ+pLSylA0lG/h3+b/5+T9+Tnl1OQCD+w1uHJk3NXaqV6zD9N1LhvHKF4U8uWovL97W7uKiQog+TBJVL1ZxvoKvSr5qrDUV2AsACDOFccngS0iLN/qZBoUN8nCkF7ME+7N8zjB+81E+W4tOMSExwtMhCSG8lCSqXqSmroZt5dsaR+ZtL99Ona4jyBzE5JjJXDPiGtLi0yjeWsy8ufM8HW67bp81lJc+O8Djq/J5ddk0T4cjhPBSkqi8mNaafaf2sf7oetYVr2Nj6Uaqa6sxKRNjIsewbOwyZsTPYMLACQSYL6z1VKJKPBi168IC/bhn7nD+94Nv+KrwBFOtAzwdkhDCC0mi8jIllSUX5s0rXs/xs8cBGBI+hMXDFzMjbgZTYqd4RT9Td7h1hpUXPj3A4x/t4fXlMzwdjhDCC0mi8rAz58806Wc6YD8AwICgAUyPm86MOGPevPiweA9H6h7BAWbuzxjOz9/dxRf7ypk5IsrTIQkhvIwkqh5WU1fD1mNbjQdtj65nR/kO6nU9wX7BTIqZxLVJ15IWl0ZS/yS3P8/kLW6aNpiVawt4fFU+M4ZHopTydEhCCCdKqQjgRWAsoIFlQBXwPBAGFALf0Vqfdsf9JVG5mdaa/JP5jTWmr0u/buxnGhs1ljvH3UlaXNpF/Ux9SZC/mQfmjeBH/9pBXv4xMkZGezokIURTTwH/0Vpfp5QKAEKAVcD3tdZrlFLLgP8CfuKOm0uicoOSypLGmcbXH13PibMnALCGW1kyfAlp8cbzTOEB4R6O1HtcPzmR5/L28+SqfNKTB0qtSggvoZSyAHOA2wG01ueB80qpZGCt47BVwIdIovJep8+f5quSr1hXvI4NRzdQeLoQMPqZ0uLSSItLY0b8DGJDYz0bqBcL8DOxYn4S//XPbazaVcqiMfKzEqKH+CmlNjq9X6m1Xun0fihwDPijUmoC8DWwAtgJLAH+DVwPNF2ArjsDdNeFfdn5uvNGP5MjMe04fqGfaXLMZK5Pvp60+DSSIpKkZtAB16QO4rm8/TyxKp8Fo2M8HY4QfUWt1rqt6WH8gEnAg1rrDUqpp4AsjH6qp5VSPwHeAc67K0BJVC6o1/XsPbnXeJ7p6Do2lW6iurYaszIzNmosd427q7Gfyd/s7+lwey0/s4kVC5JY8foW3t9xlDBPBySEADgMHNZab3C8/yeQpbX+CbAIwNEMmOmuANyWqJRSI4E3nDYNA34KRAB3YVQlAX6otX6/hfMvw+jAMwMvaq2z3RVrS45WHG180HZDyYbGfqahlqFcPeLqxnnz+gXIMhXd6crx8Tybu48nV+Xzo0na0+EI0edprUuUUkVKqZFa6z3AfGCXUipaa12mlDIBP8YYAegWbktUjgJNBFBKmYEjwL+AO4Antda/ae1cx/HPAgsxsvlXSql3tNa73BVvVV0VHx/8uHEAxMHTBwGIDIpkRvyMxueZpJ/JvcwmxcMLkrn3tU2sKw7A+yeCEqJPeBB4zTHirwDj9/itSqn7HfvfAv7orpv3VNPffGC/1vqgi30204B9WusCAKXU6xiddt2eqM7WnmXZh8vYUb4DfVgT7BfM1Nip3DjyRtLi0hgRMUL6mXrYpWNiGRMfzp93nSbviTWeDqdbVFZVEbpJyuJNfKUcAKqmmvR0911fa70FaN6P9ZTjy+16KlEtBf7m9P4BpdStwEbgUa31yWbHDwKKnN4fBqa3dGGl1HJgOYCfnx95eXkdDi6oOoiM4AzGhY/DGmjFT/lBGRwpO8IRjnT4ep5WUVHRqZ+DN/nW4DpyzmtMqtrToXSLsMB6zFIWr+Ir5QAICKjr9f/Pt0lr7dYvIAAoB2Ic72Mw+p1MwC+Bl1s45zqMfqmG97cAz7R3r5CQEN1Zubm5nT7X2/hKWXylHFpLWbyRr5RD666VBajUbs4DXf3qiTl6Lgc2aa1LHYmxVGtdp7WuB17AaOZr7ghNx+QnOLYJIYToY3oiUd2EU7OfUirOad81wI4WzvkKSFJKDXV03i3FGKcvhBCij3FrolJKhWKM3HvLafOvlVLblVLbgAzgYcex8Uqp9wG01rXAAxhTcuwG/q613unOWIUQQngntw6m0FpXApHNtt3SyrHFwBVO798HLnq+SgghRN/SN9aREEII0WtJohJCCOHVJFEJIYTwapKohBBCeDVlPO/lG5RS9UBnHzX3A2q7MRxP8pWy+Eo5QMrijXylHNC1sgRrrb260uJTiaorlFIbddtrsvQavlIWXykHSFm8ka+UA3yrLC3x6iwqhBBCSKISQgjh1SRRXbDS0wF0I18pi6+UA6Qs3shXygG+VZaLSB+VEEIIryY1KiGEEF5NEpUQQgiv1ucSlVLqMqXUHqXUPqVUVgv7A5VSbzj2b1BKWT0QZrtcKMftSqljSqktjq87PRFne5RSLyulypRSLS33gjI87SjnNqXUpJ6O0VUulCVdKWV3+kx+2tMxukoplaiUylVK7VJK7VRKrWjhGK//bFwsR6/4XJRSQUqpL5VSWx1l+XkLx/SK318d5umVG3vyC2Nl4f3AMIyVh7cCKc2OuQ943vF6KfCGp+PuZDlux4VVkT39BcwBJgE7Wtl/BfABoIA0YIOnY+5CWdKB9zwdp4tliQMmOV73A/Jb+Dfm9Z+Ni+XoFZ+L4+cc5njtD2wA0pod4/W/vzrz1ddqVNOAfVrrAq31eeB1YEmzY5YAf3K8/icwXymlejBGV7hSjl5Ba70WONHGIUuAV7VhPRDRbPFNr+FCWXoNrfVRrfUmx+szGOvCDWp2mNd/Ni6Wo1dw/JwrHG/9HV/NR8P1ht9fHdbXEtUgoMjp/WEu/kfbeIw2FnC002xNLS/gSjkArnU0yfxTKZXYM6F1O1fL2lvMcDTdfKCUGuPpYFzhaD5KxfgL3lmv+mzaKAf0ks9FKWVWSm0ByoBVWutWPxMv/v3VYX0tUfUl7wJWrfV4YBUX/soSnrMJGKK1ngD8Dvi3Z8Npn1IqDHgTeEhrfdrT8XRWO+XoNZ+L1rpOaz0RSACmKaXGejikHtHXEtURwLlmkeDY1uIxSik/wAIc75HoXNduObTWx7XW5xxvXwQm91Bs3c2Vz6xX0Fqfbmi60cYK1v5KqSgPh9UqpZQ/xi/317TWb7VwSK/4bNorR2/7XAC01qeAXOCyZrt6w++vDutrieorIEkpNVQpFYDR2fhOs2PeAW5zvL4OWK0dPZNepN1yNOsrWIzRNt8bvQPc6hhhlgbYtdZHPR1UZyilYhv6C5RS0zD+//PKXyKOOF8Cdmutn2jlMK//bFwpR2/5XJRSA5VSEY7XwcBC4Jtmh/WG318d5ufpAHqS1rpWKfUA8CHGyLmXtdY7lVL/H7BRa/0Oxj/qPyul9mF0jC/1XMQtc7Ec31NKLcaY+v8ExihAr6OU+hvGqKsopdRh4GcYncRorZ8H3scYXbYPqALu8Eyk7XOhLNcB9yqlajGWo1nqxb9EZgG3ANsdfSIAPwQGQ6/6bFwpR2/5XOKAPymlzBjJ9O9a6/d62++vzpAplIQQQni1vtb0J4QQopeRRCWEEMKrSaISQgjh1SRRCSGE8GqSqIQQQng1SVRCCCG8miQqIYQQXu3/B9YpHI+6ct+1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.grid(which='major', axis='both')\n",
    "\n",
    "ax1.set_ylabel('Actual Battery', color='C0')\n",
    "ax2.set_ylabel('Predicted Battery', color='C1')\n",
    "\n",
    "\n",
    "ax1.plot(actual, color='C0')\n",
    "ax2.plot(mean, color='C1')\n",
    "ax2.plot(q01, color='C2')\n",
    "ax2.plot(q90, color='C2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! Now let's work on detecting [motor anomalies](mt-motor-anomaly.ipynb)."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Base Python)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/python-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
